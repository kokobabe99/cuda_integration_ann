{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0b84556-3cdc-4eef-b940-361f65732745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/bin:/bin:/usr/bin:/usr/local/cuda/bin:/usr/local/cuda/bin:/usr/local/cuda/bin:/usr/local/cuda/bin:/usr/local/cuda/bin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Add the directory containing the executable to the PATH\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/usr/local/cuda/bin\"\n",
    "\n",
    "# Check if the directory is added to the a\n",
    "print(os.environ[\"PATH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82c50a9a-4761-463a-8540-1833bcbc3670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2025 NVIDIA Corporation\n",
      "Built on Wed_Apr__9_19:24:57_PDT_2025\n",
      "Cuda compilation tools, release 12.9, V12.9.41\n",
      "Build cuda_12.9.r12.9/compiler.35813241_0\n",
      "nvprof: NVIDIA (R) Cuda command line profiler\n",
      "Copyright (c) 2012 - 2025 NVIDIA Corporation\n",
      "Release version 12.9.19 (21)\n",
      "NVIDIA Nsight Systems version 2025.1.3.140-251335620677v0\n",
      "NVIDIA (R) Nsight Compute Command Line Profiler\n",
      "Copyright (c) 2018-2025 NVIDIA Corporation\n",
      "Version 2025.2.0.0 (build 35613519) (public-release)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvcc --version\n",
    "nvprof --version\n",
    "nsys --version\n",
    "ncu --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cca7ffcb-1cbc-4218-95c4-77f2cbb63c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 26 08:21:11 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.51.03              Driver Version: 575.51.03      CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-PCIE-32GB           Off |   00000000:00:10.0 Off |                    0 |\n",
      "| N/A   39C    P0             23W /  250W |       0MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0a0ed84-dd26-4ecd-b44e-daa940de7142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kmean_gpu.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile kmean_gpu.cu\n",
    "\n",
    "#include <cuda_runtime.h>\n",
    "#include <cstdio>\n",
    "#include <vector>\n",
    "#include <random>\n",
    "#include <algorithm>\n",
    "#include <numeric>\n",
    "#include <cmath>\n",
    "#include <cassert>\n",
    "#include <unordered_set>\n",
    "#include <limits>\n",
    "#include <cfloat>\n",
    "\n",
    "// ---------------- Config ----------------\n",
    "static const int DIM          = 64;\n",
    "static const float ALPHA      = 0.7f;\n",
    "static const int SEED         = 2025; \n",
    "static const int N            = 1 << 20; // 1 Million vectors\n",
    "static const int K            = 1024;    // Clusters\n",
    "static const int NPROBE       = 32;       // Search depth\n",
    "static const int TOPK         = 5;\n",
    "static const int KMEANS_ITERS = 15;      // K-Means iterations\n",
    "\n",
    "using Vec = std::vector<float>;\n",
    "\n",
    "// ---------------- Embedding Generator ----------------\n",
    "\n",
    "static Vec numberBase[76]; // 1..75\n",
    "static Vec posBase[25];    // 0..24\n",
    "\n",
    "static void normInPlace(Vec &v) {\n",
    "    double s = 0;\n",
    "    for (float x : v) s += (double)x * x;\n",
    "    float n = float(std::sqrt(s) + 1e-12);\n",
    "    for (float &x : v) x /= n;\n",
    "}\n",
    "\n",
    "static Vec randUnit(std::mt19937 &rng) {\n",
    "    std::uniform_real_distribution<float> U(-1.f, 1.f);\n",
    "    Vec v(DIM);\n",
    "    for (int i = 0; i < DIM; i++) v[i] = U(rng);\n",
    "    normInPlace(v);\n",
    "    return v;\n",
    "}\n",
    "\n",
    "static void initBases() {\n",
    "    std::mt19937 rng(SEED);\n",
    "    for (int n = 1; n <= 75; n++) numberBase[n] = randUnit(rng);\n",
    "    for (int i = 0; i < 25; i++)  posBase[i]    = randUnit(rng);\n",
    "}\n",
    "\n",
    "static Vec cardToVec(const int card[25]) {\n",
    "    Vec out(DIM, 0.f);\n",
    "    for (int i = 0; i < 25; i++) {\n",
    "        int n = card[i];\n",
    "        const Vec &b = numberBase[n];\n",
    "        const Vec &p = posBase[i];\n",
    "        for (int j = 0; j < DIM; j++)\n",
    "            out[j] += b[j] + ALPHA * p[j];\n",
    "    }\n",
    "    normInPlace(out);\n",
    "    return out;\n",
    "}\n",
    "\n",
    "static void genCard(std::mt19937 &rng, int out[25]) {\n",
    "    std::vector<int> p(75);\n",
    "    std::iota(p.begin(), p.end(), 1);\n",
    "    std::shuffle(p.begin(), p.end(), rng);\n",
    "    for (int i = 0; i < 25; i++) out[i] = p[i];\n",
    "}\n",
    "\n",
    "static double dot_host(const float* a, const float* b) {\n",
    "    double s = 0;\n",
    "    for (int i = 0; i < DIM; i++) s += (double)a[i] * b[i];\n",
    "    return s;\n",
    "}\n",
    "\n",
    "// ---------------- GPU K-Means Kernels ----------------\n",
    "// CUDA kernel for K-Means E-step\n",
    "// Each thread:\n",
    "// 1) Finds the nearest centroid for a data point\n",
    "// 2) Atomically accumulates sum and count for that centroid\n",
    "__global__ void assignAndAccumulateKernel(const float* data,      // Input data array (N x DIM)\n",
    "                                          int N,                  // Number of data points\n",
    "                                          const float* centroids, // Centroid array (K x DIM)\n",
    "                                          int K,                  // Number of clusters\n",
    "                                          int* assign,            // Output: cluster assignment per point\n",
    "                                          float* sums,            // Output: sum vectors per cluster\n",
    "                                          int* counts) {          // Output: count per cluster\n",
    "    \n",
    "    // Grid-stride loop: each thread processes multiple data points\n",
    "    for (int i = blockIdx.x * blockDim.x + threadIdx.x;  // Global thread index\n",
    "         i < N;                                          // Stop if out of range\n",
    "         i += gridDim.x * blockDim.x) {                  // Jump by total number of threads in grid\n",
    "\n",
    "        // Pointer to the current data vector x_i\n",
    "        const float* xi = data + (size_t)i * DIM;\n",
    "\n",
    "        // Best (closest) cluster index\n",
    "        int bestC = 0;\n",
    "\n",
    "        // Initialize best (minimum) distance to a very large value\n",
    "        float bestD = 1e30f;\n",
    "\n",
    "        // Loop through all centroids\n",
    "        for (int c = 0; c < K; ++c) {\n",
    "\n",
    "            // Pointer to centroid c\n",
    "            const float* ctr = centroids + (size_t)c * DIM;\n",
    "\n",
    "            // Dot product accumulator\n",
    "            float dot = 0.f;\n",
    "\n",
    "            // Compute dot product between x_i and centroid c\n",
    "            for (int d = 0; d < DIM; ++d) {\n",
    "                dot += xi[d] * ctr[d];\n",
    "            }\n",
    "\n",
    "            // Distance using cosine distance: 1 - dot product\n",
    "            float dist = 1.f - dot;\n",
    "\n",
    "            // Update best distance and best cluster if closer\n",
    "            if (dist < bestD) {\n",
    "                bestD = dist;\n",
    "                bestC = c;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Store the best cluster index for this point\n",
    "        assign[i] = bestC;\n",
    "\n",
    "        // Atomically increment the count for that cluster\n",
    "        atomicAdd(&counts[bestC], 1);\n",
    "\n",
    "        // Compute base index for the sum vector of that cluster\n",
    "        size_t base = (size_t)bestC * DIM;\n",
    "\n",
    "        // Atomically accumulate the vector into the cluster sum\n",
    "        for (int d = 0; d < DIM; ++d) {\n",
    "            atomicAdd(&sums[base + d], xi[d]);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// CUDA kernel for K-Means M-step\n",
    "// Each thread updates one centroid\n",
    "__global__ void updateCentroidsKernel(float* centroids,   // Input/Output: centroids (K x DIM)\n",
    "                                      const float* sums,  // Input: sum vectors per cluster\n",
    "                                      const int* counts, // Input: number of points per cluster\n",
    "                                      int K) {           // Number of clusters\n",
    "\n",
    "    // Global thread index maps to cluster index\n",
    "    int c = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    // Exit if thread index exceeds number of clusters\n",
    "    if (c >= K) return;\n",
    "\n",
    "    // Number of points assigned to this cluster\n",
    "    int cnt = counts[c];\n",
    "\n",
    "    // Pointer to centroid c\n",
    "    float* ctr = centroids + (size_t)c * DIM;\n",
    "\n",
    "    // Pointer to sum vector of cluster c\n",
    "    const float* sumc = sums + (size_t)c * DIM;\n",
    "\n",
    "    // Only update if cluster has at least one point\n",
    "    if (cnt > 0) {\n",
    "\n",
    "        // Used to calculate vector magnitude for normalization\n",
    "        double norm2 = 0.0;\n",
    "\n",
    "        // Compute the mean of assigned points for this centroid\n",
    "        for (int d = 0; d < DIM; ++d) {\n",
    "            float v = sumc[d] / (float)cnt;  // Mean value on dimension d\n",
    "            ctr[d] = v;                      // Store in centroid\n",
    "            norm2 += (double)v * (double)v;  // Accumulate squared magnitude\n",
    "        }\n",
    "\n",
    "        // Compute the vector norm\n",
    "        float n = float(std::sqrt(norm2) + 1e-12);\n",
    "\n",
    "        // Normalize centroid to unit length\n",
    "        for (int d = 0; d < DIM; ++d) {\n",
    "            ctr[d] /= n;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "// ---------------- Host: Inverted Lists ----------------\n",
    "\n",
    "static void buildInvertedLists(\n",
    "    const std::vector<int>& assign,\n",
    "    int N, int K,\n",
    "    std::vector<std::vector<int>>& lists\n",
    ") {\n",
    "    lists.assign(K, {});\n",
    "    for (int i = 0; i < N; ++i) {\n",
    "        int c = assign[i];\n",
    "        if (c >= 0 && c < K) {\n",
    "            lists[c].push_back(i);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "// ---------------- Main ----------------\n",
    "int main() {\n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, 0);\n",
    "    int BLOCK  = prop.multiProcessorCount; \n",
    "    \n",
    "    printf(\"Params: N=%d  K=%d  nprobe=%d  TOPK=%d  DIM=%d  KMEANS_ITERS=%d\\n\",\n",
    "           N, K, NPROBE, TOPK, DIM, KMEANS_ITERS);\n",
    "    printf(\"Mode: GPU Training -> CPU Search\\n\");\n",
    "\n",
    "    initBases();\n",
    "    std::mt19937 rng(SEED + 7);\n",
    "\n",
    "    // 1) Data Generation\n",
    "    std::vector<int>   h_cards((size_t)N * 25);\n",
    "    std::vector<float> h_data((size_t)N * DIM);\n",
    "\n",
    "    printf(\"[INIT] Generating %d vectors...\\n\", N);\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        int c[25];\n",
    "        genCard(rng, c);\n",
    "        for (int t = 0; t < 25; ++t) h_cards[(size_t)i * 25 + t] = c[t];\n",
    "        Vec v = cardToVec(c);\n",
    "        for (int d = 0; d < DIM; ++d) h_data[(size_t)i * DIM + d] = v[d];\n",
    "    }\n",
    "\n",
    "    // 2) Build Query\n",
    "    int qc[25];\n",
    "    for (int t = 0; t < 25; ++t) qc[t] = h_cards[t]; // Copy 0-th card\n",
    "    qc[3] = 75; qc[17] = 1; std::swap(qc[5], qc[19]); // Modify it\n",
    "    Vec qvec = cardToVec(qc);\n",
    "    std::vector<float> q_host(qvec.begin(), qvec.end());\n",
    "\n",
    "    {\n",
    "        double dot0 = dot_host(q_host.data(), &h_data[0]);\n",
    "        printf(\"[DEBUG] Query vs Data[0]: dot=%.9f dist=%.9f\\n\", dot0, 1.0 - dot0);\n",
    "    }\n",
    "\n",
    "    // 3) GPU Allocations for Training\n",
    "    float *d_data = 0, *d_centroids = 0;\n",
    "    int   *d_assign = 0, *d_counts = 0;\n",
    "    float *d_sums = 0;\n",
    "\n",
    "    cudaMalloc(&d_data,      (size_t)N * DIM * sizeof(float));\n",
    "    cudaMalloc(&d_centroids, (size_t)K * DIM * sizeof(float));\n",
    "    cudaMalloc(&d_assign,    N * sizeof(int));\n",
    "    cudaMalloc(&d_sums,      (size_t)K * DIM * sizeof(float));\n",
    "    cudaMalloc(&d_counts,    K * sizeof(int));\n",
    "\n",
    "    cudaMemcpy(d_data, h_data.data(), (size_t)N * DIM * sizeof(float), cudaMemcpyHostToDevice);\n",
    "\n",
    "    // 4) Initialize Centroids (Random select from data)\n",
    "    {\n",
    "        std::vector<int> idx(N);\n",
    "        std::iota(idx.begin(), idx.end(), 0);\n",
    "        std::shuffle(idx.begin(), idx.end(), rng);\n",
    "        std::vector<float> h_initC((size_t)K * DIM);\n",
    "        for (int c = 0; c < K; ++c) {\n",
    "            int i = idx[c];\n",
    "            std::copy_n(&h_data[(size_t)i * DIM], DIM, &h_initC[(size_t)c * DIM]);\n",
    "        }\n",
    "        cudaMemcpy(d_centroids, h_initC.data(), (size_t)K * DIM * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    }\n",
    "\n",
    "    // 5) GPU K-Means Training\n",
    "    {\n",
    "        dim3 block(BLOCK);\n",
    "        dim3 gridN((N + BLOCK - 1) / BLOCK);\n",
    "        dim3 gridK((K + BLOCK - 1) / BLOCK);\n",
    "\n",
    "        printf(\"[TRAIN] Running K-Means on GPU (%d iters)...\\n\", KMEANS_ITERS);\n",
    "\n",
    "        for (int it = 0; it < KMEANS_ITERS; ++it) {\n",
    "            cudaMemset(d_sums,   0, (size_t)K * DIM * sizeof(float));\n",
    "            cudaMemset(d_counts, 0, K * sizeof(int));\n",
    "\n",
    "            assignAndAccumulateKernel<<<gridN, block>>>(\n",
    "                d_data, N, d_centroids, K, d_assign, d_sums, d_counts\n",
    "            );\n",
    "            cudaDeviceSynchronize();\n",
    "\n",
    "            updateCentroidsKernel<<<gridK, block>>>(\n",
    "                d_centroids, d_sums, d_counts, K\n",
    "            );\n",
    "            cudaDeviceSynchronize();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // 6) Retrieve Training Results\n",
    "    std::vector<int> h_assign(N);\n",
    "    cudaMemcpy(h_assign.data(), d_assign, N * sizeof(int), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // Retrieve final centroids for CPU search\n",
    "    std::vector<float> h_finalCentroids(K * DIM);\n",
    "    cudaMemcpy(h_finalCentroids.data(), d_centroids, (size_t)K * DIM * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // We are done with GPU memory\n",
    "    cudaFree(d_data);\n",
    "    cudaFree(d_centroids);\n",
    "    cudaFree(d_assign);\n",
    "    cudaFree(d_sums);\n",
    "    cudaFree(d_counts);\n",
    "\n",
    "    // 7) Build IVF Index (Host)\n",
    "    printf(\"[INDEX] Building Inverted Lists on Host...\\n\");\n",
    "    std::vector<std::vector<int>> lists;\n",
    "    buildInvertedLists(h_assign, N, K, lists);\n",
    "\n",
    "    int nonEmpty = 0;\n",
    "    for(const auto& list : lists) if(!list.empty()) nonEmpty++;\n",
    "    printf(\"[INDEX] Non-empty clusters: %d / %d\\n\", nonEmpty, K);\n",
    "\n",
    "    // ---------------------------------------------------------\n",
    "    //  SEARCH PHASE (CPU)\n",
    "    // ---------------------------------------------------------\n",
    "    printf(\"\\n[SEARCH] CPU Search (nprobe=%d)...\\n\", NPROBE);\n",
    "\n",
    "    // Step A: Coarse Search (Find nearest NPROBE clusters)\n",
    "    // Format: {distance, cluster_id}\n",
    "    std::vector<std::pair<float, int>> centerDists;\n",
    "    centerDists.reserve(K);\n",
    "\n",
    "    for (int c = 0; c < K; ++c) {\n",
    "        const float* ctr = &h_finalCentroids[(size_t)c * DIM];\n",
    "        double dotVal = dot_host(q_host.data(), ctr);\n",
    "        float dist = 1.0f - (float)dotVal;\n",
    "        centerDists.push_back({dist, c});\n",
    "    }\n",
    "\n",
    "    // Sort centroids by distance ASC\n",
    "    std::sort(centerDists.begin(), centerDists.end(), \n",
    "              [](const std::pair<float, int>& a, const std::pair<float, int>& b){\n",
    "                  return a.first < b.first;\n",
    "              });\n",
    "\n",
    "    // Step B: Gather Candidates & Exact Search\n",
    "    // Format: {distance, vector_id}\n",
    "    std::vector<std::pair<float, int>> candidates;\n",
    "    // Reserve some memory to avoid reallocations (heuristic)\n",
    "    candidates.reserve((N / K) * NPROBE * 2);\n",
    "\n",
    "    int visitedVecs = 0;\n",
    "    for (int i = 0; i < NPROBE && i < K; ++i) {\n",
    "        int c_id = centerDists[i].second;\n",
    "        const auto& bucket = lists[c_id];\n",
    "        visitedVecs += bucket.size();\n",
    "\n",
    "        for (int vecIdx : bucket) {\n",
    "            const float* vec = &h_data[(size_t)vecIdx * DIM];\n",
    "            double dotVal = dot_host(q_host.data(), vec);\n",
    "            float dist = 1.0f - (float)dotVal;\n",
    "            candidates.push_back({dist, vecIdx});\n",
    "        }\n",
    "    }\n",
    "\n",
    "    printf(\"[SEARCH] Scanned %d vectors from top %d clusters.\\n\", visitedVecs, NPROBE);\n",
    "\n",
    "    // Step C: Ranking (Top-K)\n",
    "    if (candidates.empty()) {\n",
    "        printf(\"No candidates found.\\n\");\n",
    "    } else {\n",
    "        int finalK = std::min((int)candidates.size(), TOPK);\n",
    "        \n",
    "        // Partial sort gives us the smallest K elements at the beginning\n",
    "        std::partial_sort(candidates.begin(), \n",
    "                          candidates.begin() + finalK, \n",
    "                          candidates.end(),\n",
    "                          [](const std::pair<float, int>& a, const std::pair<float, int>& b){\n",
    "                              return a.first < b.first;\n",
    "                          });\n",
    "\n",
    "        printf(\"\\nTop-%d Results:\\n\", finalK);\n",
    "        for (int i = 0; i < finalK; ++i) {\n",
    "            printf(\"%2d) id=%d  dist=%.6f  sim=%.6f\\n\",\n",
    "                   i+1, candidates[i].second, candidates[i].first, 1.f - candidates[i].first);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5009ae69-3720-4533-ad36-22e9d9805804",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc -O3 -std=c++17 -arch=sm_70 kmean_gpu.cu -o kmean_gpu -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7bfe5082-b45c-4dd2-b398-69d43ed2b167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==4239== NVPROF is profiling process 4239, command: ./kmean_gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: N=1048576  K=1024  nprobe=32  TOPK=5  DIM=64  KMEANS_ITERS=15\n",
      "Mode: GPU Training -> CPU Search\n",
      "[INIT] Generating 1048576 vectors...\n",
      "[DEBUG] Query vs Data[0]: dot=0.927471359 dist=0.072528641\n",
      "[TRAIN] Running K-Means on GPU (15 iters)...\n",
      "[INDEX] Building Inverted Lists on Host...\n",
      "[INDEX] Non-empty clusters: 1024 / 1024\n",
      "\n",
      "[SEARCH] CPU Search (nprobe=32)...\n",
      "[SEARCH] Scanned 35377 vectors from top 32 clusters.\n",
      "\n",
      "Top-5 Results:\n",
      " 1) id=0  dist=0.072529  sim=0.927471\n",
      " 2) id=89698  dist=0.157913  sim=0.842087\n",
      " 3) id=913782  dist=0.158968  sim=0.841032\n",
      " 4) id=350035  dist=0.164414  sim=0.835586\n",
      " 5) id=284315  dist=0.172628  sim=0.827372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==4239== Profiling application: ./kmean_gpu\n",
      "==4239== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   89.46%  663.83ms        15  44.256ms  42.209ms  45.316ms  assignAndAccumulateKernel(float const *, int, float const *, int, int*, float*, int*)\n",
      "                   10.32%  76.570ms         2  38.285ms  23.776us  76.546ms  [CUDA memcpy HtoD]\n",
      "                    0.17%  1.2947ms         2  647.35us  28.320us  1.2664ms  [CUDA memcpy DtoH]\n",
      "                    0.04%  309.73us        15  20.648us  19.680us  24.736us  updateCentroidsKernel(float*, float const *, int const *, int)\n",
      "                    0.01%  46.176us        30  1.5390us  1.0560us  2.6240us  [CUDA memset]\n",
      "      API calls:   62.56%  664.25ms        30  22.142ms  21.470us  45.320ms  cudaDeviceSynchronize\n",
      "                   29.86%  317.05ms         5  63.409ms  2.8980us  316.84ms  cudaMalloc\n",
      "                    7.42%  78.741ms         4  19.685ms  95.473us  76.765ms  cudaMemcpy\n",
      "                    0.06%  590.13us         5  118.03us  5.5280us  405.69us  cudaFree\n",
      "                    0.04%  412.17us        30  13.738us  4.5010us  187.41us  cudaLaunchKernel\n",
      "                    0.02%  219.05us       114  1.9210us     108ns  88.558us  cuDeviceGetAttribute\n",
      "                    0.02%  212.28us        30  7.0760us  3.4200us  43.367us  cudaMemset\n",
      "                    0.02%  163.83us         1  163.83us  163.83us  163.83us  cudaGetDeviceProperties\n",
      "                    0.00%  30.773us         1  30.773us  30.773us  30.773us  cuDeviceGetName\n",
      "                    0.00%  24.317us         1  24.317us  24.317us  24.317us  cuDeviceTotalMem\n",
      "                    0.00%  4.7950us         3  1.5980us     292ns  4.0370us  cuDeviceGetCount\n",
      "                    0.00%  4.2320us         1  4.2320us  4.2320us  4.2320us  cuDeviceGetPCIBusId\n",
      "                    0.00%     730ns         2     365ns     105ns     625ns  cuDeviceGet\n",
      "                    0.00%     414ns         1     414ns     414ns     414ns  cuModuleGetLoadingMode\n",
      "                    0.00%     207ns         1     207ns     207ns     207ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./kmean_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7c544e5-7bd0-44c0-bc81-995e72322483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Device-side CUDA Event completion trace is currently enabled.\n",
      "         This may increase runtime overhead and the likelihood of false\n",
      "         dependencies across CUDA Streams. If you wish to avoid this, please\n",
      "         disable the feature with --cuda-event-trace=false.\n",
      "WARNING: CPU IP/backtrace sampling not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n",
      "WARNING: CPU context switch tracing not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: N=16777216  K=1024  nprobe=32  TOPK=5  DIM=64  KMEANS_ITERS=15\n",
      "Mode: GPU Training -> CPU Search\n",
      "[INIT] Generating 16777216 vectors...\n",
      "[DEBUG] Query vs Data[0]: dot=0.927471359 dist=0.072528641\n",
      "[TRAIN] Running K-Means on GPU (15 iters)...\n",
      "[INDEX] Building Inverted Lists on Host...\n",
      "[INDEX] Non-empty clusters: 1024 / 1024\n",
      "\n",
      "[SEARCH] CPU Search (nprobe=32)...\n",
      "[SEARCH] Scanned 557455 vectors from top 32 clusters.\n",
      "\n",
      "Top-5 Results:\n",
      " 1) id=0  dist=0.072529  sim=0.927471\n",
      " 2) id=15528589  dist=0.136097  sim=0.863903\n",
      " 3) id=13929498  dist=0.139304  sim=0.860696\n",
      " 4) id=8185180  dist=0.146311  sim=0.853689\n",
      " 5) id=16494452  dist=0.150325  sim=0.849675\n",
      "Collecting data...\n",
      "Generating '/tmp/nsys-report-bf67.qdstrm'\n",
      "[1/1] [========================100%] kmean_gpu.nsys-rep\n",
      "Generated:\n",
      "\t/home/jupyter-feifan_chen@dlsu.e-15ebb/kmean_gpu.nsys-rep\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nsys profile -o kmean_gpu ./kmean_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083df34d-0759-4049-80e0-c99062e2ce28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kmean_cpu.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile kmean_cpu.cpp\n",
    "\n",
    "#include <cstdio>\n",
    "#include <vector>\n",
    "#include <random>\n",
    "#include <algorithm>\n",
    "#include <numeric>\n",
    "#include <cmath>\n",
    "#include <cassert>\n",
    "#include <unordered_set>\n",
    "#include <limits>\n",
    "#include <cfloat>\n",
    "#include <cstring>\n",
    "\n",
    "// ---------------- Config ----------------\n",
    "static const int DIM          = 64;\n",
    "static const float ALPHA      = 0.7f;\n",
    "static const int SEED         = 2025; \n",
    "static const int N            = 1 << 16; // demo: 16384\n",
    "static const int K            = 1024;\n",
    "static const int NPROBE       = 4;       // cluster depth during search\n",
    "static const int TOPK         = 5;\n",
    "\n",
    "static const int KMEANS_ITERS = 15;      // K-Means iters\n",
    "\n",
    "using Vec = std::vector<float>;\n",
    "\n",
    "// ---------------- Embedding basic ----------------\n",
    "\n",
    "static Vec numberBase[76]; // 1..75\n",
    "static Vec posBase[25];    // 0..24\n",
    "\n",
    "static void normInPlace(Vec &v) {\n",
    "    double s = 0;\n",
    "    for (float x : v) s += (double)x * x;\n",
    "    float n = float(std::sqrt(s) + 1e-12);\n",
    "    for (float &x : v) x /= n;\n",
    "}\n",
    "\n",
    "static Vec randUnit(std::mt19937 &rng) {\n",
    "    std::uniform_real_distribution<float> U(-1.f, 1.f);\n",
    "    Vec v(DIM);\n",
    "    for (int i = 0; i < DIM; i++) v[i] = U(rng);\n",
    "    normInPlace(v);\n",
    "    return v;\n",
    "}\n",
    "\n",
    "static void initBases() {\n",
    "    std::mt19937 rng(SEED);\n",
    "    for (int n = 1; n <= 75; n++) numberBase[n] = randUnit(rng);\n",
    "    for (int i = 0; i < 25; i++)  posBase[i]    = randUnit(rng);\n",
    "}\n",
    "\n",
    "static Vec cardToVec(const int card[25]) {\n",
    "    Vec out(DIM, 0.f);\n",
    "    for (int i = 0; i < 25; i++) {\n",
    "        int n = card[i];\n",
    "        const Vec &b = numberBase[n];\n",
    "        const Vec &p = posBase[i];\n",
    "        for (int j = 0; j < DIM; j++)\n",
    "            out[j] += b[j] + ALPHA * p[j];\n",
    "    }\n",
    "    normInPlace(out);\n",
    "    return out;\n",
    "}\n",
    "\n",
    "static void genCard(std::mt19937 &rng, int out[25]) {\n",
    "    std::vector<int> p(75);\n",
    "    std::iota(p.begin(), p.end(), 1);\n",
    "    std::shuffle(p.begin(), p.end(), rng);\n",
    "    for (int i = 0; i < 25; i++) out[i] = p[i];\n",
    "}\n",
    "\n",
    "static double dot_host(const float* a, const float* b) {\n",
    "    double s = 0;\n",
    "    for (int i = 0; i < DIM; i++) s += (double)a[i] * b[i];\n",
    "    return s;\n",
    "}\n",
    "\n",
    "// ---------------- Device: Distance Kernels (Simulated for Training) ----------------\n",
    "\n",
    "/**\n",
    " * E-Step: Assign data to nearest centroid & Accumulate stats\n",
    " * * This function simulates the \"Expectation\" step of K-Means.\n",
    " * It iterates through every data point, finds the closest centroid (using Cosine Distance),\n",
    " * assigns the point to that cluster, and accumulates the vector sums and counts\n",
    " * needed for the next update step.\n",
    " */\n",
    "void assignAndAccumulateKernel(const float* data,\n",
    "                                  int N_points,\n",
    "                                  const float* centroids,\n",
    "                                  int K_clusters,\n",
    "                                  int* assign,\n",
    "                                  float* sums,\n",
    "                                  int* counts) {\n",
    "    \n",
    "    // Loop 1: Iterate through every single data point (0 to N-1)\n",
    "    for (int i = 0; i < N_points; i++) {\n",
    "        \n",
    "        // Get pointer to the current data vector (Dimension = DIM)\n",
    "        const float* xi = data + (size_t)i * DIM;\n",
    "\n",
    "        int bestC = 0;          // Store the index of the nearest cluster\n",
    "        float bestD = 1e30f;    // Initialize minimum distance to a large value\n",
    "\n",
    "        // Loop 2: Compare current point 'xi' against all K centroids\n",
    "        for (int c = 0; c < K_clusters; ++c) {\n",
    "            const float* ctr = centroids + (size_t)c * DIM;\n",
    "            \n",
    "            // Calculate Dot Product (Inner Product)\n",
    "            float dot = 0.f;\n",
    "            for (int d = 0; d < DIM; ++d) dot += xi[d] * ctr[d];\n",
    "\n",
    "            // Convert Cosine Similarity to Cosine Distance\n",
    "            // Distance = 1.0 - Similarity\n",
    "            float dist = 1.f - dot;\n",
    "\n",
    "            // Keep track of the nearest centroid found so far\n",
    "            if (dist < bestD) {\n",
    "                bestD = dist;\n",
    "                bestC = c;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // 1. Record the assignment: Point 'i' belongs to Cluster 'bestC'\n",
    "        assign[i] = bestC;\n",
    "\n",
    "        // 2. Accumulate count: Increment the member count for this cluster\n",
    "        counts[bestC]++;\n",
    "\n",
    "        // 3. Accumulate sums: Add this vector's coordinates to the cluster's total\n",
    "        // This prepares for the average calculation in the next step.\n",
    "        size_t base = (size_t)bestC * DIM;\n",
    "        for (int d = 0; d < DIM; ++d) {\n",
    "            sums[base + d] += xi[d];\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "/**\n",
    " * M-Step: Update Centroids\n",
    " * * This function simulates the \"Maximization\" step of K-Means.\n",
    " * It calculates the new position of each centroid by averaging the vectors \n",
    " * assigned to it, and then normalizes the result to ensure it stays on the unit hypersphere.\n",
    " */\n",
    "void updateCentroidsKernel(float* centroids,\n",
    "                                  const float* sums,\n",
    "                                  const int* counts,\n",
    "                                  int K_clusters) {\n",
    "    \n",
    "    // Loop 1: Iterate through every cluster (0 to K-1)\n",
    "    for (int c = 0; c < K_clusters; c++) {\n",
    "        \n",
    "        int cnt = counts[c];    // Number of points in this cluster\n",
    "        \n",
    "        // Pointers to the current centroid and its accumulated sum\n",
    "        float* ctr = centroids + (size_t)c * DIM;\n",
    "        const float* sumc = sums + (size_t)c * DIM;\n",
    "    \n",
    "        // Only update if the cluster is not empty\n",
    "        if (cnt > 0) {\n",
    "            double norm2 = 0.0;\n",
    "\n",
    "            // Loop 2: Calculate the Mean (Average) Vector\n",
    "            for (int d = 0; d < DIM; ++d) {\n",
    "                // New Coordinate = Total Sum / Count\n",
    "                float v = sumc[d] / (float)cnt;\n",
    "                ctr[d] = v;\n",
    "\n",
    "                // Accumulate squared magnitude for normalization later\n",
    "                norm2 += (double)v * (double)v;\n",
    "            }\n",
    "\n",
    "            // Calculate the L2 Norm (Euclidean length)\n",
    "            // Added 1e-12 to prevent division by zero\n",
    "            float n = float(std::sqrt(norm2) + 1e-12);\n",
    "\n",
    "            // Loop 3: Normalization\n",
    "            // Since we use Cosine Distance, centroids must be normalized \n",
    "            // (length = 1.0) to lie on the unit sphere.\n",
    "            for (int d = 0; d < DIM; ++d) {\n",
    "                ctr[d] /= n;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// ---------------- Host: Inverted Lists ----------------\n",
    "\n",
    "static void buildInvertedLists(\n",
    "    const std::vector<int>& assign,\n",
    "    int N_points, int K_clusters,\n",
    "    std::vector<std::vector<int>>& lists\n",
    ") {\n",
    "    lists.assign(K_clusters, {});\n",
    "    for (int i = 0; i < N_points; ++i) {\n",
    "        int c = assign[i];\n",
    "        if (c >= 0 && c < K_clusters) {\n",
    "            lists[c].push_back(i);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// ---------------- Main ----------------\n",
    "int main() {\n",
    "    printf(\"Params: N=%d  K=%d  nprobe=%d  TOPK=%d  DIM=%d  KMEANS_ITERS=%d\\n\",\n",
    "           N, K, NPROBE, TOPK, DIM, KMEANS_ITERS);\n",
    "\n",
    "    initBases();\n",
    "    std::mt19937 rng(SEED + 7);\n",
    "\n",
    "    clock_t start, end;\n",
    "    double elapse = 0.0f;\n",
    "\n",
    "    // 1) Building dataset\n",
    "    std::vector<int>   h_cards((size_t)N * 25);\n",
    "    std::vector<float> h_data((size_t)N * DIM);\n",
    "\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        int c[25];\n",
    "        genCard(rng, c);\n",
    "        for (int t = 0; t < 25; ++t) h_cards[(size_t)i * 25 + t] = c[t];\n",
    "        Vec v = cardToVec(c);\n",
    "        for (int d = 0; d < DIM; ++d) h_data[(size_t)i * DIM + d] = v[d];\n",
    "    }\n",
    "\n",
    "    // 2) Build query\n",
    "    int qc[25];\n",
    "    for (int t = 0; t < 25; ++t) qc[t] = h_cards[t];\n",
    "    qc[3] = 75; qc[17] = 1; std::swap(qc[5], qc[19]);\n",
    "    Vec qvec = cardToVec(qc);\n",
    "    std::vector<float> qhost(qvec.begin(), qvec.end());\n",
    "\n",
    "    {\n",
    "        std::vector<float> d0(DIM);\n",
    "        for (int i = 0; i < DIM; i++) d0[i] = h_data[i];\n",
    "        double dot0 = dot_host(qhost.data(), d0.data());\n",
    "        printf(\"[DEBUG #1] host dot(q, data[0])=%.9f  dist=%.9f\\n\", dot0, 1.0 - dot0);\n",
    "    }\n",
    "\n",
    "    // 3) Pseudo-GPU Buffers (Training)\n",
    "    float *d_data = 0, *d_centroids = 0;\n",
    "    d_data = (float*)malloc((size_t)N * DIM * sizeof(float));\n",
    "    d_centroids = (float*)malloc((size_t)K * DIM * sizeof(float));\n",
    "\n",
    "    memcpy(d_data, h_data.data(), (size_t)N * DIM * sizeof(float));\n",
    "\n",
    "    // 4) Initial centroids\n",
    "    {\n",
    "        std::vector<int> idx(N);\n",
    "        std::iota(idx.begin(), idx.end(), 0);\n",
    "        std::shuffle(idx.begin(), idx.end(), rng);\n",
    "        std::vector<float> h_initC((size_t)K * DIM);\n",
    "        for (int c = 0; c < K; ++c) {\n",
    "            int i = idx[c];\n",
    "            std::copy_n(&h_data[(size_t)i * DIM], DIM, &h_initC[(size_t)c * DIM]);\n",
    "        }\n",
    "        memcpy(d_centroids, h_initC.data(), (size_t)K * DIM * sizeof(float));\n",
    "    }\n",
    "\n",
    "    int   *d_assign = (int*)malloc(N * sizeof(int));\n",
    "    float *d_sums   = (float*)malloc((size_t)K * DIM * sizeof(float));\n",
    "    int   *d_counts = (int*)malloc(K * sizeof(int));\n",
    "\n",
    "    // 5) K-Means Training (Simulating GPU Kernel Loop)\n",
    "    {\n",
    "        start = clock();\n",
    "        printf(\"[BUILD] K-Means: iters=%d\\n\", KMEANS_ITERS);\n",
    "\n",
    "        for (int it = 0; it < KMEANS_ITERS; ++it) {\n",
    "            memset(d_sums,   0, (size_t)K * DIM * sizeof(float));\n",
    "            memset(d_counts, 0, K * sizeof(int));\n",
    "\n",
    "            assignAndAccumulateKernel(d_data, N, d_centroids, K, d_assign, d_sums, d_counts);\n",
    "            updateCentroidsKernel(d_centroids, d_sums, d_counts, K);\n",
    "        }\n",
    "\n",
    "        end = clock();\n",
    "        double time_taken = ((double)(end-start))*1E3/CLOCKS_PER_SEC;\n",
    "        elapse += time_taken;\n",
    "        printf(\"K-means (C++ impl) time: %f ms\\n\", time_taken);\n",
    "    }\n",
    "\n",
    "    // 6) Build Inverted Index on Host\n",
    "    //    Retrieve assignment from \"device\"\n",
    "    std::vector<int> h_assign(N);\n",
    "    memcpy(h_assign.data(), d_assign, N * sizeof(int));\n",
    "\n",
    "    std::vector<std::vector<int>> lists;\n",
    "    buildInvertedLists(h_assign, N, K, lists);\n",
    "\n",
    "    int nonEmpty = 0;\n",
    "    for (int c = 0; c < K; ++c) if (!lists[c].empty()) nonEmpty++;\n",
    "    printf(\"[BUILD] Non-empty clusters: %d / %d\\n\", nonEmpty, K);\n",
    "\n",
    "    // =================================================================================\n",
    "    // CPU Search\n",
    "    // =================================================================================\n",
    "\n",
    "    start = clock();\n",
    "    printf(\"\\n[SEARCH] CPU Search logic nprobe=%d)...\\n\", NPROBE);\n",
    "\n",
    "    // Step A: Coarse Search (Find nearest NPROBE clusters)\n",
    "    // Format: {distance, cluster_id}\n",
    "    std::vector<std::pair<float, int>> centerDists;\n",
    "    centerDists.reserve(K);\n",
    "\n",
    "    for (int c = 0; c < K; ++c) {\n",
    "        // d_centroids is a flat array, similar to how we used it in GPU code\n",
    "        const float* ctr = d_centroids + (size_t)c * DIM; \n",
    "        double dotVal = dot_host(qhost.data(), ctr);\n",
    "        float dist = 1.0f - (float)dotVal;\n",
    "        centerDists.push_back({dist, c});\n",
    "    }\n",
    "\n",
    "    // Sort centroids by distance ASC\n",
    "    std::sort(centerDists.begin(), centerDists.end());\n",
    "\n",
    "    // Step B: Gather Candidates & Exact Search\n",
    "    // Format: {distance, vector_id}\n",
    "    std::vector<std::pair<float, int>> candidates;\n",
    "    // Heuristic reserve\n",
    "    candidates.reserve((N / K) * NPROBE * 2);\n",
    "\n",
    "    int visitedVecs = 0;\n",
    "    for (int i = 0; i < NPROBE && i < K; ++i) {\n",
    "        int c_id = centerDists[i].second;\n",
    "        const auto& bucket = lists[c_id];\n",
    "        visitedVecs += (int)bucket.size();\n",
    "\n",
    "        for (int vecIdx : bucket) {\n",
    "            // Access raw data directly (Host DRAM)\n",
    "            const float* vec = &h_data[(size_t)vecIdx * DIM];\n",
    "            double dotVal = dot_host(qhost.data(), vec);\n",
    "            float dist = 1.0f - (float)dotVal;\n",
    "            candidates.push_back({dist, vecIdx});\n",
    "        }\n",
    "    }\n",
    "\n",
    "    printf(\"[SEARCH] Scanned %d vectors from top %d clusters.\\n\", visitedVecs, NPROBE);\n",
    "\n",
    "    // Step C: Ranking (Top-K)\n",
    "    if (candidates.empty()) {\n",
    "        printf(\"No candidates found.\\n\");\n",
    "    } else {\n",
    "        int finalK = std::min((int)candidates.size(), TOPK);\n",
    "        \n",
    "        // Use partial_sort like origin.cu\n",
    "        std::partial_sort(candidates.begin(), \n",
    "                          candidates.begin() + finalK, \n",
    "                          candidates.end());\n",
    "\n",
    "        printf(\"\\nTop-%d Results:\\n\", finalK);\n",
    "        for (int i = 0; i < finalK; ++i) {\n",
    "            printf(\"%2d) id=%d  dist=%.6f  sim=%.6f\\n\",\n",
    "                   i+1, candidates[i].second, candidates[i].first, 1.f - candidates[i].first);\n",
    "        }\n",
    "\n",
    "        // Verify with best (optional check)\n",
    "        if (finalK > 0) {\n",
    "            int bestId = candidates[0].second;\n",
    "            const float* vec = &h_data[(size_t)bestId * DIM];\n",
    "            double dotChk = dot_host(qhost.data(), vec);\n",
    "            printf(\"[DEBUG] host check best id=%d  dot=%.9f  dist=%.9f\\n\",\n",
    "                   bestId, dotChk, 1.0 - dotChk);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    end = clock();\n",
    "    double search_time = ((double)(end-start))*1E3/CLOCKS_PER_SEC;\n",
    "    printf(\"Function (Search Phase) time: %f ms\\n\", search_time);\n",
    "\n",
    "    // Cleanup\n",
    "    free(d_data);\n",
    "    free(d_centroids);\n",
    "    free(d_assign);\n",
    "    free(d_sums);\n",
    "    free(d_counts);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d8b8518-6fc4-4936-b472-2b8bc8741fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "g++ -std=c++11 kmean_cpu.cpp -o kmean_cpu -lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d632baf9-9c20-41f1-a5d0-71d2c152a8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "./kmean_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b821c5d-97f0-4962-92bf-95485999cecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kmean_gpu_share_mem.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile kmean_gpu_share_mem.cu\n",
    "\n",
    "#include <cuda_runtime.h>\n",
    "#include <cstdio>\n",
    "#include <vector>\n",
    "#include <random>\n",
    "#include <algorithm>\n",
    "#include <numeric>\n",
    "#include <cmath>\n",
    "#include <cassert>\n",
    "#include <cfloat>\n",
    "\n",
    "// ---------------- Config ----------------\n",
    "static const int DIM          = 64;\n",
    "static const float ALPHA      = 0.7f;\n",
    "static const int SEED         = 2025; \n",
    "static const int N            = 1 << 24; // 1 Million vectors\n",
    "static const int K            = 1024;    // Clusters\n",
    "static const int NPROBE       = 32;      // Search depth\n",
    "static const int TOPK         = 5;\n",
    "static const int KMEANS_ITERS = 15;      // K-Means iterations\n",
    "\n",
    "\n",
    "\n",
    "#define TILE_K 128 \n",
    "using Vec = std::vector<float>;\n",
    "                                  \n",
    "\n",
    "// ---------------- Embedding Generator ----------------\n",
    "static Vec numberBase[76]; \n",
    "static Vec posBase[25];    \n",
    "\n",
    "static void normInPlace(Vec &v) {\n",
    "    double s = 0;\n",
    "    for (float x : v) s += (double)x * x;\n",
    "    float n = float(std::sqrt(s) + 1e-12);\n",
    "    for (float &x : v) x /= n;\n",
    "}\n",
    "\n",
    "static Vec randUnit(std::mt19937 &rng) {\n",
    "    std::uniform_real_distribution<float> U(-1.f, 1.f);\n",
    "    Vec v(DIM);\n",
    "    for (int i = 0; i < DIM; i++) v[i] = U(rng);\n",
    "    normInPlace(v);\n",
    "    return v;\n",
    "}\n",
    "\n",
    "static void initBases() {\n",
    "    std::mt19937 rng(SEED);\n",
    "    for (int n = 1; n <= 75; n++) numberBase[n] = randUnit(rng);\n",
    "    for (int i = 0; i < 25; i++)  posBase[i]    = randUnit(rng);\n",
    "}\n",
    "\n",
    "static Vec cardToVec(const int card[25]) {\n",
    "    Vec out(DIM, 0.f);\n",
    "    for (int i = 0; i < 25; i++) {\n",
    "        int n = card[i];\n",
    "        const Vec &b = numberBase[n];\n",
    "        const Vec &p = posBase[i];\n",
    "        for (int j = 0; j < DIM; j++)\n",
    "            out[j] += b[j] + ALPHA * p[j];\n",
    "    }\n",
    "    normInPlace(out);\n",
    "    return out;\n",
    "}\n",
    "\n",
    "static void genCard(std::mt19937 &rng, int out[25]) {\n",
    "    std::vector<int> p(75);\n",
    "    std::iota(p.begin(), p.end(), 1);\n",
    "    std::shuffle(p.begin(), p.end(), rng);\n",
    "    for (int i = 0; i < 25; i++) out[i] = p[i];\n",
    "}\n",
    "\n",
    "static double dot_host(const float* a, const float* b) {\n",
    "    double s = 0;\n",
    "    for (int i = 0; i < DIM; i++) s += (double)a[i] * b[i];\n",
    "    return s;\n",
    "}\n",
    "\n",
    "// ---------------- GPU K-Means Kernels (Optimized) ----------------\n",
    "\n",
    "// E-Step:\n",
    "// 1. Tiled Shared Memory loading for Centroids.\n",
    "// 2. Per-Block Accumulation.\n",
    "__global__ void assignAndAccumulatePerBlockKernel(\n",
    "                                         const float* data, int N,\n",
    "                                         const float* centroids, int K,\n",
    "                                         int* assign,\n",
    "                                         double* block_sums,   // Output: (GridSize * K * DIM)\n",
    "                                         int* block_counts) {  // Output: (GridSize * K)\n",
    "    \n",
    "    // Shared memory buffer to cache a tile of centroids\n",
    "    __shared__ float sh_centroids[TILE_K * DIM];\n",
    "    \n",
    "    // Offsets for this specific block's accumulation buffer in global memory\n",
    "    size_t block_sum_base = (size_t)blockIdx.x * (size_t)K * DIM;\n",
    "    size_t block_count_base = (size_t)blockIdx.x * (size_t)K;\n",
    "\n",
    "    // Grid-Stride Loop\n",
    "    for (int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "         i < N;\n",
    "         i += gridDim.x * blockDim.x) {\n",
    "\n",
    "        const float* xi = data + (size_t)i * DIM;\n",
    "\n",
    "        int bestC = 0;\n",
    "        float bestD = 1e30f;\n",
    "        \n",
    "        // Loop over Centroids in chunks (Tiles)\n",
    "        for (int k_tile = 0; k_tile < K; k_tile += TILE_K) {\n",
    "            \n",
    "            // --- Phase 1: Load Tile into Shared Memory ---\n",
    "            int k_start = k_tile;\n",
    "            \n",
    "            // Cooperative loading: threads load distinct floats\n",
    "            for (int t = threadIdx.x; t < TILE_K * DIM; t += blockDim.x) {\n",
    "                int local_c = t / DIM;\n",
    "                int local_d = t % DIM;\n",
    "                int global_c = k_start + local_c;\n",
    "                \n",
    "                if (global_c < K) {\n",
    "                    sh_centroids[t] = centroids[(size_t)global_c * DIM + local_d];\n",
    "                } else {\n",
    "                    sh_centroids[t] = 0.0f; // Padding\n",
    "                }\n",
    "            }\n",
    "            __syncthreads(); // Wait for tile load to complete\n",
    "            \n",
    "            // --- Phase 2: Compute Distances against Tile ---\n",
    "            int k_limit = (k_tile + TILE_K > K) ? (K - k_tile) : TILE_K;\n",
    "\n",
    "            for (int c_local = 0; c_local < k_limit; ++c_local) {\n",
    "                int c_global = k_start + c_local;\n",
    "                \n",
    "                float dot = 0.f;\n",
    "                \n",
    "                for (int d = 0; d < DIM; ++d) {\n",
    "                    dot += xi[d] * sh_centroids[c_local * DIM + d];\n",
    "                }\n",
    "                \n",
    "                float dist = 1.f - dot;\n",
    "                if (dist < bestD) {\n",
    "                    bestD = dist;\n",
    "                    bestC = c_global;\n",
    "                }\n",
    "            }\n",
    "            __syncthreads(); // Sync before loading next tile\n",
    "        }\n",
    "\n",
    "        assign[i] = bestC;\n",
    "\n",
    "        // --- Accumulation ---\n",
    "        // We atomicAdd to THIS block's specific buffer.\n",
    "        atomicAdd(&block_counts[block_count_base + bestC], 1);\n",
    "\n",
    "        size_t cluster_base = block_sum_base + (size_t)bestC * DIM;\n",
    "        for (int d = 0; d < DIM; ++d) {\n",
    "            atomicAdd(&block_sums[cluster_base + d], (double)xi[d]);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void reduceSumsKernel(double* final_sums, \n",
    "                                 int* final_counts, \n",
    "                                 const double* block_sums, \n",
    "                                 const int* block_counts, \n",
    "                                 int K, int GridSize) {\n",
    "    \n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    // Reduce Counts: 1 thread per cluster\n",
    "    if (idx < K) {\n",
    "        int total_cnt = 0;\n",
    "        for (int b = 0; b < GridSize; ++b) {\n",
    "            total_cnt += block_counts[(size_t)b * K + idx];\n",
    "        }\n",
    "        final_counts[idx] = total_cnt;\n",
    "    }\n",
    "    \n",
    "    // Reduce Sums\n",
    "    size_t total_elements = (size_t)K * DIM;\n",
    "    for (size_t i = idx; i < total_elements; i += gridDim.x * blockDim.x) {\n",
    "        double total_sum = 0.0;\n",
    "        for (int b = 0; b < GridSize; ++b) {\n",
    "            total_sum += block_sums[(size_t)b * total_elements + i];\n",
    "        }\n",
    "        final_sums[i] = total_sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "// M-step: Update centroids\n",
    "__global__ void updateCentroidsKernel(float* centroids,\n",
    "                                      const double* sums, \n",
    "                                      const int* counts,\n",
    "                                      int K) {\n",
    "    int c = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (c >= K) return;\n",
    "\n",
    "    int cnt = counts[c];\n",
    "    float* ctr = centroids + (size_t)c * DIM;\n",
    "    const double* sumc = sums + (size_t)c * DIM; \n",
    "\n",
    "    if (cnt > 0) {\n",
    "        double norm2 = 0.0;\n",
    "        for (int d = 0; d < DIM; ++d) {\n",
    "            double v_double = sumc[d] / (double)cnt; // Mean\n",
    "            float v = (float)v_double;\n",
    "            ctr[d] = v;\n",
    "            norm2 += v_double * v_double;\n",
    "        }\n",
    "        // Normalize\n",
    "        float n = float(std::sqrt(norm2) + 1e-12);\n",
    "        for (int d = 0; d < DIM; ++d) {\n",
    "            ctr[d] /= n;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// ---------------- Host Helpers ----------------\n",
    "\n",
    "static void buildInvertedLists(\n",
    "    const std::vector<int>& assign,\n",
    "    int N, int K,\n",
    "    std::vector<std::vector<int>>& lists\n",
    ") {\n",
    "    lists.assign(K, {});\n",
    "    for (int i = 0; i < N; ++i) {\n",
    "        int c = assign[i];\n",
    "        if (c >= 0 && c < K) {\n",
    "            lists[c].push_back(i);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// ---------------- Main ----------------\n",
    "int main() {\n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, 0);\n",
    "\n",
    "    const int threads = 256;\n",
    "    const int SMs     = prop.multiProcessorCount;\n",
    "\n",
    "    int maxBlocksForN = (N + threads - 1) / threads;\n",
    "    int maxBlocksHW   = SMs * 32;\n",
    "    int blocksN       = std::min(maxBlocksForN, maxBlocksHW);\n",
    "\n",
    "    dim3 block(threads);\n",
    "    dim3 gridN(blocksN);\n",
    "    int GridSize = gridN.x;\n",
    "\n",
    "    dim3 gridReduce((K * DIM + threads - 1) / threads);\n",
    "    dim3 gridUpdate((K       + threads - 1) / threads);\n",
    "\n",
    "    printf(\"Params: N=%d  K=%d  DIM=%d  SMs=%d threads=%d gridN=%d\\n\",\n",
    "           N, K, DIM, SMs, threads, GridSize);\n",
    "\n",
    "    initBases();\n",
    "    std::mt19937 rng(SEED + 7);\n",
    "\n",
    "    // 1) Data Generation\n",
    "    std::vector<int>  h_cards((size_t)N * 25);\n",
    "    std::vector<float> h_data((size_t)N * DIM);\n",
    "    printf(\"[INIT] Generating %d vectors...\\n\", N);\n",
    "    \n",
    "    for (int i = 0; i < N; i++) {\n",
    "        int c[25]; genCard(rng, c);\n",
    "        for (int t = 0; t < 25; ++t) h_cards[(size_t)i * 25 + t] = c[t];\n",
    "        Vec v = cardToVec(c);\n",
    "        for (int d = 0; d < DIM; ++d) h_data[(size_t)i * DIM + d] = v[d];\n",
    "    }\n",
    "\n",
    "    // 2) Build Query\n",
    "    int qc[25];\n",
    "    for (int t = 0; t < 25; ++t) qc[t] = h_cards[t]; \n",
    "    qc[3] = 75; qc[17] = 1; std::swap(qc[5], qc[19]); \n",
    "    Vec qvec = cardToVec(qc);\n",
    "    std::vector<float> q_host(qvec.begin(), qvec.end());\n",
    "\n",
    "    {\n",
    "        double dot0 = dot_host(q_host.data(), &h_data[0]);\n",
    "        printf(\"[DEBUG] Query vs Data[0]: dot=%.9f dist=%.9f\\n\", dot0, 1.0 - dot0);\n",
    "    }\n",
    "\n",
    "    // 3) GPU Allocations\n",
    "    float *d_data = 0, *d_centroids = 0;\n",
    "    int   *d_assign = 0;\n",
    "\n",
    "    // Final Buffers\n",
    "    double *d_sums_final = 0; \n",
    "    int    *d_counts_final = 0;\n",
    "    \n",
    "    // Temporary Block Buffers\n",
    "    double *d_block_sums = 0;\n",
    "    int    *d_block_counts = 0;\n",
    "\n",
    "    size_t szBlockSums   = (size_t)GridSize * K * DIM * sizeof(double);\n",
    "    size_t szBlockCounts = (size_t)GridSize * K * sizeof(int);\n",
    "\n",
    "    cudaMalloc(&d_data,      (size_t)N * DIM * sizeof(float));\n",
    "    cudaMalloc(&d_centroids, (size_t)K * DIM * sizeof(float));\n",
    "    cudaMalloc(&d_assign,    N * sizeof(int));\n",
    "    \n",
    "    cudaMalloc(&d_sums_final,   (size_t)K * DIM * sizeof(double));\n",
    "    cudaMalloc(&d_counts_final, K * sizeof(int));\n",
    "    \n",
    "    cudaMalloc(&d_block_sums,   szBlockSums);\n",
    "    cudaMalloc(&d_block_counts, szBlockCounts);\n",
    "\n",
    "    // Copy Data\n",
    "    cudaMemcpy(d_data, h_data.data(), (size_t)N * DIM * sizeof(float), cudaMemcpyHostToDevice);\n",
    "\n",
    "    // 4) Initialize Centroids\n",
    "    {\n",
    "        std::vector<int> idx(N);\n",
    "        std::iota(idx.begin(), idx.end(), 0);\n",
    "        std::shuffle(idx.begin(), idx.end(), rng);\n",
    "        std::vector<float> h_initC((size_t)K * DIM);\n",
    "        for (int c = 0; c < K; ++c) {\n",
    "            int i = idx[c];\n",
    "            std::copy_n(&h_data[(size_t)i * DIM], DIM, &h_initC[(size_t)c * DIM]);\n",
    "        }\n",
    "        cudaMemcpy(d_centroids, h_initC.data(), (size_t)K * DIM * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    }\n",
    "\n",
    "    // 5) GPU K-Means Training Loop\n",
    "    printf(\"[TRAIN] Starting K-Means (%d iters)...\\n\", KMEANS_ITERS);\n",
    "    \n",
    "    for (int it = 0; it < KMEANS_ITERS; ++it) {\n",
    "        // A. Clear Block Accumulators\n",
    "        cudaMemset(d_block_sums,   0, szBlockSums);\n",
    "        cudaMemset(d_block_counts, 0, szBlockCounts);\n",
    "        \n",
    "        // B. E-Step\n",
    "        assignAndAccumulatePerBlockKernel<<<gridN, block>>>(\n",
    "            d_data, N, d_centroids, K, d_assign, d_block_sums, d_block_counts\n",
    "        );\n",
    "        \n",
    "        // C. Reduction\n",
    "        reduceSumsKernel<<<gridReduce, block>>>(\n",
    "            d_sums_final, d_counts_final, d_block_sums, d_block_counts, K, GridSize\n",
    "        );\n",
    "        \n",
    "        // D. M-Step\n",
    "        updateCentroidsKernel<<<gridUpdate, block>>>(\n",
    "            d_centroids, d_sums_final, d_counts_final, K\n",
    "        );\n",
    "        cudaDeviceSynchronize();\n",
    "    }\n",
    "    printf(\"[TRAIN] Done.\\n\");\n",
    "\n",
    "    // 6) Retrieve Results\n",
    "    std::vector<int> h_assign(N);\n",
    "    cudaMemcpy(h_assign.data(), d_assign, N * sizeof(int), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    std::vector<float> h_finalCentroids(K * DIM);\n",
    "    cudaMemcpy(h_finalCentroids.data(), d_centroids, (size_t)K * DIM * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // Cleanup GPU\n",
    "    cudaFree(d_data); cudaFree(d_centroids); cudaFree(d_assign);\n",
    "    cudaFree(d_sums_final); cudaFree(d_counts_final);\n",
    "    cudaFree(d_block_sums); cudaFree(d_block_counts);\n",
    "\n",
    "    // 7) Build Host Index\n",
    "    printf(\"[INDEX] Building Inverted Lists...\\n\");\n",
    "    std::vector<std::vector<int>> lists;\n",
    "    buildInvertedLists(h_assign, N, K, lists);\n",
    "\n",
    "    int nonEmpty = 0;\n",
    "    for(const auto& list : lists) if(!list.empty()) nonEmpty++;\n",
    "    printf(\"[INDEX] Non-empty clusters: %d / %d\\n\", nonEmpty, K);\n",
    "    \n",
    "    if (nonEmpty < K * 0.1) {\n",
    "        printf(\"WARNING: Too many empty clusters! Check initialization or data distribution.\\n\");\n",
    "    }\n",
    "\n",
    "    // 8) CPU Search\n",
    "    printf(\"\\n[SEARCH] CPU Search (nprobe=%d)...\\n\", NPROBE);\n",
    "\n",
    "    // Coarse Search\n",
    "    std::vector<std::pair<float, int>> centerDists;\n",
    "    centerDists.reserve(K);\n",
    "    for (int c = 0; c < K; ++c) {\n",
    "        const float* ctr = &h_finalCentroids[(size_t)c * DIM];\n",
    "        double dotVal = dot_host(q_host.data(), ctr);\n",
    "        float dist = 1.0f - (float)dotVal;\n",
    "        centerDists.push_back({dist, c});\n",
    "    }\n",
    "    std::sort(centerDists.begin(), centerDists.end(), \n",
    "              [](const std::pair<float, int>& a, const std::pair<float, int>& b){\n",
    "                  return a.first < b.first;\n",
    "              });\n",
    "\n",
    "    // Fine Search\n",
    "    std::vector<std::pair<float, int>> candidates;\n",
    "    candidates.reserve((N / K) * NPROBE * 2);\n",
    "\n",
    "    int visitedVecs = 0;\n",
    "    for (int i = 0; i < NPROBE && i < K; ++i) {\n",
    "        int c_id = centerDists[i].second;\n",
    "        const auto& bucket = lists[c_id];\n",
    "        visitedVecs += bucket.size();\n",
    "\n",
    "        for (int vecIdx : bucket) {\n",
    "            const float* vec = &h_data[(size_t)vecIdx * DIM];\n",
    "            double dotVal = dot_host(q_host.data(), vec);\n",
    "            float dist = 1.0f - (float)dotVal;\n",
    "            candidates.push_back({dist, vecIdx});\n",
    "        }\n",
    "    }\n",
    "    printf(\"[SEARCH] Scanned %d vectors.\\n\", visitedVecs);\n",
    "\n",
    "    // Top-K\n",
    "    if (candidates.empty()) {\n",
    "        printf(\"No candidates found.\\n\");\n",
    "    } else {\n",
    "        int finalK = std::min((int)candidates.size(), TOPK);\n",
    "        std::partial_sort(candidates.begin(), \n",
    "                          candidates.begin() + finalK, \n",
    "                          candidates.end(),\n",
    "                          [](const std::pair<float, int>& a, const std::pair<float, int>& b){\n",
    "                              return a.first < b.first;\n",
    "                          });\n",
    "\n",
    "        printf(\"\\nTop-%d Results:\\n\", finalK);\n",
    "        for (int i = 0; i < finalK; ++i) {\n",
    "            printf(\"%2d) id=%d  dist=%.6f  sim=%.6f\\n\",\n",
    "                   i+1, candidates[i].second, candidates[i].first, 1.f - candidates[i].first);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d28c189-897a-41c3-bcff-7dac5a992699",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc -O3 -std=c++17 -arch=sm_70 kmean_gpu_share_mem.cu -o kmean_gpu_share_mem -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce70cc62-ebf6-469c-a10f-6e4a51189a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==3944== NVPROF is profiling process 3944, command: ./kmean_gpu_share_mem\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: N=16777216  K=1024  DIM=64  SMs=80 threads=256 gridN=2560\n",
      "[INIT] Generating 16777216 vectors...\n",
      "[DEBUG] Query vs Data[0]: dot=0.927471359 dist=0.072528641\n",
      "[TRAIN] Starting K-Means (15 iters)...\n",
      "[TRAIN] Done.\n",
      "[INDEX] Building Inverted Lists...\n",
      "[INDEX] Non-empty clusters: 1024 / 1024\n",
      "\n",
      "[SEARCH] CPU Search (nprobe=32)...\n",
      "[SEARCH] Scanned 557460 vectors.\n",
      "\n",
      "Top-5 Results:\n",
      " 1) id=0  dist=0.072529  sim=0.927471\n",
      " 2) id=15528589  dist=0.136097  sim=0.863903\n",
      " 3) id=13929498  dist=0.139304  sim=0.860696\n",
      " 4) id=8185180  dist=0.146311  sim=0.853689\n",
      " 5) id=16494452  dist=0.150325  sim=0.849675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==3944== Profiling application: ./kmean_gpu_share_mem\n",
      "==3944== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   77.62%  4.50354s        15  300.24ms  298.14ms  320.97ms  assignAndAccumulatePerBlockKernel(float const *, int, float const *, int, int*, double*, int*)\n",
      "                   21.07%  1.22258s         2  611.29ms  23.616us  1.22256s  [CUDA memcpy HtoD]\n",
      "                    0.46%  26.424ms         2  13.212ms  27.744us  26.397ms  [CUDA memcpy DtoH]\n",
      "                    0.44%  25.814ms        15  1.7209ms  1.7109ms  1.7308ms  reduceSumsKernel(double*, int*, double const *, int const *, int, int)\n",
      "                    0.39%  22.752ms        30  758.41us  13.312us  1.5167ms  [CUDA memset]\n",
      "                    0.02%  938.21us        15  62.547us  62.080us  63.968us  updateCentroidsKernel(float*, double const *, int const *, int)\n",
      "      API calls:   74.34%  4.55117s        15  303.41ms  301.42ms  322.74ms  cudaDeviceSynchronize\n",
      "                   20.42%  1.24994s         4  312.49ms  106.83us  1.22280s  cudaMemcpy\n",
      "                    5.09%  311.74ms         7  44.534ms  2.2890us  311.21ms  cudaMalloc\n",
      "                    0.07%  4.1814ms         7  597.35us  5.7080us  2.9454ms  cudaFree\n",
      "                    0.03%  1.9986ms        45  44.414us  4.8920us  1.5866ms  cudaLaunchKernel\n",
      "                    0.03%  1.8789ms       114  16.481us     216ns  1.4741ms  cuDeviceGetAttribute\n",
      "                    0.01%  812.88us        30  27.095us  6.5030us  121.03us  cudaMemset\n",
      "                    0.00%  271.07us         1  271.07us  271.07us  271.07us  cudaGetDeviceProperties\n",
      "                    0.00%  28.083us         1  28.083us  28.083us  28.083us  cuDeviceGetName\n",
      "                    0.00%  9.9340us         1  9.9340us  9.9340us  9.9340us  cuDeviceTotalMem\n",
      "                    0.00%  2.5440us         1  2.5440us  2.5440us  2.5440us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.2130us         3     737ns     233ns  1.6410us  cuDeviceGetCount\n",
      "                    0.00%     952ns         2     476ns     251ns     701ns  cuDeviceGet\n",
      "                    0.00%     482ns         1     482ns     482ns     482ns  cuDeviceGetUuid\n",
      "                    0.00%     430ns         1     430ns     430ns     430ns  cuModuleGetLoadingMode\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./kmean_gpu_share_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac72881a-d276-4d2d-a526-a6762d90d139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kmean_gpu_simple_managed.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile kmean_gpu_simple_managed.cu\n",
    "\n",
    "#include <cuda_runtime.h>\n",
    "#include <cstdio>\n",
    "#include <vector>\n",
    "#include <random>\n",
    "#include <algorithm>\n",
    "#include <numeric>\n",
    "#include <cmath>\n",
    "#include <cassert>\n",
    "#include <cfloat>\n",
    "\n",
    "// ---------------- Config ----------------\n",
    "static const int DIM          = 64;\n",
    "static const float ALPHA      = 0.7f;\n",
    "static const int SEED         = 2025; \n",
    "static const int N            = 1 << 20; // ~16.7 Million vectors\n",
    "static const int K            = 1024;    // Clusters\n",
    "static const int NPROBE       = 32;      // Search depth\n",
    "static const int TOPK         = 5;\n",
    "static const int KMEANS_ITERS = 15;      // K-Means iterations\n",
    "\n",
    "#define TILE_K 128 \n",
    "using Vec = std::vector<float>;\n",
    "\n",
    "\n",
    "// ---------------- Embedding Generator ----------------\n",
    "static Vec numberBase[76]; \n",
    "static Vec posBase[25];    \n",
    "\n",
    "static void normInPlace(Vec &v) {\n",
    "    double s = 0;\n",
    "    for (float x : v) s += (double)x * x;\n",
    "    float n = float(std::sqrt(s) + 1e-12);\n",
    "    for (float &x : v) x /= n;\n",
    "}\n",
    "\n",
    "static Vec randUnit(std::mt19937 &rng) {\n",
    "    std::uniform_real_distribution<float> U(-1.f, 1.f);\n",
    "    Vec v(DIM);\n",
    "    for (int i = 0; i < DIM; i++) v[i] = U(rng);\n",
    "    normInPlace(v);\n",
    "    return v;\n",
    "}\n",
    "\n",
    "static void initBases() {\n",
    "    std::mt19937 rng(SEED);\n",
    "    for (int n = 1; n <= 75; n++) numberBase[n] = randUnit(rng);\n",
    "    for (int i = 0; i < 25; i++)  posBase[i]    = randUnit(rng);\n",
    "}\n",
    "\n",
    "static Vec cardToVec(const int card[25]) {\n",
    "    Vec out(DIM, 0.f);\n",
    "    for (int i = 0; i < 25; i++) {\n",
    "        int n = card[i];\n",
    "        const Vec &b = numberBase[n];\n",
    "        const Vec &p = posBase[i];\n",
    "        for (int j = 0; j < DIM; j++)\n",
    "            out[j] += b[j] + ALPHA * p[j];\n",
    "    }\n",
    "    normInPlace(out);\n",
    "    return out;\n",
    "}\n",
    "\n",
    "static void genCard(std::mt19937 &rng, int out[25]) {\n",
    "    std::vector<int> p(75);\n",
    "    std::iota(p.begin(), p.end(), 1);\n",
    "    std::shuffle(p.begin(), p.end(), rng);\n",
    "    for (int i = 0; i < 25; i++) out[i] = p[i];\n",
    "}\n",
    "\n",
    "static double dot_host(const float* a, const float* b) {\n",
    "    double s = 0;\n",
    "    for (int i = 0; i < DIM; i++) s += (double)a[i] * b[i];\n",
    "    return s;\n",
    "}\n",
    "\n",
    "// ---------------- GPU K-Means Kernels ----------------\n",
    "\n",
    "// E-Step\n",
    "__global__ void assignAndAccumulatePerBlockKernel(\n",
    "                                         const float* data, int n_points,\n",
    "                                         const float* centroids, int k_clusters,\n",
    "                                         int* assign,\n",
    "                                         double* block_sums,   \n",
    "                                         int* block_counts) {\n",
    "    \n",
    "    __shared__ float sh_centroids[TILE_K * DIM];\n",
    "    \n",
    "    size_t block_sum_base = (size_t)blockIdx.x * (size_t)k_clusters * DIM;\n",
    "    size_t block_count_base = (size_t)blockIdx.x * (size_t)k_clusters;\n",
    "\n",
    "    for (int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "         i < n_points;\n",
    "         i += gridDim.x * blockDim.x) {\n",
    "\n",
    "        const float* xi = data + (size_t)i * DIM;\n",
    "        int bestC = 0;\n",
    "        float bestD = 1e30f;\n",
    "        \n",
    "        for (int k_tile = 0; k_tile < k_clusters; k_tile += TILE_K) {\n",
    "            int k_start = k_tile;\n",
    "            \n",
    "            // Phase 1: Load Tile\n",
    "            for (int t = threadIdx.x; t < TILE_K * DIM; t += blockDim.x) {\n",
    "                int local_c = t / DIM;\n",
    "                int local_d = t % DIM;\n",
    "                int global_c = k_start + local_c;\n",
    "                if (global_c < k_clusters) {\n",
    "                    sh_centroids[t] = centroids[(size_t)global_c * DIM + local_d];\n",
    "                } else {\n",
    "                    sh_centroids[t] = 0.0f; \n",
    "                }\n",
    "            }\n",
    "            __syncthreads(); \n",
    "            \n",
    "            // Phase 2: Compute\n",
    "            int k_limit = (k_tile + TILE_K > k_clusters) ? (k_clusters - k_tile) : TILE_K;\n",
    "\n",
    "            for (int c_local = 0; c_local < k_limit; ++c_local) {\n",
    "                int c_global = k_start + c_local;\n",
    "                float dot = 0.f;\n",
    "                for (int d = 0; d < DIM; ++d) {\n",
    "                    dot += xi[d] * sh_centroids[c_local * DIM + d];\n",
    "                }\n",
    "                float dist = 1.f - dot;\n",
    "                if (dist < bestD) {\n",
    "                    bestD = dist;\n",
    "                    bestC = c_global;\n",
    "                }\n",
    "            }\n",
    "            __syncthreads(); \n",
    "        }\n",
    "\n",
    "        assign[i] = bestC;\n",
    "\n",
    "        // Atomic Add (Native double support)\n",
    "        atomicAdd(&block_counts[block_count_base + bestC], 1);\n",
    "        size_t cluster_base = block_sum_base + (size_t)bestC * DIM;\n",
    "        for (int d = 0; d < DIM; ++d) {\n",
    "            atomicAdd(&block_sums[cluster_base + d], (double)xi[d]);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// Reduce Step\n",
    "__global__ void reduceSumsKernel(double* final_sums, \n",
    "                                 int* final_counts, \n",
    "                                 const double* block_sums, \n",
    "                                 const int* block_counts, \n",
    "                                 int k_clusters, int GridSize) {\n",
    "    \n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    if (idx < k_clusters) {\n",
    "        int total_cnt = 0;\n",
    "        for (int b = 0; b < GridSize; ++b) {\n",
    "            total_cnt += block_counts[(size_t)b * k_clusters + idx];\n",
    "        }\n",
    "        final_counts[idx] = total_cnt;\n",
    "    }\n",
    "    \n",
    "    size_t total_elements = (size_t)k_clusters * DIM;\n",
    "    for (size_t i = idx; i < total_elements; i += gridDim.x * blockDim.x) {\n",
    "        double total_sum = 0.0;\n",
    "        for (int b = 0; b < GridSize; ++b) {\n",
    "            total_sum += block_sums[(size_t)b * total_elements + i];\n",
    "        }\n",
    "        final_sums[i] = total_sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "// M-Step\n",
    "__global__ void updateCentroidsKernel(float* centroids,\n",
    "                                      const double* sums, \n",
    "                                      const int* counts,\n",
    "                                      int k_clusters) {\n",
    "    int c = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (c >= k_clusters) return;\n",
    "\n",
    "    int cnt = counts[c];\n",
    "    float* ctr = centroids + (size_t)c * DIM;\n",
    "    const double* sumc = sums + (size_t)c * DIM; \n",
    "\n",
    "    if (cnt > 0) {\n",
    "        double norm2 = 0.0;\n",
    "        for (int d = 0; d < DIM; ++d) {\n",
    "            double v_double = sumc[d] / (double)cnt; \n",
    "            float v = (float)v_double;\n",
    "            ctr[d] = v;\n",
    "            norm2 += v_double * v_double;\n",
    "        }\n",
    "        float n = float(std::sqrt(norm2) + 1e-12);\n",
    "        for (int d = 0; d < DIM; ++d) {\n",
    "            ctr[d] /= n;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// ---------------- Host Helpers ----------------\n",
    "\n",
    "static void buildInvertedLists(\n",
    "    const int* assign, // Managed pointer\n",
    "    int n_points, int k_clusters,\n",
    "    std::vector<std::vector<int>>& lists\n",
    ") {\n",
    "    lists.assign(k_clusters, {});\n",
    "    for (int i = 0; i < n_points; ++i) {\n",
    "        int c = assign[i];\n",
    "        if (c >= 0 && c < k_clusters) {\n",
    "            lists[c].push_back(i);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// ---------------- Main ----------------\n",
    "int main() {\n",
    "    int deviceId = 0;\n",
    "    cudaGetDevice(&deviceId);\n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, deviceId);\n",
    "\n",
    "    const int threads = 256;\n",
    "    const int SMs     = prop.multiProcessorCount;\n",
    "    int maxBlocksForN = (N + threads - 1) / threads;\n",
    "    int maxBlocksHW   = SMs * 32;\n",
    "    int blocksN       = std::min(maxBlocksForN, maxBlocksHW);\n",
    "\n",
    "    dim3 block(threads);\n",
    "    dim3 gridN(blocksN);\n",
    "    int GridSize = gridN.x;\n",
    "\n",
    "    dim3 gridReduce((K * DIM + threads - 1) / threads);\n",
    "    dim3 gridUpdate((K       + threads - 1) / threads);\n",
    "\n",
    "    printf(\"Params: N=%d  K=%d  DIM=%d  GridSize=%d (Simple Managed Mode)\\n\", N, K, DIM, GridSize);\n",
    "\n",
    "    initBases();\n",
    "    std::mt19937 rng(SEED + 7);\n",
    "\n",
    "    float *data, *centroids;\n",
    "    int   *assign;\n",
    "    double *sums_final, *block_sums;\n",
    "    int    *counts_final, *block_counts;\n",
    "\n",
    "    size_t szData        = (size_t)N * DIM * sizeof(float);\n",
    "    size_t szCentroids   = (size_t)K * DIM * sizeof(float);\n",
    "    size_t szAssign      = (size_t)N * sizeof(int);\n",
    "    size_t szBlockSums   = (size_t)GridSize * K * DIM * sizeof(double);\n",
    "    size_t szBlockCounts = (size_t)GridSize * K * sizeof(int);\n",
    "    size_t szFinalSums   = (size_t)K * DIM * sizeof(double);\n",
    "    size_t szFinalCounts = (size_t)K * sizeof(int);\n",
    "\n",
    "    cudaMallocManaged(&data,      szData);\n",
    "    cudaMallocManaged(&centroids, szCentroids);\n",
    "    cudaMallocManaged(&assign,    szAssign);\n",
    "    cudaMallocManaged(&sums_final,   szFinalSums);\n",
    "    cudaMallocManaged(&counts_final, szFinalCounts);\n",
    "    cudaMallocManaged(&block_sums,   szBlockSums);\n",
    "    cudaMallocManaged(&block_counts, szBlockCounts);\n",
    "\n",
    "    std::vector<int> h_cards_sample((size_t)N * 25); \n",
    "\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        int c[25]; genCard(rng, c);\n",
    "        for(int t=0; t<25; ++t) h_cards_sample[(size_t)i*25 + t] = c[t];\n",
    "        Vec v = cardToVec(c);\n",
    "        for (int d = 0; d < DIM; ++d) data[(size_t)i * DIM + d] = v[d];\n",
    "    }\n",
    "\n",
    "    int qc[25];\n",
    "    for (int t = 0; t < 25; ++t) qc[t] = h_cards_sample[t]; \n",
    "    qc[3] = 75; qc[17] = 1; std::swap(qc[5], qc[19]); \n",
    "    Vec qvec = cardToVec(qc);\n",
    "    std::vector<float> q_host(qvec.begin(), qvec.end());\n",
    "\n",
    "    {\n",
    "        std::vector<int> idx(N);\n",
    "        std::iota(idx.begin(), idx.end(), 0);\n",
    "        std::shuffle(idx.begin(), idx.end(), rng);\n",
    "        for (int c = 0; c < K; ++c) {\n",
    "            int src_i = idx[c];\n",
    "            for(int d=0; d<DIM; ++d) {\n",
    "                centroids[(size_t)c * DIM + d] = data[(size_t)src_i * DIM + d];\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    printf(\"[OPTIM] Prefetching to GPU...\\n\");\n",
    "    cudaMemAdvise(data, szData, cudaMemAdviseSetReadMostly, deviceId);\n",
    "\n",
    "    cudaMemPrefetchAsync(data,      szData,      deviceId, 0);\n",
    "    cudaMemPrefetchAsync(centroids, szCentroids, deviceId, 0);\n",
    "    cudaMemPrefetchAsync(assign,    szAssign,    deviceId, 0);\n",
    "    \n",
    "    cudaMemPrefetchAsync(block_sums,   szBlockSums,   deviceId, 0);\n",
    "    cudaMemPrefetchAsync(block_counts, szBlockCounts, deviceId, 0);\n",
    "    cudaMemPrefetchAsync(sums_final,   szFinalSums,   deviceId, 0);\n",
    "    cudaMemPrefetchAsync(counts_final, szFinalCounts, deviceId, 0);\n",
    "\n",
    "    printf(\"[TRAIN] Starting K-Means (%d iters)...\\n\", KMEANS_ITERS);\n",
    "    \n",
    "    for (int it = 0; it < KMEANS_ITERS; ++it) {\n",
    "        cudaMemsetAsync(block_sums, 0, szBlockSums, 0);\n",
    "        cudaMemsetAsync(block_counts, 0, szBlockCounts, 0);\n",
    "        \n",
    "        assignAndAccumulatePerBlockKernel<<<gridN, block>>>(\n",
    "            data, N, centroids, K, assign, block_sums, block_counts\n",
    "        );\n",
    "        \n",
    "        reduceSumsKernel<<<gridReduce, block>>>(\n",
    "            sums_final, counts_final, block_sums, block_counts, K, GridSize\n",
    "        );\n",
    "        \n",
    "        updateCentroidsKernel<<<gridUpdate, block>>>(\n",
    "            centroids, sums_final, counts_final, K\n",
    "        );\n",
    "    }\n",
    "    \n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    printf(\"[TRAIN] Done. Prefetching results to CPU...\\n\");\n",
    "    cudaMemPrefetchAsync(centroids, szCentroids, cudaCpuDeviceId, 0);\n",
    "    cudaMemPrefetchAsync(assign,    szAssign,    cudaCpuDeviceId, 0);\n",
    "    \n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    printf(\"[INDEX] Building Inverted Lists...\\n\");\n",
    "    std::vector<std::vector<int>> lists;\n",
    "    buildInvertedLists(assign, N, K, lists);\n",
    "\n",
    "    int nonEmpty = 0;\n",
    "    for(const auto& list : lists) if(!list.empty()) nonEmpty++;\n",
    "    printf(\"[INDEX] Non-empty clusters: %d / %d\\n\", nonEmpty, K);\n",
    "\n",
    "    printf(\"\\n[SEARCH] CPU Search (nprobe=%d)...\\n\", NPROBE);\n",
    "\n",
    "    std::vector<std::pair<float, int>> centerDists;\n",
    "    centerDists.reserve(K);\n",
    "    for (int c = 0; c < K; ++c) {\n",
    "        const float* ctr = &centroids[(size_t)c * DIM];\n",
    "        double dotVal = dot_host(q_host.data(), ctr);\n",
    "        centerDists.push_back({1.0f - (float)dotVal, c});\n",
    "    }\n",
    "    std::sort(centerDists.begin(), centerDists.end()); \n",
    "\n",
    "    std::vector<std::pair<float, int>> candidates;\n",
    "    candidates.reserve((N / K) * NPROBE * 2);\n",
    "\n",
    "    int visitedVecs = 0;\n",
    "    for (int i = 0; i < NPROBE && i < K; ++i) {\n",
    "        int c_id = centerDists[i].second;\n",
    "        const auto& bucket = lists[c_id];\n",
    "        visitedVecs += bucket.size();\n",
    "\n",
    "        for (int vecIdx : bucket) {\n",
    "            const float* vec = &data[(size_t)vecIdx * DIM];\n",
    "            double dotVal = dot_host(q_host.data(), vec);\n",
    "            candidates.push_back({1.0f - (float)dotVal, vecIdx});\n",
    "        }\n",
    "    }\n",
    "    printf(\"[SEARCH] Scanned %d vectors.\\n\", visitedVecs);\n",
    "\n",
    "    int finalK = std::min((int)candidates.size(), TOPK);\n",
    "    if (finalK > 0) {\n",
    "        std::partial_sort(candidates.begin(), \n",
    "                          candidates.begin() + finalK, \n",
    "                          candidates.end());\n",
    "        printf(\"\\nTop-%d Results:\\n\", finalK);\n",
    "        for (int i = 0; i < finalK; ++i) {\n",
    "            printf(\"%2d) id=%d  dist=%.6f\\n\",\n",
    "                   i+1, candidates[i].second, candidates[i].first);\n",
    "        }\n",
    "    } else {\n",
    "        printf(\"No candidates found.\\n\");\n",
    "    }\n",
    "\n",
    "    // Cleanup\n",
    "    cudaFree(data); cudaFree(centroids); cudaFree(assign);\n",
    "    cudaFree(sums_final); cudaFree(counts_final);\n",
    "    cudaFree(block_sums); cudaFree(block_counts);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08e16830-77ed-40cb-b9dd-c76bc5a225ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc -O3 -std=c++17 -arch=sm_70 kmean_gpu_simple_managed.cu -o kmean_gpu_simple_managed -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9831f4e7-5b10-4c11-a328-3bcc2f8fa914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==4168== NVPROF is profiling process 4168, command: ./kmean_gpu_simple_managed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: N=1048576  K=1024  DIM=64  GridSize=2560 (Simple Managed Mode)\n",
      "[INIT] Generating data in Managed Memory...\n",
      "[OPTIM] Prefetching to GPU...\n",
      "[TRAIN] Starting K-Means (15 iters)...\n",
      "[TRAIN] Done. Prefetching results to CPU...\n",
      "[INDEX] Building Inverted Lists...\n",
      "[INDEX] Non-empty clusters: 1024 / 1024\n",
      "\n",
      "[SEARCH] CPU Search (nprobe=32)...\n",
      "[SEARCH] Scanned 35228 vectors.\n",
      "\n",
      "Top-5 Results:\n",
      " 1) id=0  dist=0.072529\n",
      " 2) id=89698  dist=0.157913\n",
      " 3) id=913782  dist=0.158968\n",
      " 4) id=350035  dist=0.164414\n",
      " 5) id=284315  dist=0.172628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==4168== Profiling application: ./kmean_gpu_simple_managed\n",
      "==4168== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   86.41%  316.02ms        15  21.068ms  20.014ms  22.191ms  assignAndAccumulatePerBlockKernel(float const *, int, float const *, int, int*, double*, int*)\n",
      "                    7.09%  25.923ms        15  1.7282ms  1.7144ms  1.7418ms  reduceSumsKernel(double*, int*, double const *, int const *, int, int)\n",
      "                    6.23%  22.781ms        30  759.36us  13.439us  1.5140ms  [CUDA memset]\n",
      "                    0.27%  991.61us        15  66.107us  62.239us  69.664us  updateCentroidsKernel(float*, double const *, int const *, int)\n",
      "      API calls:   46.35%  363.93ms         2  181.97ms  9.8450us  363.92ms  cudaDeviceSynchronize\n",
      "                   43.60%  342.30ms         7  48.900ms  10.876us  341.90ms  cudaMallocManaged\n",
      "                    4.39%  34.432ms        45  765.15us  3.2710us  34.250ms  cudaLaunchKernel\n",
      "                    2.49%  19.567ms         1  19.567ms  19.567ms  19.567ms  cudaMemAdvise\n",
      "                    2.03%  15.925ms         7  2.2750ms  18.348us  8.5947ms  cudaFree\n",
      "                    1.03%  8.0946ms         9  899.40us  3.4180us  6.0262ms  cudaMemPrefetchAsync\n",
      "                    0.04%  293.09us       114  2.5700us     197ns  121.35us  cuDeviceGetAttribute\n",
      "                    0.03%  231.90us         1  231.90us  231.90us  231.90us  cudaGetDeviceProperties\n",
      "                    0.03%  213.16us        30  7.1050us  3.8350us  76.166us  cudaMemsetAsync\n",
      "                    0.02%  129.63us         1  129.63us  129.63us  129.63us  cudaGetDevice\n",
      "                    0.00%  26.838us         1  26.838us  26.838us  26.838us  cuDeviceGetName\n",
      "                    0.00%  11.691us         1  11.691us  11.691us  11.691us  cuDeviceTotalMem\n",
      "                    0.00%  1.9080us         1  1.9080us  1.9080us  1.9080us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.8760us         3     625ns     206ns  1.3200us  cuDeviceGetCount\n",
      "                    0.00%  1.3960us         2     698ns     218ns  1.1780us  cuDeviceGet\n",
      "                    0.00%     477ns         1     477ns     477ns     477ns  cuModuleGetLoadingMode\n",
      "                    0.00%     411ns         1     411ns     411ns     411ns  cuDeviceGetUuid\n",
      "\n",
      "==4168== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "     129  1.9864MB  256.00KB  2.0000MB  256.2500MB  24.88465ms  Host To Device\n",
      "       3  1.4167MB  256.00KB  2.0000MB  4.250000MB  839.4510us  Device To Host\n",
      "Total CPU Page faults: 771\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./kmean_gpu_simple_managed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1e9dd5-16d3-4516-bd81-097f004f44fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

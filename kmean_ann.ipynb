{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0b84556-3cdc-4eef-b940-361f65732745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/bin:/bin:/usr/bin:/usr/local/cuda/bin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Add the directory containing the executable to the PATH\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/usr/local/cuda/bin\"\n",
    "\n",
    "# Check if the directory is added to the a\n",
    "print(os.environ[\"PATH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82c50a9a-4761-463a-8540-1833bcbc3670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2025 NVIDIA Corporation\n",
      "Built on Wed_Apr__9_19:24:57_PDT_2025\n",
      "Cuda compilation tools, release 12.9, V12.9.41\n",
      "Build cuda_12.9.r12.9/compiler.35813241_0\n",
      "nvprof: NVIDIA (R) Cuda command line profiler\n",
      "Copyright (c) 2012 - 2025 NVIDIA Corporation\n",
      "Release version 12.9.19 (21)\n",
      "NVIDIA Nsight Systems version 2025.1.3.140-251335620677v0\n",
      "NVIDIA (R) Nsight Compute Command Line Profiler\n",
      "Copyright (c) 2018-2025 NVIDIA Corporation\n",
      "Version 2025.2.0.0 (build 35613519) (public-release)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvcc --version\n",
    "nvprof --version\n",
    "nsys --version\n",
    "ncu --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca7ffcb-1cbc-4218-95c4-77f2cbb63c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 21 14:22:15 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.51.03              Driver Version: 575.51.03      CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-PCIE-32GB           Off |   00000000:00:10.0 Off |                    0 |\n",
      "| N/A   27C    P0             22W /  250W |       0MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0a0ed84-dd26-4ecd-b44e-daa940de7142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting origin.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile origin.cu\n",
    "\n",
    "#include <cuda_runtime.h>\n",
    "#include <cstdio>\n",
    "#include <vector>\n",
    "#include <random>\n",
    "#include <algorithm>\n",
    "#include <numeric>\n",
    "#include <cmath>\n",
    "#include <cassert>\n",
    "#include <unordered_set>\n",
    "#include <limits>\n",
    "#include <cfloat>\n",
    "\n",
    "// ---------------- Config ----------------\n",
    "static const int DIM          = 64;\n",
    "static const float ALPHA      = 0.7f;\n",
    "static const int SEED         = 2025; \n",
    "static const int N            = 1 << 24; // 1 Million vectors\n",
    "static const int K            = 1024;    // Clusters\n",
    "static const int NPROBE       = 32;       // Search depth\n",
    "static const int TOPK         = 5;\n",
    "static const int KMEANS_ITERS = 15;      // K-Means iterations\n",
    "\n",
    "using Vec = std::vector<float>;\n",
    "\n",
    "// ---------------- Embedding Generator ----------------\n",
    "\n",
    "static Vec numberBase[76]; // 1..75\n",
    "static Vec posBase[25];    // 0..24\n",
    "\n",
    "static void normInPlace(Vec &v) {\n",
    "    double s = 0;\n",
    "    for (float x : v) s += (double)x * x;\n",
    "    float n = float(std::sqrt(s) + 1e-12);\n",
    "    for (float &x : v) x /= n;\n",
    "}\n",
    "\n",
    "static Vec randUnit(std::mt19937 &rng) {\n",
    "    std::uniform_real_distribution<float> U(-1.f, 1.f);\n",
    "    Vec v(DIM);\n",
    "    for (int i = 0; i < DIM; i++) v[i] = U(rng);\n",
    "    normInPlace(v);\n",
    "    return v;\n",
    "}\n",
    "\n",
    "static void initBases() {\n",
    "    std::mt19937 rng(SEED);\n",
    "    for (int n = 1; n <= 75; n++) numberBase[n] = randUnit(rng);\n",
    "    for (int i = 0; i < 25; i++)  posBase[i]    = randUnit(rng);\n",
    "}\n",
    "\n",
    "static Vec cardToVec(const int card[25]) {\n",
    "    Vec out(DIM, 0.f);\n",
    "    for (int i = 0; i < 25; i++) {\n",
    "        int n = card[i];\n",
    "        const Vec &b = numberBase[n];\n",
    "        const Vec &p = posBase[i];\n",
    "        for (int j = 0; j < DIM; j++)\n",
    "            out[j] += b[j] + ALPHA * p[j];\n",
    "    }\n",
    "    normInPlace(out);\n",
    "    return out;\n",
    "}\n",
    "\n",
    "static void genCard(std::mt19937 &rng, int out[25]) {\n",
    "    std::vector<int> p(75);\n",
    "    std::iota(p.begin(), p.end(), 1);\n",
    "    std::shuffle(p.begin(), p.end(), rng);\n",
    "    for (int i = 0; i < 25; i++) out[i] = p[i];\n",
    "}\n",
    "\n",
    "static double dot_host(const float* a, const float* b) {\n",
    "    double s = 0;\n",
    "    for (int i = 0; i < DIM; i++) s += (double)a[i] * b[i];\n",
    "    return s;\n",
    "}\n",
    "\n",
    "// ---------------- GPU K-Means Kernels ----------------\n",
    "\n",
    "// E-step: Assign data to nearest centroid\n",
    "__global__ void assignAndAccumulateKernel(const float* data,\n",
    "                                          int N,\n",
    "                                          const float* centroids,\n",
    "                                          int K,\n",
    "                                          int* assign,\n",
    "                                          float* sums,\n",
    "                                          int* counts) {\n",
    "    for (int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "         i < N;\n",
    "         i += gridDim.x * blockDim.x) {\n",
    "\n",
    "        const float* xi = data + (size_t)i * DIM;\n",
    "\n",
    "        int bestC = 0;\n",
    "        float bestD = 1e30f;\n",
    "\n",
    "        for (int c = 0; c < K; ++c) {\n",
    "            const float* ctr = centroids + (size_t)c * DIM;\n",
    "            float dot = 0.f;\n",
    "            for (int d = 0; d < DIM; ++d) {\n",
    "                dot += xi[d] * ctr[d];\n",
    "            }\n",
    "            float dist = 1.f - dot;\n",
    "            if (dist < bestD) {\n",
    "                bestD = dist;\n",
    "                bestC = c;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        assign[i] = bestC;\n",
    "\n",
    "        // Atomic add to accumulators (Naive approach, ok for demo)\n",
    "        atomicAdd(&counts[bestC], 1);\n",
    "        size_t base = (size_t)bestC * DIM;\n",
    "        for (int d = 0; d < DIM; ++d) {\n",
    "            atomicAdd(&sums[base + d], xi[d]);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// M-step: Update centroids\n",
    "__global__ void updateCentroidsKernel(float* centroids,\n",
    "                                      const float* sums,\n",
    "                                      const int* counts,\n",
    "                                      int K) {\n",
    "    int c = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (c >= K) return;\n",
    "\n",
    "    int cnt = counts[c];\n",
    "    float* ctr = centroids + (size_t)c * DIM;\n",
    "    const float* sumc = sums + (size_t)c * DIM;\n",
    "\n",
    "    if (cnt > 0) {\n",
    "        double norm2 = 0.0;\n",
    "        for (int d = 0; d < DIM; ++d) {\n",
    "            float v = sumc[d] / (float)cnt;\n",
    "            ctr[d] = v;\n",
    "            norm2 += (double)v * (double)v;\n",
    "        }\n",
    "        float n = float(std::sqrt(norm2) + 1e-12);\n",
    "        for (int d = 0; d < DIM; ++d) {\n",
    "            ctr[d] /= n;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "// ---------------- Host: Inverted Lists ----------------\n",
    "\n",
    "static void buildInvertedLists(\n",
    "    const std::vector<int>& assign,\n",
    "    int N, int K,\n",
    "    std::vector<std::vector<int>>& lists\n",
    ") {\n",
    "    lists.assign(K, {});\n",
    "    for (int i = 0; i < N; ++i) {\n",
    "        int c = assign[i];\n",
    "        if (c >= 0 && c < K) {\n",
    "            lists[c].push_back(i);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "// ---------------- Main ----------------\n",
    "int main() {\n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, 0);\n",
    "    int BLOCK  = prop.multiProcessorCount; \n",
    "    \n",
    "    printf(\"Params: N=%d  K=%d  nprobe=%d  TOPK=%d  DIM=%d  KMEANS_ITERS=%d\\n\",\n",
    "           N, K, NPROBE, TOPK, DIM, KMEANS_ITERS);\n",
    "    printf(\"Mode: GPU Training -> CPU Search\\n\");\n",
    "\n",
    "    initBases();\n",
    "    std::mt19937 rng(SEED + 7);\n",
    "\n",
    "    // 1) Data Generation\n",
    "    std::vector<int>   h_cards((size_t)N * 25);\n",
    "    std::vector<float> h_data((size_t)N * DIM);\n",
    "\n",
    "    printf(\"[INIT] Generating %d vectors...\\n\", N);\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        int c[25];\n",
    "        genCard(rng, c);\n",
    "        for (int t = 0; t < 25; ++t) h_cards[(size_t)i * 25 + t] = c[t];\n",
    "        Vec v = cardToVec(c);\n",
    "        for (int d = 0; d < DIM; ++d) h_data[(size_t)i * DIM + d] = v[d];\n",
    "    }\n",
    "\n",
    "    // 2) Build Query\n",
    "    int qc[25];\n",
    "    for (int t = 0; t < 25; ++t) qc[t] = h_cards[t]; // Copy 0-th card\n",
    "    qc[3] = 75; qc[17] = 1; std::swap(qc[5], qc[19]); // Modify it\n",
    "    Vec qvec = cardToVec(qc);\n",
    "    std::vector<float> q_host(qvec.begin(), qvec.end());\n",
    "\n",
    "    {\n",
    "        double dot0 = dot_host(q_host.data(), &h_data[0]);\n",
    "        printf(\"[DEBUG] Query vs Data[0]: dot=%.9f dist=%.9f\\n\", dot0, 1.0 - dot0);\n",
    "    }\n",
    "\n",
    "    // 3) GPU Allocations for Training\n",
    "    float *d_data = 0, *d_centroids = 0;\n",
    "    int   *d_assign = 0, *d_counts = 0;\n",
    "    float *d_sums = 0;\n",
    "\n",
    "    cudaMalloc(&d_data,      (size_t)N * DIM * sizeof(float));\n",
    "    cudaMalloc(&d_centroids, (size_t)K * DIM * sizeof(float));\n",
    "    cudaMalloc(&d_assign,    N * sizeof(int));\n",
    "    cudaMalloc(&d_sums,      (size_t)K * DIM * sizeof(float));\n",
    "    cudaMalloc(&d_counts,    K * sizeof(int));\n",
    "\n",
    "    cudaMemcpy(d_data, h_data.data(), (size_t)N * DIM * sizeof(float), cudaMemcpyHostToDevice);\n",
    "\n",
    "    // 4) Initialize Centroids (Random select from data)\n",
    "    {\n",
    "        std::vector<int> idx(N);\n",
    "        std::iota(idx.begin(), idx.end(), 0);\n",
    "        std::shuffle(idx.begin(), idx.end(), rng);\n",
    "        std::vector<float> h_initC((size_t)K * DIM);\n",
    "        for (int c = 0; c < K; ++c) {\n",
    "            int i = idx[c];\n",
    "            std::copy_n(&h_data[(size_t)i * DIM], DIM, &h_initC[(size_t)c * DIM]);\n",
    "        }\n",
    "        cudaMemcpy(d_centroids, h_initC.data(), (size_t)K * DIM * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    }\n",
    "\n",
    "    // 5) GPU K-Means Training\n",
    "    {\n",
    "        dim3 block(BLOCK);\n",
    "        dim3 gridN((N + BLOCK - 1) / BLOCK);\n",
    "        dim3 gridK((K + BLOCK - 1) / BLOCK);\n",
    "\n",
    "        printf(\"[TRAIN] Running K-Means on GPU (%d iters)...\\n\", KMEANS_ITERS);\n",
    "\n",
    "        for (int it = 0; it < KMEANS_ITERS; ++it) {\n",
    "            cudaMemset(d_sums,   0, (size_t)K * DIM * sizeof(float));\n",
    "            cudaMemset(d_counts, 0, K * sizeof(int));\n",
    "\n",
    "            assignAndAccumulateKernel<<<gridN, block>>>(\n",
    "                d_data, N, d_centroids, K, d_assign, d_sums, d_counts\n",
    "            );\n",
    "            cudaDeviceSynchronize();\n",
    "\n",
    "            updateCentroidsKernel<<<gridK, block>>>(\n",
    "                d_centroids, d_sums, d_counts, K\n",
    "            );\n",
    "            cudaDeviceSynchronize();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // 6) Retrieve Training Results\n",
    "    std::vector<int> h_assign(N);\n",
    "    cudaMemcpy(h_assign.data(), d_assign, N * sizeof(int), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // Retrieve final centroids for CPU search\n",
    "    std::vector<float> h_finalCentroids(K * DIM);\n",
    "    cudaMemcpy(h_finalCentroids.data(), d_centroids, (size_t)K * DIM * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // We are done with GPU memory\n",
    "    cudaFree(d_data);\n",
    "    cudaFree(d_centroids);\n",
    "    cudaFree(d_assign);\n",
    "    cudaFree(d_sums);\n",
    "    cudaFree(d_counts);\n",
    "\n",
    "    // 7) Build IVF Index (Host)\n",
    "    printf(\"[INDEX] Building Inverted Lists on Host...\\n\");\n",
    "    std::vector<std::vector<int>> lists;\n",
    "    buildInvertedLists(h_assign, N, K, lists);\n",
    "\n",
    "    int nonEmpty = 0;\n",
    "    for(const auto& list : lists) if(!list.empty()) nonEmpty++;\n",
    "    printf(\"[INDEX] Non-empty clusters: %d / %d\\n\", nonEmpty, K);\n",
    "\n",
    "    // ---------------------------------------------------------\n",
    "    //  SEARCH PHASE (CPU)\n",
    "    // ---------------------------------------------------------\n",
    "    printf(\"\\n[SEARCH] CPU Search (nprobe=%d)...\\n\", NPROBE);\n",
    "\n",
    "    // Step A: Coarse Search (Find nearest NPROBE clusters)\n",
    "    // Format: {distance, cluster_id}\n",
    "    std::vector<std::pair<float, int>> centerDists;\n",
    "    centerDists.reserve(K);\n",
    "\n",
    "    for (int c = 0; c < K; ++c) {\n",
    "        const float* ctr = &h_finalCentroids[(size_t)c * DIM];\n",
    "        double dotVal = dot_host(q_host.data(), ctr);\n",
    "        float dist = 1.0f - (float)dotVal;\n",
    "        centerDists.push_back({dist, c});\n",
    "    }\n",
    "\n",
    "    // Sort centroids by distance ASC\n",
    "    std::sort(centerDists.begin(), centerDists.end(), \n",
    "              [](const std::pair<float, int>& a, const std::pair<float, int>& b){\n",
    "                  return a.first < b.first;\n",
    "              });\n",
    "\n",
    "    // Step B: Gather Candidates & Exact Search\n",
    "    // Format: {distance, vector_id}\n",
    "    std::vector<std::pair<float, int>> candidates;\n",
    "    // Reserve some memory to avoid reallocations (heuristic)\n",
    "    candidates.reserve((N / K) * NPROBE * 2);\n",
    "\n",
    "    int visitedVecs = 0;\n",
    "    for (int i = 0; i < NPROBE && i < K; ++i) {\n",
    "        int c_id = centerDists[i].second;\n",
    "        const auto& bucket = lists[c_id];\n",
    "        visitedVecs += bucket.size();\n",
    "\n",
    "        for (int vecIdx : bucket) {\n",
    "            const float* vec = &h_data[(size_t)vecIdx * DIM];\n",
    "            double dotVal = dot_host(q_host.data(), vec);\n",
    "            float dist = 1.0f - (float)dotVal;\n",
    "            candidates.push_back({dist, vecIdx});\n",
    "        }\n",
    "    }\n",
    "\n",
    "    printf(\"[SEARCH] Scanned %d vectors from top %d clusters.\\n\", visitedVecs, NPROBE);\n",
    "\n",
    "    // Step C: Ranking (Top-K)\n",
    "    if (candidates.empty()) {\n",
    "        printf(\"No candidates found.\\n\");\n",
    "    } else {\n",
    "        int finalK = std::min((int)candidates.size(), TOPK);\n",
    "        \n",
    "        // Partial sort gives us the smallest K elements at the beginning\n",
    "        std::partial_sort(candidates.begin(), \n",
    "                          candidates.begin() + finalK, \n",
    "                          candidates.end(),\n",
    "                          [](const std::pair<float, int>& a, const std::pair<float, int>& b){\n",
    "                              return a.first < b.first;\n",
    "                          });\n",
    "\n",
    "        printf(\"\\nTop-%d Results:\\n\", finalK);\n",
    "        for (int i = 0; i < finalK; ++i) {\n",
    "            printf(\"%2d) id=%d  dist=%.6f  sim=%.6f\\n\",\n",
    "                   i+1, candidates[i].second, candidates[i].first, 1.f - candidates[i].first);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5009ae69-3720-4533-ad36-22e9d9805804",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc -O3 -std=c++17 -arch=sm_70 origin.cu -o origin -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bfe5082-b45c-4dd2-b398-69d43ed2b167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==102655== NVPROF is profiling process 102655, command: ./origin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: N=16777216  K=1024  nprobe=32  TOPK=5  DIM=64  KMEANS_ITERS=15\n",
      "Mode: GPU Training -> CPU Search\n",
      "[INIT] Generating 16777216 vectors...\n",
      "[DEBUG] Query vs Data[0]: dot=0.927471359 dist=0.072528641\n",
      "[TRAIN] Running K-Means on GPU (15 iters)...\n",
      "[INDEX] Building Inverted Lists on Host...\n",
      "[INDEX] Non-empty clusters: 1024 / 1024\n",
      "\n",
      "[SEARCH] CPU Search (nprobe=32)...\n",
      "[SEARCH] Scanned 557487 vectors from top 32 clusters.\n",
      "\n",
      "Top-5 Results:\n",
      " 1) id=0  dist=0.072529  sim=0.927471\n",
      " 2) id=15528589  dist=0.136097  sim=0.863903\n",
      " 3) id=13929498  dist=0.139304  sim=0.860696\n",
      " 4) id=8185180  dist=0.146311  sim=0.853689\n",
      " 5) id=16494452  dist=0.150325  sim=0.849675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==102655== Profiling application: ./origin\n",
      "==102655== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   70.15%  10.2910s        15  686.07ms  645.03ms  689.22ms  assignAndAccumulateKernel(float const *, int, float const *, int, int*, float*, int*)\n",
      "                   29.40%  4.31305s         2  2.15653s  52.799us  4.31300s  [CUDA memcpy HtoD]\n",
      "                    0.45%  65.979ms         2  32.989ms  61.951us  65.917ms  [CUDA memcpy DtoH]\n",
      "                    0.00%  300.99us        15  20.066us  19.680us  22.240us  updateCentroidsKernel(float*, float const *, int const *, int)\n",
      "                    0.00%  44.541us        30  1.4840us  1.0870us  2.3030us  [CUDA memset]\n",
      "      API calls:   65.85%  10.2929s        30  343.10ms  19.968us  689.27ms  cudaDeviceSynchronize\n",
      "                   28.04%  4.38281s         4  1.09570s  397.92us  4.31431s  cudaMemcpy\n",
      "                    6.00%  937.81ms         5  187.56ms  5.1660us  937.31ms  cudaMalloc\n",
      "                    0.04%  7.0242ms         5  1.4048ms  55.813us  5.9044ms  cudaFree\n",
      "                    0.03%  5.2388ms        30  174.63us  20.214us  1.1240ms  cudaLaunchKernel\n",
      "                    0.02%  3.6098ms       114  31.665us     108ns  3.1664ms  cuDeviceGetAttribute\n",
      "                    0.01%  1.9034ms        30  63.448us  11.245us  371.38us  cudaMemset\n",
      "                    0.00%  264.22us         1  264.22us  264.22us  264.22us  cuDeviceGetName\n",
      "                    0.00%  221.03us         1  221.03us  221.03us  221.03us  cudaGetDeviceProperties\n",
      "                    0.00%  31.012us         1  31.012us  31.012us  31.012us  cuDeviceGetPCIBusId\n",
      "                    0.00%  26.181us         1  26.181us  26.181us  26.181us  cuDeviceTotalMem\n",
      "                    0.00%  11.323us         3  3.7740us     168ns  10.085us  cuDeviceGetCount\n",
      "                    0.00%  4.6400us         2  2.3200us     189ns  4.4510us  cuDeviceGet\n",
      "                    0.00%     905ns         1     905ns     905ns     905ns  cuModuleGetLoadingMode\n",
      "                    0.00%     548ns         1     548ns     548ns     548ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7c544e5-7bd0-44c0-bc81-995e72322483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Device-side CUDA Event completion trace is currently enabled.\n",
      "         This may increase runtime overhead and the likelihood of false\n",
      "         dependencies across CUDA Streams. If you wish to avoid this, please\n",
      "         disable the feature with --cuda-event-trace=false.\n",
      "WARNING: CPU IP/backtrace sampling not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n",
      "WARNING: CPU context switch tracing not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: N=16777216  K=1024  nprobe=32  TOPK=5  DIM=64  KMEANS_ITERS=15\n",
      "Mode: GPU Training -> CPU Search\n",
      "[INIT] Generating 16777216 vectors...\n",
      "[DEBUG] Query vs Data[0]: dot=0.927471359 dist=0.072528641\n",
      "[TRAIN] Running K-Means on GPU (15 iters)...\n",
      "[INDEX] Building Inverted Lists on Host...\n",
      "[INDEX] Non-empty clusters: 1024 / 1024\n",
      "\n",
      "[SEARCH] CPU Search (nprobe=32)...\n",
      "[SEARCH] Scanned 557512 vectors from top 32 clusters.\n",
      "\n",
      "Top-5 Results:\n",
      " 1) id=0  dist=0.072529  sim=0.927471\n",
      " 2) id=15528589  dist=0.136097  sim=0.863903\n",
      " 3) id=13929498  dist=0.139304  sim=0.860696\n",
      " 4) id=8185180  dist=0.146311  sim=0.853689\n",
      " 5) id=16494452  dist=0.150325  sim=0.849675\n",
      "Collecting data...\n",
      "Generating '/tmp/nsys-report-2f4c.qdstrm'\n",
      "[1/1] [========================100%] report1.nsys-rep\n",
      "Generated:\n",
      "\t/home/jupyter-feifan_chen@dlsu.e-15ebb/report1.nsys-rep\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nsys profile -o ./origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083df34d-0759-4049-80e0-c99062e2ce28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

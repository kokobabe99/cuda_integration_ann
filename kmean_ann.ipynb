{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0b84556-3cdc-4eef-b940-361f65732745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/bin:/bin:/usr/bin:/usr/local/cuda/bin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Add the directory containing the executable to the PATH\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/usr/local/cuda/bin\"\n",
    "\n",
    "# Check if the directory is added to the a\n",
    "print(os.environ[\"PATH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82c50a9a-4761-463a-8540-1833bcbc3670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2025 NVIDIA Corporation\n",
      "Built on Wed_Apr__9_19:24:57_PDT_2025\n",
      "Cuda compilation tools, release 12.9, V12.9.41\n",
      "Build cuda_12.9.r12.9/compiler.35813241_0\n",
      "nvprof: NVIDIA (R) Cuda command line profiler\n",
      "Copyright (c) 2012 - 2025 NVIDIA Corporation\n",
      "Release version 12.9.19 (21)\n",
      "NVIDIA Nsight Systems version 2025.1.3.140-251335620677v0\n",
      "NVIDIA (R) Nsight Compute Command Line Profiler\n",
      "Copyright (c) 2018-2025 NVIDIA Corporation\n",
      "Version 2025.2.0.0 (build 35613519) (public-release)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvcc --version\n",
    "nvprof --version\n",
    "nsys --version\n",
    "ncu --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cca7ffcb-1cbc-4218-95c4-77f2cbb63c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 24 13:37:59 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.51.03              Driver Version: 575.51.03      CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-PCIE-32GB           Off |   00000000:00:10.0 Off |                    0 |\n",
      "| N/A   27C    P0             22W /  250W |       0MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0a0ed84-dd26-4ecd-b44e-daa940de7142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kmean_gpu.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile kmean_gpu.cu\n",
    "\n",
    "#include <cuda_runtime.h>\n",
    "#include <cstdio>\n",
    "#include <vector>\n",
    "#include <random>\n",
    "#include <algorithm>\n",
    "#include <numeric>\n",
    "#include <cmath>\n",
    "#include <cassert>\n",
    "#include <unordered_set>\n",
    "#include <limits>\n",
    "#include <cfloat>\n",
    "\n",
    "// ---------------- Config ----------------\n",
    "static const int DIM      = 64;\n",
    "static const float ALPHA  = 0.7f;\n",
    "static const int SEED     = 2025; \n",
    "static const int N        = 1 << 20; // 1 Million vectors\n",
    "static const int K        = 2048;    // Clusters\n",
    "static const int NPROBE   = 32;      // Search depth\n",
    "static const int TOPK     = 5;\n",
    "static const int KMEANS_ITERS = 15;  // K-Means iterations\n",
    "static int BLOCK = 512;\n",
    "\n",
    "\n",
    "using Vec = std::vector<float>;\n",
    "\n",
    "// ---------------- Embedding Generator ----------------\n",
    "\n",
    "static Vec numberBase[76]; // 1..75\n",
    "static Vec posBase[25];    // 0..24\n",
    "\n",
    "static void normInPlace(Vec &v) {\n",
    "    double s = 0;\n",
    "    for (float x : v) s += (double)x * x;\n",
    "    float n = float(std::sqrt(s) + 1e-12);\n",
    "    for (float &x : v) x /= n;\n",
    "}\n",
    "\n",
    "static Vec randUnit(std::mt19937 &rng) {\n",
    "    std::uniform_real_distribution<float> U(-1.f, 1.f);\n",
    "    Vec v(DIM);\n",
    "    for (int i = 0; i < DIM; i++) v[i] = U(rng);\n",
    "    normInPlace(v);\n",
    "    return v;\n",
    "}\n",
    "\n",
    "static void initBases() {\n",
    "    std::mt19937 rng(SEED);\n",
    "    for (int n = 1; n <= 75; n++) numberBase[n] = randUnit(rng);\n",
    "    for (int i = 0; i < 25; i++)  posBase[i]    = randUnit(rng);\n",
    "}\n",
    "\n",
    "static Vec cardToVec(const int card[25]) {\n",
    "    Vec out(DIM, 0.f);\n",
    "    for (int i = 0; i < 25; i++) {\n",
    "        int n = card[i];\n",
    "        const Vec &b = numberBase[n];\n",
    "        const Vec &p = posBase[i];\n",
    "        for (int j = 0; j < DIM; j++)\n",
    "            out[j] += b[j] + ALPHA * p[j];\n",
    "    }\n",
    "    normInPlace(out);\n",
    "    return out;\n",
    "}\n",
    "\n",
    "static void genCard(std::mt19937 &rng, int out[25]) {\n",
    "    std::vector<int> p(75);\n",
    "    std::iota(p.begin(), p.end(), 1);\n",
    "    std::shuffle(p.begin(), p.end(), rng);\n",
    "    for (int i = 0; i < 25; i++) out[i] = p[i];\n",
    "}\n",
    "\n",
    "static double dot_host(const float* a, const float* b) {\n",
    "    double s = 0;\n",
    "    for (int i = 0; i < DIM; i++) s += (double)a[i] * b[i];\n",
    "    return s;\n",
    "}\n",
    "\n",
    "// ---------------- GPU K-Means Kernels ----------------\n",
    "\n",
    "// E-step: Assign data to nearest centroid (E-Step: Data Assignment)\n",
    "__global__ void assignAndAccumulateKernel(const float* data,      // [Input] Dataset (N * DIM)\n",
    "                                          int N,                 // Total number of data points\n",
    "                                          const float* centroids, // [Input] Centroids (K * DIM)\n",
    "                                          int K,                 // Total number of clusters K\n",
    "                                          int* assign,            // [Output] Assignment results (N elements, storing 0..K-1)\n",
    "                                          double* sums,           // [Output] Accumulator: Centroid vector sums (K * DIM, using double precision)\n",
    "                                          int* counts)           // [Output] Accumulator: Centroid counts (K elements)\n",
    "{\n",
    "    // Each thread processes one or more data points\n",
    "    for (int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "         i < N;\n",
    "         i += gridDim.x * blockDim.x) {\n",
    "\n",
    "        // Get the starting pointer for the current data point xi\n",
    "        const float* xi = data + (size_t)i * DIM;\n",
    "\n",
    "        int bestC = 0;\n",
    "        // Initialize the minimum distance with a sufficiently large number (e.g., FLT_MAX)\n",
    "        float bestD = 1e30f; \n",
    "\n",
    "        // Iterate through all K centroids to find the closest one\n",
    "        for (int c = 0; c < K; ++c) {\n",
    "            // Get the starting pointer for the current centroid ctr\n",
    "            const float* ctr = centroids + (size_t)c * DIM;\n",
    "            \n",
    "            // Use double precision for dot product accumulation to improve numerical stability\n",
    "            double dot_double = 0.0; \n",
    "            for (int d = 0; d < DIM; ++d) {\n",
    "                // Promote float values to double for multiplication and addition\n",
    "                dot_double += (double)xi[d] * (double)ctr[d]; \n",
    "            }\n",
    "            float dot = (float)dot_double; // Convert the final result back to float for distance comparison\n",
    "            \n",
    "            // Calculate cosine distance: 1.0 - similarity (similarity is the dot product)\n",
    "            float dist = 1.f - dot;\n",
    "            \n",
    "            // Update the nearest centroid\n",
    "            if (dist < bestD) {\n",
    "                bestD = dist;\n",
    "                bestC = c;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Record the assignment result for data point i\n",
    "        assign[i] = bestC;\n",
    "\n",
    "        // Atomic add to accumulators (Atomic operations resolve concurrent write conflicts)\n",
    "        // Accumulate count\n",
    "        atomicAdd(&counts[bestC], 1);\n",
    "        \n",
    "        // Accumulate vector sum\n",
    "        size_t base = (size_t)bestC * DIM;\n",
    "        for (int d = 0; d < DIM; ++d) {\n",
    "            // Convert the float xi[d] to double before atomically adding to the double sums array\n",
    "            atomicAdd(&sums[base + d], (double)xi[d]); \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// -----------------------------------------------------------------------------\n",
    "\n",
    "// M-step: Update centroids (M-Step: Centroid Update)\n",
    "__global__ void updateCentroidsKernel(float* centroids,      // [Output] Centroids (updated values)\n",
    "                                      const double* sums,    // [Input] Accumulated vector sums (double precision)\n",
    "                                      const int* counts,     // [Input] Accumulated counts\n",
    "                                      int K) {\n",
    "    // Each thread processes one centroid c\n",
    "    int c = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (c >= K) return;\n",
    "\n",
    "    int cnt = counts[c];\n",
    "    float* ctr = centroids + (size_t)c * DIM;      // Pointer to the centroid to be updated\n",
    "    const double* sumc = sums + (size_t)c * DIM;   // Pointer to the vector sum for centroid c\n",
    "\n",
    "    if (cnt > 0) { // Only update centroids that were assigned data points\n",
    "        double norm2 = 0.0;\n",
    "        for (int d = 0; d < DIM; ++d) {\n",
    "            // FIX: Use double for precise average calculation (sum / count)\n",
    "            double v_double = sumc[d] / (double)cnt;\n",
    "            float v = (float)v_double; // Convert result back to float for storage\n",
    "            \n",
    "            ctr[d] = v;\n",
    "            \n",
    "            // Use double precision to accumulate the squared norm, preparing for unit normalization\n",
    "            norm2 += v_double * v_double; \n",
    "        }\n",
    "        \n",
    "        // Centroid Normalization (Unit Length)\n",
    "        // Calculate the L2 norm (magnitude)\n",
    "        float n = float(std::sqrt(norm2) + 1e-12); \n",
    "        \n",
    "        // Normalize the centroid vector onto the unit sphere\n",
    "        for (int d = 0; d < DIM; ++d) {\n",
    "            ctr[d] /= n;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "// ---------------- Host: Inverted Lists ----------------\n",
    "\n",
    "static void buildInvertedLists(\n",
    "    const std::vector<int>& assign,\n",
    "    int N, int K,\n",
    "    std::vector<std::vector<int>>& lists\n",
    ") {\n",
    "    lists.assign(K, {});\n",
    "    for (int i = 0; i < N; ++i) {\n",
    "        int c = assign[i];\n",
    "        if (c >= 0 && c < K) {\n",
    "            lists[c].push_back(i);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "// ---------------- Main ----------------\n",
    "int main() {\n",
    "\n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, 0);\n",
    "\n",
    "    int smCount = prop.multiProcessorCount;\n",
    "    int gridSizeN = smCount * 4;\n",
    "\n",
    "    printf(\"GPU: %s\\n\", prop.name);\n",
    "    printf(\"SM count: %d\\n\", prop.multiProcessorCount);\n",
    "    printf(\"Params: N=%d  K=%d  nprobe=%d  TOPK=%d  DIM=%d  KMEANS_ITERS=%d\\n\",\n",
    "           N, K, NPROBE, TOPK, DIM, KMEANS_ITERS);\n",
    "    printf(\"Mode: GPU Training -> CPU Search\\n\");\n",
    "\n",
    "    initBases();\n",
    "    std::mt19937 rng(SEED + 7);\n",
    "\n",
    "    // 1) Data Generation\n",
    "    std::vector<int>  h_cards((size_t)N * 25);\n",
    "    std::vector<float> h_data((size_t)N * DIM);\n",
    "\n",
    "    printf(\"[INIT] Generating %d vectors...\\n\", N);\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        int c[25];\n",
    "        genCard(rng, c);\n",
    "        for (int t = 0; t < 25; ++t) h_cards[(size_t)i * 25 + t] = c[t];\n",
    "        Vec v = cardToVec(c);\n",
    "        for (int d = 0; d < DIM; ++d) h_data[(size_t)i * DIM + d] = v[d];\n",
    "    }\n",
    "\n",
    "    // 2) Build Query\n",
    "    int qc[25];\n",
    "    for (int t = 0; t < 25; ++t) qc[t] = h_cards[t]; // Copy 0-th card\n",
    "    qc[3] = 75; qc[17] = 1; std::swap(qc[5], qc[19]); // Modify it\n",
    "    Vec qvec = cardToVec(qc);\n",
    "    std::vector<float> q_host(qvec.begin(), qvec.end());\n",
    "\n",
    "    {\n",
    "        double dot0 = dot_host(q_host.data(), &h_data[0]);\n",
    "        printf(\"[DEBUG] Query vs Data[0]: dot=%.9f dist=%.9f\\n\", dot0, 1.0 - dot0);\n",
    "    }\n",
    "\n",
    "    // 3) GPU Allocations for Training\n",
    "    float *d_data = 0, *d_centroids = 0;\n",
    "    int   *d_assign = 0, *d_counts = 0;\n",
    "    double *d_sums_double = 0;\n",
    "\n",
    "    cudaMalloc(&d_data,      (size_t)N * DIM * sizeof(float));\n",
    "    cudaMalloc(&d_centroids, (size_t)K * DIM * sizeof(float));\n",
    "    cudaMalloc(&d_assign,    N * sizeof(int));\n",
    "    cudaMalloc(&d_sums_double, (size_t)K * DIM * sizeof(double));\n",
    "    cudaMalloc(&d_counts,    K * sizeof(int));\n",
    "\n",
    "    cudaMemcpy(d_data, h_data.data(), (size_t)N * DIM * sizeof(float), cudaMemcpyHostToDevice);\n",
    "\n",
    "    // 4) Initialize Centroids (Random select from data)\n",
    "    {\n",
    "        std::vector<int> idx(N);\n",
    "        std::iota(idx.begin(), idx.end(), 0);\n",
    "        std::shuffle(idx.begin(), idx.end(), rng);\n",
    "        std::vector<float> h_initC((size_t)K * DIM);\n",
    "        for (int c = 0; c < K; ++c) {\n",
    "            int i = idx[c];\n",
    "            std::copy_n(&h_data[(size_t)i * DIM], DIM, &h_initC[(size_t)c * DIM]);\n",
    "        }\n",
    "        cudaMemcpy(d_centroids, h_initC.data(), (size_t)K * DIM * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    }\n",
    "\n",
    "    // 5) GPU K-Means Training\n",
    "    {\n",
    "        dim3 block(BLOCK);\n",
    "        dim3 gridN(gridSizeN);\n",
    "\n",
    "        printf(\"[TRAIN] Running K-Means on GPU (%d iters)...\\n\", KMEANS_ITERS);\n",
    "\n",
    "        for (int it = 0; it < KMEANS_ITERS; ++it) {\n",
    "            cudaMemset(d_sums_double,  0, (size_t)K * DIM * sizeof(double)); \n",
    "            cudaMemset(d_counts, 0, K * sizeof(int));\n",
    "\n",
    "            assignAndAccumulateKernel<<<gridN,block>>>(\n",
    "                d_data, N, d_centroids, K, d_assign, d_sums_double, d_counts\n",
    "            );\n",
    "            cudaDeviceSynchronize();\n",
    "\n",
    "            updateCentroidsKernel<<<gridN,block>>>(\n",
    "                d_centroids, d_sums_double, d_counts, K\n",
    "            );\n",
    "            cudaDeviceSynchronize();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // 6) Retrieve Training Results\n",
    "    std::vector<int> h_assign(N);\n",
    "    cudaMemcpy(h_assign.data(), d_assign, N * sizeof(int), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // Retrieve final centroids for CPU search\n",
    "    std::vector<float> h_finalCentroids(K * DIM);\n",
    "    cudaMemcpy(h_finalCentroids.data(), d_centroids, (size_t)K * DIM * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // We are done with GPU memory\n",
    "    cudaFree(d_data);\n",
    "    cudaFree(d_centroids);\n",
    "    cudaFree(d_assign);\n",
    "    cudaFree(d_sums_double);\n",
    "    cudaFree(d_counts);\n",
    "\n",
    "    // 7) Build IVF Index (Host)\n",
    "    printf(\"[INDEX] Building Inverted Lists on Host...\\n\");\n",
    "    std::vector<std::vector<int>> lists;\n",
    "    buildInvertedLists(h_assign, N, K, lists);\n",
    "\n",
    "    int nonEmpty = 0;\n",
    "    for(const auto& list : lists) if(!list.empty()) nonEmpty++;\n",
    "    printf(\"[INDEX] Non-empty clusters: %d / %d\\n\", nonEmpty, K);\n",
    "\n",
    "    // ---------------------------------------------------------\n",
    "    //  SEARCH PHASE (CPU)\n",
    "    // ---------------------------------------------------------\n",
    "    printf(\"\\n[SEARCH] CPU Search (nprobe=%d)...\\n\", NPROBE);\n",
    "\n",
    "    // Step A: Coarse Search (Find nearest NPROBE clusters)\n",
    "    // Format: {distance, cluster_id}\n",
    "    std::vector<std::pair<float, int>> centerDists;\n",
    "    centerDists.reserve(K);\n",
    "\n",
    "    for (int c = 0; c < K; ++c) {\n",
    "        const float* ctr = &h_finalCentroids[(size_t)c * DIM];\n",
    "        double dotVal = dot_host(q_host.data(), ctr);\n",
    "        float dist = 1.0f - (float)dotVal;\n",
    "        centerDists.push_back({dist, c});\n",
    "    }\n",
    "\n",
    "    // Sort centroids by distance ASC\n",
    "    std::sort(centerDists.begin(), centerDists.end(), \n",
    "              [](const std::pair<float, int>& a, const std::pair<float, int>& b){\n",
    "                  return a.first < b.first;\n",
    "              });\n",
    "\n",
    "    // Step B: Gather Candidates & Exact Search\n",
    "    // Format: {distance, vector_id}\n",
    "    std::vector<std::pair<float, int>> candidates;\n",
    "    // Reserve some memory to avoid reallocations (heuristic)\n",
    "    candidates.reserve((N / K) * NPROBE * 2);\n",
    "\n",
    "    int visitedVecs = 0;\n",
    "    for (int i = 0; i < NPROBE && i < K; ++i) {\n",
    "        int c_id = centerDists[i].second;\n",
    "        const auto& bucket = lists[c_id];\n",
    "        visitedVecs += bucket.size();\n",
    "\n",
    "        for (int vecIdx : bucket) {\n",
    "            const float* vec = &h_data[(size_t)vecIdx * DIM];\n",
    "            double dotVal = dot_host(q_host.data(), vec);\n",
    "            float dist = 1.0f - (float)dotVal;\n",
    "            candidates.push_back({dist, vecIdx});\n",
    "        }\n",
    "    }\n",
    "\n",
    "    printf(\"[SEARCH] Scanned %d vectors from top %d clusters.\\n\", visitedVecs, NPROBE);\n",
    "\n",
    "    // Step C: Ranking (Top-K)\n",
    "    if (candidates.empty()) {\n",
    "        printf(\"No candidates found.\\n\");\n",
    "    } else {\n",
    "        int finalK = std::min((int)candidates.size(), TOPK);\n",
    "        \n",
    "        // Partial sort gives us the smallest K elements at the beginning\n",
    "        std::partial_sort(candidates.begin(), \n",
    "                          candidates.begin() + finalK, \n",
    "                          candidates.end(),\n",
    "                          [](const std::pair<float, int>& a, const std::pair<float, int>& b){\n",
    "                              return a.first < b.first;\n",
    "                          });\n",
    "\n",
    "        printf(\"\\nTop-%d Results:\\n\", finalK);\n",
    "        for (int i = 0; i < finalK; ++i) {\n",
    "            printf(\"%2d) id=%d  dist=%.6f  sim=%.6f\\n\",\n",
    "                   i+1, candidates[i].second, candidates[i].first, 1.f - candidates[i].first);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5009ae69-3720-4533-ad36-22e9d9805804",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc -O3 -std=c++17 -arch=sm_70 kmean_gpu.cu -o kmean_gpu -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bfe5082-b45c-4dd2-b398-69d43ed2b167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==386485== NVPROF is profiling process 386485, command: ./kmean_gpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: Tesla V100-PCIE-32GB\n",
      "SM count: 80\n",
      "Params: N=1048576  K=2048  nprobe=32  TOPK=5  DIM=64  KMEANS_ITERS=15\n",
      "Mode: GPU Training -> CPU Search\n",
      "[INIT] Generating 1048576 vectors...\n",
      "[DEBUG] Query vs Data[0]: dot=0.927471359 dist=0.072528641\n",
      "[TRAIN] Running K-Means on GPU (15 iters)...\n",
      "[INDEX] Building Inverted Lists on Host...\n",
      "[INDEX] Non-empty clusters: 2048 / 2048\n",
      "\n",
      "[SEARCH] CPU Search (nprobe=32)...\n",
      "[SEARCH] Scanned 18343 vectors from top 32 clusters.\n",
      "\n",
      "Top-5 Results:\n",
      " 1) id=0  dist=0.072529  sim=0.927471\n",
      " 2) id=89698  dist=0.157913  sim=0.842087\n",
      " 3) id=913782  dist=0.158968  sim=0.841032\n",
      " 4) id=350035  dist=0.164414  sim=0.835586\n",
      " 5) id=56801  dist=0.177664  sim=0.822336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==386485== Profiling application: ./kmean_gpu\n",
      "==386485== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.57%  55.2780s        15  3.68520s  3.67646s  3.69604s  assignAndAccumulateKernel(float const *, int, float const *, int, int*, double*, int*)\n",
      "                    0.42%  233.02ms         2  116.51ms  96.160us  232.92ms  [CUDA memcpy HtoD]\n",
      "                    0.00%  2.0804ms         2  1.0402ms  113.41us  1.9669ms  [CUDA memcpy DtoH]\n",
      "                    0.00%  2.0160ms        15  134.40us  133.25us  135.10us  updateCentroidsKernel(float*, double const *, int const *, int)\n",
      "                    0.00%  60.928us        30  2.0300us  1.3440us  4.4800us  [CUDA memset]\n",
      "      API calls:   98.51%  55.2807s        30  1.84269s  94.913us  3.69610s  cudaDeviceSynchronize\n",
      "                    1.05%  591.17ms         5  118.23ms  5.4120us  590.38ms  cudaMalloc\n",
      "                    0.42%  238.21ms         4  59.551ms  486.11us  233.98ms  cudaMemcpy\n",
      "                    0.01%  4.4132ms        30  147.11us  12.501us  924.16us  cudaLaunchKernel\n",
      "                    0.00%  1.6140ms        30  53.799us  9.4340us  204.10us  cudaMemset\n",
      "                    0.00%  1.1141ms         5  222.82us  9.4990us  821.85us  cudaFree\n",
      "                    0.00%  249.44us       114  2.1880us     105ns  105.67us  cuDeviceGetAttribute\n",
      "                    0.00%  151.64us         1  151.64us  151.64us  151.64us  cudaGetDeviceProperties\n",
      "                    0.00%  77.833us         1  77.833us  77.833us  77.833us  cuDeviceGetName\n",
      "                    0.00%  23.654us         1  23.654us  23.654us  23.654us  cuDeviceTotalMem\n",
      "                    0.00%  19.879us         1  19.879us  19.879us  19.879us  cuDeviceGetPCIBusId\n",
      "                    0.00%  4.1850us         3  1.3950us     397ns  3.2630us  cuDeviceGetCount\n",
      "                    0.00%  1.3920us         2     696ns     115ns  1.2770us  cuDeviceGet\n",
      "                    0.00%     943ns         1     943ns     943ns     943ns  cuModuleGetLoadingMode\n",
      "                    0.00%     208ns         1     208ns     208ns     208ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./kmean_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7c544e5-7bd0-44c0-bc81-995e72322483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Device-side CUDA Event completion trace is currently enabled.\n",
      "         This may increase runtime overhead and the likelihood of false\n",
      "         dependencies across CUDA Streams. If you wish to avoid this, please\n",
      "         disable the feature with --cuda-event-trace=false.\n",
      "WARNING: CPU IP/backtrace sampling not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n",
      "WARNING: CPU context switch tracing not supported, disabling.\n",
      "Try the 'nsys status --environment' command to learn more.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: N=16777216  K=1024  nprobe=32  TOPK=5  DIM=64  KMEANS_ITERS=15\n",
      "Mode: GPU Training -> CPU Search\n",
      "[INIT] Generating 16777216 vectors...\n",
      "[DEBUG] Query vs Data[0]: dot=0.927471359 dist=0.072528641\n",
      "[TRAIN] Running K-Means on GPU (15 iters)...\n",
      "[INDEX] Building Inverted Lists on Host...\n",
      "[INDEX] Non-empty clusters: 1024 / 1024\n",
      "\n",
      "[SEARCH] CPU Search (nprobe=32)...\n",
      "[SEARCH] Scanned 557455 vectors from top 32 clusters.\n",
      "\n",
      "Top-5 Results:\n",
      " 1) id=0  dist=0.072529  sim=0.927471\n",
      " 2) id=15528589  dist=0.136097  sim=0.863903\n",
      " 3) id=13929498  dist=0.139304  sim=0.860696\n",
      " 4) id=8185180  dist=0.146311  sim=0.853689\n",
      " 5) id=16494452  dist=0.150325  sim=0.849675\n",
      "Collecting data...\n",
      "Generating '/tmp/nsys-report-bf67.qdstrm'\n",
      "[1/1] [========================100%] kmean_gpu.nsys-rep\n",
      "Generated:\n",
      "\t/home/jupyter-feifan_chen@dlsu.e-15ebb/kmean_gpu.nsys-rep\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nsys profile -o kmean_gpu ./kmean_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "083df34d-0759-4049-80e0-c99062e2ce28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kmean_cpu.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile kmean_cpu.cpp\n",
    "\n",
    "#include <cstdio>\n",
    "#include <vector>\n",
    "#include <random>\n",
    "#include <algorithm>\n",
    "#include <numeric>\n",
    "#include <cmath>\n",
    "#include <cassert>\n",
    "#include <unordered_set>\n",
    "#include <limits>\n",
    "#include <cfloat>\n",
    "#include <cstring>\n",
    "\n",
    "// ---------------- Config ----------------\n",
    "static const int DIM          = 64;\n",
    "static const float ALPHA      = 0.7f;\n",
    "static const int SEED         = 2025; \n",
    "static const int N            = 1 << 14; // demo: 16384\n",
    "static const int K            = 1024;\n",
    "static const int NPROBE       = 4;       // cluster depth during search\n",
    "static const int TOPK         = 5;\n",
    "\n",
    "static const int KMEANS_ITERS = 15;      // K-Means iters\n",
    "\n",
    "using Vec = std::vector<float>;\n",
    "\n",
    "// ---------------- Embedding basic ----------------\n",
    "\n",
    "static Vec numberBase[76]; // 1..75\n",
    "static Vec posBase[25];    // 0..24\n",
    "\n",
    "static void normInPlace(Vec &v) {\n",
    "    double s = 0;\n",
    "    for (float x : v) s += (double)x * x;\n",
    "    float n = float(std::sqrt(s) + 1e-12);\n",
    "    for (float &x : v) x /= n;\n",
    "}\n",
    "\n",
    "static Vec randUnit(std::mt19937 &rng) {\n",
    "    std::uniform_real_distribution<float> U(-1.f, 1.f);\n",
    "    Vec v(DIM);\n",
    "    for (int i = 0; i < DIM; i++) v[i] = U(rng);\n",
    "    normInPlace(v);\n",
    "    return v;\n",
    "}\n",
    "\n",
    "static void initBases() {\n",
    "    std::mt19937 rng(SEED);\n",
    "    for (int n = 1; n <= 75; n++) numberBase[n] = randUnit(rng);\n",
    "    for (int i = 0; i < 25; i++)  posBase[i]    = randUnit(rng);\n",
    "}\n",
    "\n",
    "static Vec cardToVec(const int card[25]) {\n",
    "    Vec out(DIM, 0.f);\n",
    "    for (int i = 0; i < 25; i++) {\n",
    "        int n = card[i];\n",
    "        const Vec &b = numberBase[n];\n",
    "        const Vec &p = posBase[i];\n",
    "        for (int j = 0; j < DIM; j++)\n",
    "            out[j] += b[j] + ALPHA * p[j];\n",
    "    }\n",
    "    normInPlace(out);\n",
    "    return out;\n",
    "}\n",
    "\n",
    "static void genCard(std::mt19937 &rng, int out[25]) {\n",
    "    std::vector<int> p(75);\n",
    "    std::iota(p.begin(), p.end(), 1);\n",
    "    std::shuffle(p.begin(), p.end(), rng);\n",
    "    for (int i = 0; i < 25; i++) out[i] = p[i];\n",
    "}\n",
    "\n",
    "static double dot_host(const float* a, const float* b) {\n",
    "    double s = 0;\n",
    "    for (int i = 0; i < DIM; i++) s += (double)a[i] * b[i];\n",
    "    return s;\n",
    "}\n",
    "\n",
    "// ---------------- Device: Distance Kernels (Simulated for Training) ----------------\n",
    "\n",
    "/**\n",
    " * E-Step: Assign data to nearest centroid & Accumulate stats\n",
    " * * This function simulates the \"Expectation\" step of K-Means.\n",
    " * It iterates through every data point, finds the closest centroid (using Cosine Distance),\n",
    " * assigns the point to that cluster, and accumulates the vector sums and counts\n",
    " * needed for the next update step.\n",
    " */\n",
    "void assignAndAccumulateKernel(const float* data,\n",
    "                                  int N_points,\n",
    "                                  const float* centroids,\n",
    "                                  int K_clusters,\n",
    "                                  int* assign,\n",
    "                                  float* sums,\n",
    "                                  int* counts) {\n",
    "    \n",
    "    // Loop 1: Iterate through every single data point (0 to N-1)\n",
    "    for (int i = 0; i < N_points; i++) {\n",
    "        \n",
    "        // Get pointer to the current data vector (Dimension = DIM)\n",
    "        const float* xi = data + (size_t)i * DIM;\n",
    "\n",
    "        int bestC = 0;          // Store the index of the nearest cluster\n",
    "        float bestD = 1e30f;    // Initialize minimum distance to a large value\n",
    "\n",
    "        // Loop 2: Compare current point 'xi' against all K centroids\n",
    "        for (int c = 0; c < K_clusters; ++c) {\n",
    "            const float* ctr = centroids + (size_t)c * DIM;\n",
    "            \n",
    "            // Calculate Dot Product (Inner Product)\n",
    "            float dot = 0.f;\n",
    "            for (int d = 0; d < DIM; ++d) dot += xi[d] * ctr[d];\n",
    "\n",
    "            // Convert Cosine Similarity to Cosine Distance\n",
    "            // Distance = 1.0 - Similarity\n",
    "            float dist = 1.f - dot;\n",
    "\n",
    "            // Keep track of the nearest centroid found so far\n",
    "            if (dist < bestD) {\n",
    "                bestD = dist;\n",
    "                bestC = c;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // 1. Record the assignment: Point 'i' belongs to Cluster 'bestC'\n",
    "        assign[i] = bestC;\n",
    "\n",
    "        // 2. Accumulate count: Increment the member count for this cluster\n",
    "        counts[bestC]++;\n",
    "\n",
    "        // 3. Accumulate sums: Add this vector's coordinates to the cluster's total\n",
    "        // This prepares for the average calculation in the next step.\n",
    "        size_t base = (size_t)bestC * DIM;\n",
    "        for (int d = 0; d < DIM; ++d) {\n",
    "            sums[base + d] += xi[d];\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "/**\n",
    " * M-Step: Update Centroids\n",
    " * * This function simulates the \"Maximization\" step of K-Means.\n",
    " * It calculates the new position of each centroid by averaging the vectors \n",
    " * assigned to it, and then normalizes the result to ensure it stays on the unit hypersphere.\n",
    " */\n",
    "void updateCentroidsKernel(float* centroids,\n",
    "                                  const float* sums,\n",
    "                                  const int* counts,\n",
    "                                  int K_clusters) {\n",
    "    \n",
    "    // Loop 1: Iterate through every cluster (0 to K-1)\n",
    "    for (int c = 0; c < K_clusters; c++) {\n",
    "        \n",
    "        int cnt = counts[c];    // Number of points in this cluster\n",
    "        \n",
    "        // Pointers to the current centroid and its accumulated sum\n",
    "        float* ctr = centroids + (size_t)c * DIM;\n",
    "        const float* sumc = sums + (size_t)c * DIM;\n",
    "    \n",
    "        // Only update if the cluster is not empty\n",
    "        if (cnt > 0) {\n",
    "            double norm2 = 0.0;\n",
    "\n",
    "            // Loop 2: Calculate the Mean (Average) Vector\n",
    "            for (int d = 0; d < DIM; ++d) {\n",
    "                // New Coordinate = Total Sum / Count\n",
    "                float v = sumc[d] / (float)cnt;\n",
    "                ctr[d] = v;\n",
    "\n",
    "                // Accumulate squared magnitude for normalization later\n",
    "                norm2 += (double)v * (double)v;\n",
    "            }\n",
    "\n",
    "            // Calculate the L2 Norm (Euclidean length)\n",
    "            // Added 1e-12 to prevent division by zero\n",
    "            float n = float(std::sqrt(norm2) + 1e-12);\n",
    "\n",
    "            // Loop 3: Normalization\n",
    "            // Since we use Cosine Distance, centroids must be normalized \n",
    "            // (length = 1.0) to lie on the unit sphere.\n",
    "            for (int d = 0; d < DIM; ++d) {\n",
    "                ctr[d] /= n;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// ---------------- Host: Inverted Lists ----------------\n",
    "\n",
    "static void buildInvertedLists(\n",
    "    const std::vector<int>& assign,\n",
    "    int N_points, int K_clusters,\n",
    "    std::vector<std::vector<int>>& lists\n",
    ") {\n",
    "    lists.assign(K_clusters, {});\n",
    "    for (int i = 0; i < N_points; ++i) {\n",
    "        int c = assign[i];\n",
    "        if (c >= 0 && c < K_clusters) {\n",
    "            lists[c].push_back(i);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// ---------------- Main ----------------\n",
    "int main() {\n",
    "    printf(\"Params: N=%d  K=%d  nprobe=%d  TOPK=%d  DIM=%d  KMEANS_ITERS=%d\\n\",\n",
    "           N, K, NPROBE, TOPK, DIM, KMEANS_ITERS);\n",
    "\n",
    "    initBases();\n",
    "    std::mt19937 rng(SEED + 7);\n",
    "\n",
    "    clock_t start, end;\n",
    "    double elapse = 0.0f;\n",
    "\n",
    "    // 1) Building dataset\n",
    "    std::vector<int>   h_cards((size_t)N * 25);\n",
    "    std::vector<float> h_data((size_t)N * DIM);\n",
    "\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        int c[25];\n",
    "        genCard(rng, c);\n",
    "        for (int t = 0; t < 25; ++t) h_cards[(size_t)i * 25 + t] = c[t];\n",
    "        Vec v = cardToVec(c);\n",
    "        for (int d = 0; d < DIM; ++d) h_data[(size_t)i * DIM + d] = v[d];\n",
    "    }\n",
    "\n",
    "    // 2) Build query\n",
    "    int qc[25];\n",
    "    for (int t = 0; t < 25; ++t) qc[t] = h_cards[t];\n",
    "    qc[3] = 75; qc[17] = 1; std::swap(qc[5], qc[19]);\n",
    "    Vec qvec = cardToVec(qc);\n",
    "    std::vector<float> qhost(qvec.begin(), qvec.end());\n",
    "\n",
    "    {\n",
    "        std::vector<float> d0(DIM);\n",
    "        for (int i = 0; i < DIM; i++) d0[i] = h_data[i];\n",
    "        double dot0 = dot_host(qhost.data(), d0.data());\n",
    "        printf(\"[DEBUG #1] host dot(q, data[0])=%.9f  dist=%.9f\\n\", dot0, 1.0 - dot0);\n",
    "    }\n",
    "\n",
    "    // 3) Pseudo-GPU Buffers (Training)\n",
    "    float *d_data = 0, *d_centroids = 0;\n",
    "    d_data = (float*)malloc((size_t)N * DIM * sizeof(float));\n",
    "    d_centroids = (float*)malloc((size_t)K * DIM * sizeof(float));\n",
    "\n",
    "    memcpy(d_data, h_data.data(), (size_t)N * DIM * sizeof(float));\n",
    "\n",
    "    // 4) Initial centroids\n",
    "    {\n",
    "        std::vector<int> idx(N);\n",
    "        std::iota(idx.begin(), idx.end(), 0);\n",
    "        std::shuffle(idx.begin(), idx.end(), rng);\n",
    "        std::vector<float> h_initC((size_t)K * DIM);\n",
    "        for (int c = 0; c < K; ++c) {\n",
    "            int i = idx[c];\n",
    "            std::copy_n(&h_data[(size_t)i * DIM], DIM, &h_initC[(size_t)c * DIM]);\n",
    "        }\n",
    "        memcpy(d_centroids, h_initC.data(), (size_t)K * DIM * sizeof(float));\n",
    "    }\n",
    "\n",
    "    int   *d_assign = (int*)malloc(N * sizeof(int));\n",
    "    float *d_sums   = (float*)malloc((size_t)K * DIM * sizeof(float));\n",
    "    int   *d_counts = (int*)malloc(K * sizeof(int));\n",
    "\n",
    "    // 5) K-Means Training (Simulating GPU Kernel Loop)\n",
    "    {\n",
    "        start = clock();\n",
    "        printf(\"[BUILD] K-Means: iters=%d\\n\", KMEANS_ITERS);\n",
    "\n",
    "        for (int it = 0; it < KMEANS_ITERS; ++it) {\n",
    "            memset(d_sums,   0, (size_t)K * DIM * sizeof(float));\n",
    "            memset(d_counts, 0, K * sizeof(int));\n",
    "\n",
    "            assignAndAccumulateKernel(d_data, N, d_centroids, K, d_assign, d_sums, d_counts);\n",
    "            updateCentroidsKernel(d_centroids, d_sums, d_counts, K);\n",
    "        }\n",
    "\n",
    "        end = clock();\n",
    "        double time_taken = ((double)(end-start))*1E3/CLOCKS_PER_SEC;\n",
    "        elapse += time_taken;\n",
    "        printf(\"K-means (C++ impl) time: %f ms\\n\", time_taken);\n",
    "    }\n",
    "\n",
    "    // 6) Build Inverted Index on Host\n",
    "    //    Retrieve assignment from \"device\"\n",
    "    std::vector<int> h_assign(N);\n",
    "    memcpy(h_assign.data(), d_assign, N * sizeof(int));\n",
    "\n",
    "    std::vector<std::vector<int>> lists;\n",
    "    buildInvertedLists(h_assign, N, K, lists);\n",
    "\n",
    "    int nonEmpty = 0;\n",
    "    for (int c = 0; c < K; ++c) if (!lists[c].empty()) nonEmpty++;\n",
    "    printf(\"[BUILD] Non-empty clusters: %d / %d\\n\", nonEmpty, K);\n",
    "\n",
    "    // =================================================================================\n",
    "    // CPU Search\n",
    "    // =================================================================================\n",
    "\n",
    "    start = clock();\n",
    "    printf(\"\\n[SEARCH] CPU Search logic (matching origin.cu, nprobe=%d)...\\n\", NPROBE);\n",
    "\n",
    "    // Step A: Coarse Search (Find nearest NPROBE clusters)\n",
    "    // Format: {distance, cluster_id}\n",
    "    std::vector<std::pair<float, int>> centerDists;\n",
    "    centerDists.reserve(K);\n",
    "\n",
    "    for (int c = 0; c < K; ++c) {\n",
    "        // d_centroids is a flat array, similar to how we used it in GPU code\n",
    "        const float* ctr = d_centroids + (size_t)c * DIM; \n",
    "        double dotVal = dot_host(qhost.data(), ctr);\n",
    "        float dist = 1.0f - (float)dotVal;\n",
    "        centerDists.push_back({dist, c});\n",
    "    }\n",
    "\n",
    "    // Sort centroids by distance ASC\n",
    "    std::sort(centerDists.begin(), centerDists.end());\n",
    "\n",
    "    // Step B: Gather Candidates & Exact Search\n",
    "    // Format: {distance, vector_id}\n",
    "    std::vector<std::pair<float, int>> candidates;\n",
    "    // Heuristic reserve\n",
    "    candidates.reserve((N / K) * NPROBE * 2);\n",
    "\n",
    "    int visitedVecs = 0;\n",
    "    for (int i = 0; i < NPROBE && i < K; ++i) {\n",
    "        int c_id = centerDists[i].second;\n",
    "        const auto& bucket = lists[c_id];\n",
    "        visitedVecs += (int)bucket.size();\n",
    "\n",
    "        for (int vecIdx : bucket) {\n",
    "            // Access raw data directly (Host DRAM)\n",
    "            const float* vec = &h_data[(size_t)vecIdx * DIM];\n",
    "            double dotVal = dot_host(qhost.data(), vec);\n",
    "            float dist = 1.0f - (float)dotVal;\n",
    "            candidates.push_back({dist, vecIdx});\n",
    "        }\n",
    "    }\n",
    "\n",
    "    printf(\"[SEARCH] Scanned %d vectors from top %d clusters.\\n\", visitedVecs, NPROBE);\n",
    "\n",
    "    // Step C: Ranking (Top-K)\n",
    "    if (candidates.empty()) {\n",
    "        printf(\"No candidates found.\\n\");\n",
    "    } else {\n",
    "        int finalK = std::min((int)candidates.size(), TOPK);\n",
    "        \n",
    "        // Use partial_sort like origin.cu\n",
    "        std::partial_sort(candidates.begin(), \n",
    "                          candidates.begin() + finalK, \n",
    "                          candidates.end());\n",
    "\n",
    "        printf(\"\\nTop-%d Results:\\n\", finalK);\n",
    "        for (int i = 0; i < finalK; ++i) {\n",
    "            printf(\"%2d) id=%d  dist=%.6f  sim=%.6f\\n\",\n",
    "                   i+1, candidates[i].second, candidates[i].first, 1.f - candidates[i].first);\n",
    "        }\n",
    "\n",
    "        // Verify with best (optional check)\n",
    "        if (finalK > 0) {\n",
    "            int bestId = candidates[0].second;\n",
    "            const float* vec = &h_data[(size_t)bestId * DIM];\n",
    "            double dotChk = dot_host(qhost.data(), vec);\n",
    "            printf(\"[DEBUG] host check best id=%d  dot=%.9f  dist=%.9f\\n\",\n",
    "                   bestId, dotChk, 1.0 - dotChk);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    end = clock();\n",
    "    double search_time = ((double)(end-start))*1E3/CLOCKS_PER_SEC;\n",
    "    printf(\"Function (Search Phase) time: %f ms\\n\", search_time);\n",
    "\n",
    "    // Cleanup\n",
    "    free(d_data);\n",
    "    free(d_centroids);\n",
    "    free(d_assign);\n",
    "    free(d_sums);\n",
    "    free(d_counts);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d8b8518-6fc4-4936-b472-2b8bc8741fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "g++ -std=c++11 kmean_cpu.cpp -o kmean_cpu -lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d632baf9-9c20-41f1-a5d0-71d2c152a8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: N=16384  K=1024  nprobe=4  TOPK=5  DIM=64  KMEANS_ITERS=15\n",
      "[DEBUG #1] host dot(q, data[0])=0.927471359  dist=0.072528641\n",
      "[BUILD] K-Means: iters=15\n",
      "K-means (C++ impl) time: 70167.580000 ms\n",
      "[BUILD] Non-empty clusters: 1024 / 1024\n",
      "\n",
      "[SEARCH] CPU Search logic (matching origin.cu, nprobe=4)...\n",
      "[SEARCH] Scanned 105 vectors from top 4 clusters.\n",
      "\n",
      "Top-5 Results:\n",
      " 1) id=0  dist=0.072529  sim=0.927471\n",
      " 2) id=15967  dist=0.177058  sim=0.822942\n",
      " 3) id=1427  dist=0.216366  sim=0.783634\n",
      " 4) id=3831  dist=0.226154  sim=0.773846\n",
      " 5) id=10211  dist=0.246999  sim=0.753001\n",
      "[DEBUG] host check best id=0  dot=0.927471359  dist=0.072528641\n",
      "Function (Search Phase) time: 1.645000 ms\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./kmean_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b821c5d-97f0-4962-92bf-95485999cecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kmean_gpu_share_mem.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile kmean_gpu_share_mem.cu\n",
    "\n",
    "#include <cuda_runtime.h>\n",
    "#include <cstdio>\n",
    "#include <vector>\n",
    "#include <random>\n",
    "#include <algorithm>\n",
    "#include <numeric>\n",
    "#include <cmath>\n",
    "#include <cassert>\n",
    "#include <cfloat>\n",
    "\n",
    "// ---------------- Config ----------------\n",
    "static const int DIM          = 64;\n",
    "static const float ALPHA      = 0.7f;\n",
    "static const int SEED         = 2025; \n",
    "static const int N            = 1 << 20; // 1 Million vectors\n",
    "static const int K            = 2048;    // Clusters\n",
    "static const int NPROBE       = 32;      // Search depth\n",
    "static const int TOPK         = 5;\n",
    "static const int KMEANS_ITERS = 15;      // K-Means iterations\n",
    "static int BLOCK              = 512;     // Thread block size\n",
    "\n",
    "// Tiling config for Shared Memory\n",
    "// We load TILE_K centroids at a time into shared memory.\n",
    "// 128 centroids * 64 floats * 4 bytes = 32 KB (Safe for essentially all GPUs)\n",
    "#define TILE_K 128 \n",
    "\n",
    "using Vec = std::vector<float>;\n",
    "\n",
    "// ---------------- Helper for AtomicAdd Double ----------------\n",
    "// Compute Capability < 6.0 needs a CAS loop for double atomicAdd.\n",
    "#if !defined(__CUDA_ARCH__) || __CUDA_ARCH__ >= 600\n",
    "#else\n",
    "__device__ double atomicAdd(double* address, double val) {\n",
    "    unsigned long long int* address_as_ull = (unsigned long long int*)address;\n",
    "    unsigned long long int old = *address_as_ull, assumed;\n",
    "    do {\n",
    "        assumed = old;\n",
    "        old = atomicCAS(address_as_ull, assumed,\n",
    "                        __double_as_longlong(val + __longlong_as_double(assumed)));\n",
    "    } while (assumed != old);\n",
    "    return __longlong_as_double(old);\n",
    "}\n",
    "#endif\n",
    "\n",
    "// ---------------- Embedding Generator ----------------\n",
    "static Vec numberBase[76]; \n",
    "static Vec posBase[25];    \n",
    "\n",
    "static void normInPlace(Vec &v) {\n",
    "    double s = 0;\n",
    "    for (float x : v) s += (double)x * x;\n",
    "    float n = float(std::sqrt(s) + 1e-12);\n",
    "    for (float &x : v) x /= n;\n",
    "}\n",
    "\n",
    "static Vec randUnit(std::mt19937 &rng) {\n",
    "    std::uniform_real_distribution<float> U(-1.f, 1.f);\n",
    "    Vec v(DIM);\n",
    "    for (int i = 0; i < DIM; i++) v[i] = U(rng);\n",
    "    normInPlace(v);\n",
    "    return v;\n",
    "}\n",
    "\n",
    "static void initBases() {\n",
    "    std::mt19937 rng(SEED);\n",
    "    for (int n = 1; n <= 75; n++) numberBase[n] = randUnit(rng);\n",
    "    for (int i = 0; i < 25; i++)  posBase[i]    = randUnit(rng);\n",
    "}\n",
    "\n",
    "static Vec cardToVec(const int card[25]) {\n",
    "    Vec out(DIM, 0.f);\n",
    "    for (int i = 0; i < 25; i++) {\n",
    "        int n = card[i];\n",
    "        const Vec &b = numberBase[n];\n",
    "        const Vec &p = posBase[i];\n",
    "        for (int j = 0; j < DIM; j++)\n",
    "            out[j] += b[j] + ALPHA * p[j];\n",
    "    }\n",
    "    normInPlace(out);\n",
    "    return out;\n",
    "}\n",
    "\n",
    "static void genCard(std::mt19937 &rng, int out[25]) {\n",
    "    std::vector<int> p(75);\n",
    "    std::iota(p.begin(), p.end(), 1);\n",
    "    std::shuffle(p.begin(), p.end(), rng);\n",
    "    for (int i = 0; i < 25; i++) out[i] = p[i];\n",
    "}\n",
    "\n",
    "static double dot_host(const float* a, const float* b) {\n",
    "    double s = 0;\n",
    "    for (int i = 0; i < DIM; i++) s += (double)a[i] * b[i];\n",
    "    return s;\n",
    "}\n",
    "\n",
    "// ---------------- GPU K-Means Kernels (Optimized) ----------------\n",
    "\n",
    "// E-Step:\n",
    "// 1. Tiled Shared Memory loading for Centroids.\n",
    "// 2. Per-Block Accumulation.\n",
    "__global__ void assignAndAccumulatePerBlockKernel_V3(\n",
    "                                         const float* data, int N,\n",
    "                                         const float* centroids, int K,\n",
    "                                         int* assign,\n",
    "                                         double* block_sums,   // Output: (GridSize * K * DIM)\n",
    "                                         int* block_counts) {  // Output: (GridSize * K)\n",
    "    \n",
    "    // Shared memory buffer to cache a tile of centroids\n",
    "    __shared__ float sh_centroids[TILE_K * DIM];\n",
    "    \n",
    "    // Offsets for this specific block's accumulation buffer in global memory\n",
    "    size_t block_sum_base = (size_t)blockIdx.x * (size_t)K * DIM;\n",
    "    size_t block_count_base = (size_t)blockIdx.x * (size_t)K;\n",
    "\n",
    "    // Grid-Stride Loop\n",
    "    for (int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "         i < N;\n",
    "         i += gridDim.x * blockDim.x) {\n",
    "\n",
    "        const float* xi = data + (size_t)i * DIM;\n",
    "\n",
    "        int bestC = 0;\n",
    "        float bestD = 1e30f;\n",
    "        \n",
    "        // Loop over Centroids in chunks (Tiles)\n",
    "        for (int k_tile = 0; k_tile < K; k_tile += TILE_K) {\n",
    "            \n",
    "            // --- Phase 1: Load Tile into Shared Memory ---\n",
    "            int k_start = k_tile;\n",
    "            \n",
    "            // Cooperative loading: threads load distinct floats\n",
    "            for (int t = threadIdx.x; t < TILE_K * DIM; t += blockDim.x) {\n",
    "                int local_c = t / DIM;\n",
    "                int local_d = t % DIM;\n",
    "                int global_c = k_start + local_c;\n",
    "                \n",
    "                if (global_c < K) {\n",
    "                    sh_centroids[t] = centroids[(size_t)global_c * DIM + local_d];\n",
    "                } else {\n",
    "                    sh_centroids[t] = 0.0f; // Padding\n",
    "                }\n",
    "            }\n",
    "            __syncthreads(); // Wait for tile load to complete\n",
    "            \n",
    "            // --- Phase 2: Compute Distances against Tile ---\n",
    "            int k_limit = (k_tile + TILE_K > K) ? (K - k_tile) : TILE_K;\n",
    "\n",
    "            for (int c_local = 0; c_local < k_limit; ++c_local) {\n",
    "                int c_global = k_start + c_local;\n",
    "                \n",
    "                float dot = 0.f;\n",
    "                \n",
    "                for (int d = 0; d < DIM; ++d) {\n",
    "                    dot += xi[d] * sh_centroids[c_local * DIM + d];\n",
    "                }\n",
    "                \n",
    "                float dist = 1.f - dot;\n",
    "                if (dist < bestD) {\n",
    "                    bestD = dist;\n",
    "                    bestC = c_global;\n",
    "                }\n",
    "            }\n",
    "            __syncthreads(); // Sync before loading next tile\n",
    "        }\n",
    "\n",
    "        assign[i] = bestC;\n",
    "\n",
    "        // --- Accumulation ---\n",
    "        // We atomicAdd to THIS block's specific buffer.\n",
    "        atomicAdd(&block_counts[block_count_base + bestC], 1);\n",
    "\n",
    "        size_t cluster_base = block_sum_base + (size_t)bestC * DIM;\n",
    "        for (int d = 0; d < DIM; ++d) {\n",
    "            atomicAdd(&block_sums[cluster_base + d], (double)xi[d]);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void reduceSumsKernel(double* final_sums, \n",
    "                                 int* final_counts, \n",
    "                                 const double* block_sums, \n",
    "                                 const int* block_counts, \n",
    "                                 int K, int GridSize) {\n",
    "    \n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    // Reduce Counts: 1 thread per cluster\n",
    "    if (idx < K) {\n",
    "        int total_cnt = 0;\n",
    "        for (int b = 0; b < GridSize; ++b) {\n",
    "            total_cnt += block_counts[(size_t)b * K + idx];\n",
    "        }\n",
    "        final_counts[idx] = total_cnt;\n",
    "    }\n",
    "    \n",
    "    // Reduce Sums\n",
    "    size_t total_elements = (size_t)K * DIM;\n",
    "    for (size_t i = idx; i < total_elements; i += gridDim.x * blockDim.x) {\n",
    "        double total_sum = 0.0;\n",
    "        for (int b = 0; b < GridSize; ++b) {\n",
    "            total_sum += block_sums[(size_t)b * total_elements + i];\n",
    "        }\n",
    "        final_sums[i] = total_sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "// M-step: Update centroids (Standard)\n",
    "__global__ void updateCentroidsKernel(float* centroids,\n",
    "                                      const double* sums, \n",
    "                                      const int* counts,\n",
    "                                      int K) {\n",
    "    int c = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (c >= K) return;\n",
    "\n",
    "    int cnt = counts[c];\n",
    "    float* ctr = centroids + (size_t)c * DIM;\n",
    "    const double* sumc = sums + (size_t)c * DIM; \n",
    "\n",
    "    if (cnt > 0) {\n",
    "        double norm2 = 0.0;\n",
    "        for (int d = 0; d < DIM; ++d) {\n",
    "            double v_double = sumc[d] / (double)cnt; // Mean\n",
    "            float v = (float)v_double;\n",
    "            ctr[d] = v;\n",
    "            norm2 += v_double * v_double;\n",
    "        }\n",
    "        // Normalize\n",
    "        float n = float(std::sqrt(norm2) + 1e-12);\n",
    "        for (int d = 0; d < DIM; ++d) {\n",
    "            ctr[d] /= n;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// ---------------- Host Helpers ----------------\n",
    "\n",
    "static void buildInvertedLists(\n",
    "    const std::vector<int>& assign,\n",
    "    int N, int K,\n",
    "    std::vector<std::vector<int>>& lists\n",
    ") {\n",
    "    lists.assign(K, {});\n",
    "    for (int i = 0; i < N; ++i) {\n",
    "        int c = assign[i];\n",
    "        if (c >= 0 && c < K) {\n",
    "            lists[c].push_back(i);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// ---------------- Main ----------------\n",
    "int main() {\n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, 0);\n",
    "\n",
    "    printf(\"Params: N=%d  K=%d  DIM=%d  BLOCK=%d\\n\", N, K, DIM, BLOCK);\n",
    "    printf(\"Mode: GPU Training V3.0 (No Unroll Pragma)\\n\");\n",
    "\n",
    "    initBases();\n",
    "    std::mt19937 rng(SEED + 7);\n",
    "\n",
    "    // 1) Data Generation\n",
    "    std::vector<int>  h_cards((size_t)N * 25);\n",
    "    std::vector<float> h_data((size_t)N * DIM);\n",
    "    printf(\"[INIT] Generating %d vectors...\\n\", N);\n",
    "    \n",
    "    for (int i = 0; i < N; i++) {\n",
    "        int c[25]; genCard(rng, c);\n",
    "        for (int t = 0; t < 25; ++t) h_cards[(size_t)i * 25 + t] = c[t];\n",
    "        Vec v = cardToVec(c);\n",
    "        for (int d = 0; d < DIM; ++d) h_data[(size_t)i * DIM + d] = v[d];\n",
    "    }\n",
    "\n",
    "    // 2) Build Query\n",
    "    int qc[25];\n",
    "    for (int t = 0; t < 25; ++t) qc[t] = h_cards[t]; \n",
    "    qc[3] = 75; qc[17] = 1; std::swap(qc[5], qc[19]); \n",
    "    Vec qvec = cardToVec(qc);\n",
    "    std::vector<float> q_host(qvec.begin(), qvec.end());\n",
    "\n",
    "    {\n",
    "        double dot0 = dot_host(q_host.data(), &h_data[0]);\n",
    "        printf(\"[DEBUG] Query vs Data[0]: dot=%.9f dist=%.9f\\n\", dot0, 1.0 - dot0);\n",
    "    }\n",
    "\n",
    "    // 3) GPU Allocations\n",
    "    float *d_data = 0, *d_centroids = 0;\n",
    "    int   *d_assign = 0;\n",
    "\n",
    "    // Final Buffers\n",
    "    double *d_sums_final = 0; \n",
    "    int    *d_counts_final = 0;\n",
    "    \n",
    "    // Temporary Block Buffers\n",
    "    double *d_block_sums = 0;\n",
    "    int    *d_block_counts = 0;\n",
    "\n",
    "    // Grid Calculation\n",
    "    dim3 block(BLOCK);\n",
    "    dim3 gridN((N + BLOCK - 1) / BLOCK);\n",
    "    int GridSize = gridN.x;\n",
    "    \n",
    "    // Determine kernel launch dim for reduction\n",
    "    dim3 gridReduce((K * DIM + BLOCK - 1) / BLOCK);\n",
    "    \n",
    "    // Determine kernel launch dim for update\n",
    "    dim3 gridUpdate((K + BLOCK - 1) / BLOCK);\n",
    "\n",
    "    size_t szBlockSums   = (size_t)GridSize * K * DIM * sizeof(double);\n",
    "    size_t szBlockCounts = (size_t)GridSize * K * sizeof(int);\n",
    "\n",
    "    cudaMalloc(&d_data,      (size_t)N * DIM * sizeof(float));\n",
    "    cudaMalloc(&d_centroids, (size_t)K * DIM * sizeof(float));\n",
    "    cudaMalloc(&d_assign,    N * sizeof(int));\n",
    "    \n",
    "    cudaMalloc(&d_sums_final,   (size_t)K * DIM * sizeof(double));\n",
    "    cudaMalloc(&d_counts_final, K * sizeof(int));\n",
    "    \n",
    "    cudaMalloc(&d_block_sums,   szBlockSums);\n",
    "    cudaMalloc(&d_block_counts, szBlockCounts);\n",
    "\n",
    "    // Copy Data\n",
    "    cudaMemcpy(d_data, h_data.data(), (size_t)N * DIM * sizeof(float), cudaMemcpyHostToDevice);\n",
    "\n",
    "    // 4) Initialize Centroids\n",
    "    {\n",
    "        std::vector<int> idx(N);\n",
    "        std::iota(idx.begin(), idx.end(), 0);\n",
    "        std::shuffle(idx.begin(), idx.end(), rng);\n",
    "        std::vector<float> h_initC((size_t)K * DIM);\n",
    "        for (int c = 0; c < K; ++c) {\n",
    "            int i = idx[c];\n",
    "            std::copy_n(&h_data[(size_t)i * DIM], DIM, &h_initC[(size_t)c * DIM]);\n",
    "        }\n",
    "        cudaMemcpy(d_centroids, h_initC.data(), (size_t)K * DIM * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    }\n",
    "\n",
    "    // 5) GPU K-Means Training Loop\n",
    "    printf(\"[TRAIN] Starting V3.0 K-Means (%d iters)...\\n\", KMEANS_ITERS);\n",
    "    \n",
    "    for (int it = 0; it < KMEANS_ITERS; ++it) {\n",
    "        // A. Clear Block Accumulators\n",
    "        cudaMemset(d_block_sums,   0, szBlockSums);\n",
    "        cudaMemset(d_block_counts, 0, szBlockCounts);\n",
    "        \n",
    "        // B. E-Step\n",
    "        assignAndAccumulatePerBlockKernel_V3<<<gridN, block>>>(\n",
    "            d_data, N, d_centroids, K, d_assign, d_block_sums, d_block_counts\n",
    "        );\n",
    "        \n",
    "        // C. Reduction\n",
    "        reduceSumsKernel<<<gridReduce, block>>>(\n",
    "            d_sums_final, d_counts_final, d_block_sums, d_block_counts, K, GridSize\n",
    "        );\n",
    "        \n",
    "        // D. M-Step\n",
    "        updateCentroidsKernel<<<gridUpdate, block>>>(\n",
    "            d_centroids, d_sums_final, d_counts_final, K\n",
    "        );\n",
    "        cudaDeviceSynchronize();\n",
    "    }\n",
    "    printf(\"[TRAIN] Done.\\n\");\n",
    "\n",
    "    // 6) Retrieve Results\n",
    "    std::vector<int> h_assign(N);\n",
    "    cudaMemcpy(h_assign.data(), d_assign, N * sizeof(int), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    std::vector<float> h_finalCentroids(K * DIM);\n",
    "    cudaMemcpy(h_finalCentroids.data(), d_centroids, (size_t)K * DIM * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // Cleanup GPU\n",
    "    cudaFree(d_data); cudaFree(d_centroids); cudaFree(d_assign);\n",
    "    cudaFree(d_sums_final); cudaFree(d_counts_final);\n",
    "    cudaFree(d_block_sums); cudaFree(d_block_counts);\n",
    "\n",
    "    // 7) Build Host Index\n",
    "    printf(\"[INDEX] Building Inverted Lists...\\n\");\n",
    "    std::vector<std::vector<int>> lists;\n",
    "    buildInvertedLists(h_assign, N, K, lists);\n",
    "\n",
    "    int nonEmpty = 0;\n",
    "    for(const auto& list : lists) if(!list.empty()) nonEmpty++;\n",
    "    printf(\"[INDEX] Non-empty clusters: %d / %d\\n\", nonEmpty, K);\n",
    "    \n",
    "    if (nonEmpty < K * 0.1) {\n",
    "        printf(\"WARNING: Too many empty clusters! Check initialization or data distribution.\\n\");\n",
    "    }\n",
    "\n",
    "    // 8) CPU Search\n",
    "    printf(\"\\n[SEARCH] CPU Search (nprobe=%d)...\\n\", NPROBE);\n",
    "\n",
    "    // Coarse Search\n",
    "    std::vector<std::pair<float, int>> centerDists;\n",
    "    centerDists.reserve(K);\n",
    "    for (int c = 0; c < K; ++c) {\n",
    "        const float* ctr = &h_finalCentroids[(size_t)c * DIM];\n",
    "        double dotVal = dot_host(q_host.data(), ctr);\n",
    "        float dist = 1.0f - (float)dotVal;\n",
    "        centerDists.push_back({dist, c});\n",
    "    }\n",
    "    std::sort(centerDists.begin(), centerDists.end(), \n",
    "              [](const std::pair<float, int>& a, const std::pair<float, int>& b){\n",
    "                  return a.first < b.first;\n",
    "              });\n",
    "\n",
    "    // Fine Search\n",
    "    std::vector<std::pair<float, int>> candidates;\n",
    "    candidates.reserve((N / K) * NPROBE * 2);\n",
    "\n",
    "    int visitedVecs = 0;\n",
    "    for (int i = 0; i < NPROBE && i < K; ++i) {\n",
    "        int c_id = centerDists[i].second;\n",
    "        const auto& bucket = lists[c_id];\n",
    "        visitedVecs += bucket.size();\n",
    "\n",
    "        for (int vecIdx : bucket) {\n",
    "            const float* vec = &h_data[(size_t)vecIdx * DIM];\n",
    "            double dotVal = dot_host(q_host.data(), vec);\n",
    "            float dist = 1.0f - (float)dotVal;\n",
    "            candidates.push_back({dist, vecIdx});\n",
    "        }\n",
    "    }\n",
    "    printf(\"[SEARCH] Scanned %d vectors.\\n\", visitedVecs);\n",
    "\n",
    "    // Top-K\n",
    "    if (candidates.empty()) {\n",
    "        printf(\"No candidates found.\\n\");\n",
    "    } else {\n",
    "        int finalK = std::min((int)candidates.size(), TOPK);\n",
    "        std::partial_sort(candidates.begin(), \n",
    "                          candidates.begin() + finalK, \n",
    "                          candidates.end(),\n",
    "                          [](const std::pair<float, int>& a, const std::pair<float, int>& b){\n",
    "                              return a.first < b.first;\n",
    "                          });\n",
    "\n",
    "        printf(\"\\nTop-%d Results:\\n\", finalK);\n",
    "        for (int i = 0; i < finalK; ++i) {\n",
    "            printf(\"%2d) id=%d  dist=%.6f  sim=%.6f\\n\",\n",
    "                   i+1, candidates[i].second, candidates[i].first, 1.f - candidates[i].first);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d28c189-897a-41c3-bcff-7dac5a992699",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc -O3 -std=c++17 -arch=sm_70 kmean_gpu_share_mem.cu -o kmean_gpu_share_mem -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce70cc62-ebf6-469c-a10f-6e4a51189a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==386315== NVPROF is profiling process 386315, command: ./kmean_gpu_share_mem\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: N=1048576  K=2048  DIM=64  BLOCK=512\n",
      "Mode: GPU Training V3.0 (No Unroll Pragma)\n",
      "[INIT] Generating 1048576 vectors...\n",
      "[DEBUG] Query vs Data[0]: dot=0.927471359 dist=0.072528641\n",
      "[TRAIN] Starting V3.0 K-Means (15 iters)...\n",
      "[TRAIN] Done.\n",
      "[INDEX] Building Inverted Lists...\n",
      "[INDEX] Non-empty clusters: 2048 / 2048\n",
      "\n",
      "[SEARCH] CPU Search (nprobe=32)...\n",
      "[SEARCH] Scanned 18350 vectors.\n",
      "\n",
      "Top-5 Results:\n",
      " 1) id=0  dist=0.072529  sim=0.927471\n",
      " 2) id=89698  dist=0.157913  sim=0.842087\n",
      " 3) id=913782  dist=0.158968  sim=0.841032\n",
      " 4) id=350035  dist=0.164414  sim=0.835586\n",
      " 5) id=56801  dist=0.177664  sim=0.822336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==386315== Profiling application: ./kmean_gpu_share_mem\n",
      "==386315== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   68.68%  703.20ms        15  46.880ms  42.476ms  50.344ms  assignAndAccumulatePerBlockKernel_V3(float const *, int, float const *, int, int*, double*, int*)\n",
      "                   23.27%  238.22ms         2  119.11ms  93.184us  238.12ms  [CUDA memcpy HtoD]\n",
      "                    4.02%  41.109ms        15  2.7406ms  2.7238ms  2.7783ms  reduceSumsKernel(double*, int*, double const *, int const *, int, int)\n",
      "                    3.55%  36.336ms        30  1.2112ms  20.448us  2.4143ms  [CUDA memset]\n",
      "                    0.28%  2.8982ms         2  1.4491ms  125.47us  2.7727ms  [CUDA memcpy DtoH]\n",
      "                    0.20%  2.0625ms        15  137.50us  133.12us  150.50us  updateCentroidsKernel(float*, double const *, int const *, int)\n",
      "      API calls:   49.49%  1.01629s         7  145.18ms  5.6800us  1.01428s  cudaMalloc\n",
      "                   37.95%  779.28ms        15  51.952ms  47.723ms  55.490ms  cudaDeviceSynchronize\n",
      "                   11.96%  245.58ms         4  61.394ms  675.11us  239.31ms  cudaMemcpy\n",
      "                    0.20%  4.0590ms        45  90.200us  8.9300us  2.6933ms  cudaLaunchKernel\n",
      "                    0.19%  3.8074ms         7  543.92us  13.565us  1.9858ms  cudaFree\n",
      "                    0.17%  3.4283ms        30  114.28us  12.057us  431.01us  cudaMemset\n",
      "                    0.03%  550.91us       114  4.8320us     126ns  237.45us  cuDeviceGetAttribute\n",
      "                    0.01%  214.04us         1  214.04us  214.04us  214.04us  cuDeviceGetName\n",
      "                    0.01%  193.46us         1  193.46us  193.46us  193.46us  cudaGetDeviceProperties\n",
      "                    0.00%  34.419us         1  34.419us  34.419us  34.419us  cuDeviceTotalMem\n",
      "                    0.00%  18.322us         1  18.322us  18.322us  18.322us  cuDeviceGetPCIBusId\n",
      "                    0.00%  10.000us         3  3.3330us     195ns  9.5980us  cuDeviceGetCount\n",
      "                    0.00%  4.8120us         2  2.4060us     791ns  4.0210us  cuDeviceGet\n",
      "                    0.00%  2.0430us         1  2.0430us  2.0430us  2.0430us  cuModuleGetLoadingMode\n",
      "                    0.00%     935ns         1     935ns     935ns     935ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./kmean_gpu_share_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf67988-b3ec-456d-be7c-976efb4e4a88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

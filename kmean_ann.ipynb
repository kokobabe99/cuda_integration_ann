{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0b84556-3cdc-4eef-b940-361f65732745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/bin:/bin:/usr/bin:/usr/local/cuda/bin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Add the directory containing the executable to the PATH\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/usr/local/cuda/bin\"\n",
    "\n",
    "# Check if the directory is added to the a\n",
    "print(os.environ[\"PATH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbe34e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82c50a9a-4761-463a-8540-1833bcbc3670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2025 NVIDIA Corporation\n",
      "Built on Wed_Apr__9_19:24:57_PDT_2025\n",
      "Cuda compilation tools, release 12.9, V12.9.41\n",
      "Build cuda_12.9.r12.9/compiler.35813241_0\n",
      "nvprof: NVIDIA (R) Cuda command line profiler\n",
      "Copyright (c) 2012 - 2025 NVIDIA Corporation\n",
      "Release version 12.9.19 (21)\n",
      "NVIDIA Nsight Systems version 2025.1.3.140-251335620677v0\n",
      "NVIDIA (R) Nsight Compute Command Line Profiler\n",
      "Copyright (c) 2018-2025 NVIDIA Corporation\n",
      "Version 2025.2.0.0 (build 35613519) (public-release)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvcc --version\n",
    "nvprof --version\n",
    "nsys --version\n",
    "ncu --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cca7ffcb-1cbc-4218-95c4-77f2cbb63c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  9 04:20:40 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.51.03              Driver Version: 575.51.03      CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-PCIE-32GB           Off |   00000000:00:10.0 Off |                    0 |\n",
      "| N/A   27C    P0             22W /  250W |       0MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46631544-01d1-4293-b231-fc2a63aadc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kmeans_ann_cuda_search.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile kmeans_ann_cuda_search.cu \n",
    "\n",
    "#include <cuda_runtime.h>\n",
    "#include <cstdio>\n",
    "#include <vector>\n",
    "#include <random>\n",
    "#include <algorithm>\n",
    "#include <numeric>\n",
    "#include <cmath>\n",
    "#include <cassert>\n",
    "#include <unordered_set>\n",
    "#include <limits>\n",
    "#include <cfloat>\n",
    "\n",
    "#include <thrust/device_ptr.h>\n",
    "#include <thrust/device_vector.h>\n",
    "#include <thrust/sort.h>\n",
    "#include <thrust/sequence.h>\n",
    "#include <thrust/copy.h>\n",
    "\n",
    "#include <cub/cub.cuh>\n",
    "\n",
    "// ---------------- Config ----------------\n",
    "static const int DIM          = 64;\n",
    "static const float ALPHA      = 0.7f;\n",
    "static const int SEED         = 2025; \n",
    "static const int N            = 1 << 20; // demo: 1M 160m\n",
    "static const int K            = 1024;\n",
    "static const int NPROBE       = 4;       // cluster depth during search\n",
    "static const int TOPK         = 5;\n",
    "\n",
    "static const int KMEANS_ITERS = 15;      // K-Means iters\n",
    "\n",
    "using Vec = std::vector<float>;\n",
    "\n",
    "struct Pair { float key; int id; };\n",
    "\n",
    "// ---------------- Embedding basic ----------------\n",
    "\n",
    "static Vec numberBase[76]; // 1..75\n",
    "static Vec posBase[25];    // 0..24\n",
    "\n",
    "static void normInPlace(Vec &v) {\n",
    "    double s = 0;\n",
    "    for (float x : v) s += (double)x * x;\n",
    "    float n = float(std::sqrt(s) + 1e-12);\n",
    "    for (float &x : v) x /= n;\n",
    "}\n",
    "\n",
    "static Vec randUnit(std::mt19937 &rng) {\n",
    "    std::uniform_real_distribution<float> U(-1.f, 1.f);\n",
    "    Vec v(DIM);\n",
    "    for (int i = 0; i < DIM; i++) v[i] = U(rng);\n",
    "    normInPlace(v);\n",
    "    return v;\n",
    "}\n",
    "\n",
    "static void initBases() {\n",
    "    std::mt19937 rng(SEED);\n",
    "    for (int n = 1; n <= 75; n++) numberBase[n] = randUnit(rng);\n",
    "    for (int i = 0; i < 25; i++)  posBase[i]    = randUnit(rng);\n",
    "}\n",
    "\n",
    "static Vec cardToVec(const int card[25]) {\n",
    "    Vec out(DIM, 0.f);\n",
    "    for (int i = 0; i < 25; i++) {\n",
    "        int n = card[i];\n",
    "        if (n < 1 || n > 75) {\n",
    "            fprintf(stderr, \"number out of range\\n\");\n",
    "            exit(1);\n",
    "        }\n",
    "        const Vec &b = numberBase[n];\n",
    "        const Vec &p = posBase[i];\n",
    "        for (int j = 0; j < DIM; j++)\n",
    "            out[j] += b[j] + ALPHA * p[j];\n",
    "    }\n",
    "    normInPlace(out);\n",
    "    return out;\n",
    "}\n",
    "\n",
    "static void genCard(std::mt19937 &rng, int out[25]) {\n",
    "    std::vector<int> p(75);\n",
    "    std::iota(p.begin(), p.end(), 1);\n",
    "    std::shuffle(p.begin(), p.end(), rng);\n",
    "    for (int i = 0; i < 25; i++) out[i] = p[i];\n",
    "}\n",
    "\n",
    "static double dot_host(const float* a, const float* b) {\n",
    "    double s = 0;\n",
    "    for (int i = 0; i < DIM; i++) s += (double)a[i] * b[i];\n",
    "    return s;\n",
    "}\n",
    "\n",
    "// ---------------- Device: Distance Kernels ----------------\n",
    "\n",
    "// data[0..Ntot-1] vs single q\n",
    "__global__ void cosineDistKernel(const float* data,\n",
    "                                 const float* q,\n",
    "                                 int Ntot,\n",
    "                                 float* out) {\n",
    "    for (int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "         i < Ntot;\n",
    "         i += gridDim.x * blockDim.x) {\n",
    "        const float* row = data + (size_t)i * DIM;\n",
    "        float dot = 0.f;\n",
    "        for (int d = 0; d < DIM; ++d) dot += row[d] * q[d];\n",
    "        out[i] = 1.f - dot;\n",
    "    }\n",
    "}\n",
    "\n",
    "// assign idxSel[0..M-1] vs q\n",
    "__global__ void cosineDistIndexKernel(const float* data,\n",
    "                                      const float* q,\n",
    "                                      const int* idxSel,\n",
    "                                      int M,\n",
    "                                      float* distSel) {\n",
    "    for (int j = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "         j < M;\n",
    "         j += gridDim.x * blockDim.x) {\n",
    "        int i = idxSel[j];\n",
    "        const float* row = data + (size_t)i * DIM;\n",
    "        float dot = 0.f;\n",
    "        for (int d = 0; d < DIM; ++d) dot += row[d] * q[d];\n",
    "        distSel[j] = 1.f - dot;\n",
    "    }\n",
    "}\n",
    "\n",
    "// ----------------  GPU K-Means Kernels ----------------\n",
    "\n",
    "// E-step + accumulate:\n",
    "// every data to search nearest center -> assign[i]\n",
    "// atomicAdd sums[c][d] and counts[c]\n",
    "__global__ void assignAndAccumulateKernel(const float* data,\n",
    "                                          int N,\n",
    "                                          const float* centroids,\n",
    "                                          int K,\n",
    "                                          int* assign,\n",
    "                                          float* sums,\n",
    "                                          int* counts) {\n",
    "    for (int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "         i < N;\n",
    "         i += gridDim.x * blockDim.x) {\n",
    "\n",
    "        const float* xi = data + (size_t)i * DIM;\n",
    "\n",
    "        int bestC = 0;\n",
    "        float bestD = 1e30f;\n",
    "\n",
    "        for (int c = 0; c < K; ++c) {\n",
    "            const float* ctr = centroids + (size_t)c * DIM;\n",
    "            float dot = 0.f;\n",
    "            for (int d = 0; d < DIM; ++d) {\n",
    "                dot += xi[d] * ctr[d];\n",
    "            }\n",
    "            float dist = 1.f - dot;\n",
    "            if (dist < bestD) {\n",
    "                bestD = dist;\n",
    "                bestC = c;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        assign[i] = bestC;\n",
    "\n",
    "        atomicAdd(&counts[bestC], 1);\n",
    "        size_t base = (size_t)bestC * DIM;\n",
    "        for (int d = 0; d < DIM; ++d) {\n",
    "            atomicAdd(&sums[base + d], xi[d]);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// M-step: sums/counts -> update centroid + norm\n",
    "__global__ void updateCentroidsKernel(float* centroids,\n",
    "                                      const float* sums,\n",
    "                                      const int* counts,\n",
    "                                      int K) {\n",
    "    int c = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (c >= K) return;\n",
    "\n",
    "    int cnt = counts[c];\n",
    "    float* ctr = centroids + (size_t)c * DIM;\n",
    "    const float* sumc = sums + (size_t)c * DIM;\n",
    "\n",
    "    if (cnt > 0) {\n",
    "        double norm2 = 0.0;\n",
    "        for (int d = 0; d < DIM; ++d) {\n",
    "            float v = sumc[d] / (float)cnt;\n",
    "            ctr[d] = v;\n",
    "            norm2 += (double)v * (double)v;\n",
    "        }\n",
    "        float n = float(std::sqrt(norm2) + 1e-12);\n",
    "        for (int d = 0; d < DIM; ++d) {\n",
    "            ctr[d] /= n;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// ---------------- Host: Inverted Lists (vector<vector<int>>) ----------------\n",
    "\n",
    "static void buildInvertedLists(\n",
    "    const std::vector<int>& assign,\n",
    "    int N, int K,\n",
    "    std::vector<std::vector<int>>& lists\n",
    ") {\n",
    "    lists.assign(K, {});\n",
    "    for (int i = 0; i < N; ++i) {\n",
    "        int c = assign[i];\n",
    "        if (c >= 0 && c < K) {\n",
    "            lists[c].push_back(i);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "static void buildCSRFromLists(\n",
    "    const std::vector<std::vector<int>>& lists,\n",
    "    int K, int N,\n",
    "    std::vector<int>& listOffsets,\n",
    "    std::vector<int>& listIds\n",
    ") {\n",
    "    listOffsets.assign(K + 1, 0);\n",
    "    listIds.clear();\n",
    "    listIds.reserve(N);\n",
    "\n",
    "    int offset = 0;\n",
    "    for (int c = 0; c < K; ++c) {\n",
    "        listOffsets[c] = offset;\n",
    "        const std::vector<int>& bucket = lists[c];\n",
    "        listIds.insert(listIds.end(), bucket.begin(), bucket.end());\n",
    "        offset += (int)bucket.size();\n",
    "    }\n",
    "    listOffsets[K] = offset;\n",
    "}\n",
    "\n",
    "// ---------------- Device: gatherCandidates ----------------\n",
    "\n",
    "// centIds:     \n",
    "// nprobe:      nprobe to dect\n",
    "// listOffsets: CSR offsets,\n",
    "// listIds:     CSR ids\n",
    "// outIdx:     \n",
    "// outCount:    \n",
    "__global__ void gatherCandidatesKernel(\n",
    "    const int* centIds,\n",
    "    int nprobe,\n",
    "    const int* listOffsets,\n",
    "    const int* listIds,\n",
    "    int* outIdx,\n",
    "    int* outCount\n",
    ") {\n",
    "    int p = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (p >= nprobe) return;\n",
    "\n",
    "    int c = centIds[p];\n",
    "    int start = listOffsets[c];\n",
    "    int end   = listOffsets[c + 1];\n",
    "    int len   = end - start;\n",
    "    if (len <= 0) return;\n",
    "\n",
    "    int base = atomicAdd(outCount, len);\n",
    "    for (int i = 0; i < len; ++i) {\n",
    "        outIdx[base + i] = listIds[start + i];\n",
    "    }\n",
    "}\n",
    "\n",
    "// ---------------- Main ----------------\n",
    "int main() {\n",
    "\n",
    "    cudaDeviceProp prop;\n",
    "    cudaGetDeviceProperties(&prop, 0);\n",
    "\n",
    "    int threads = prop.maxThreadsPerBlock;  \n",
    "    int BLOCK  = prop.multiProcessorCount; \n",
    "    printf(\"Params: N=%d  K=%d  nprobe=%d  TOPK=%d  DIM=%d  KMEANS_ITERS=%d threads=%d blocks=%d\\n\",\n",
    "           N, K, NPROBE, TOPK, DIM, KMEANS_ITERS,threads,BLOCK);\n",
    "\n",
    "    initBases();\n",
    "    std::mt19937 rng(SEED + 7);\n",
    "\n",
    "    // 1) building dataset\n",
    "    std::vector<int>   h_cards((size_t)N * 25);\n",
    "    std::vector<float> h_data((size_t)N * DIM);\n",
    "\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        int c[25];\n",
    "        genCard(rng, c);\n",
    "        for (int t = 0; t < 25; ++t)\n",
    "            h_cards[(size_t)i * 25 + t] = c[t];\n",
    "        Vec v = cardToVec(c);\n",
    "        for (int d = 0; d < DIM; ++d)\n",
    "            h_data[(size_t)i * DIM + d] = v[d];\n",
    "    }\n",
    "\n",
    "    // 2) build query\n",
    "    int qc[25];\n",
    "    for (int t = 0; t < 25; ++t) qc[t] = h_cards[t];\n",
    "    qc[3] = 75; qc[17] = 1; std::swap(qc[5], qc[19]);\n",
    "    Vec qvec = cardToVec(qc);\n",
    "\n",
    "    {\n",
    "        std::vector<float> qhost(qvec.begin(), qvec.end());\n",
    "        std::vector<float> d0(DIM);\n",
    "        for (int i = 0; i < DIM; i++) d0[i] = h_data[i];\n",
    "        double dot0 = dot_host(qhost.data(), d0.data());\n",
    "        printf(\"[DEBUG #1] host dot(q, data[0])=%.9f  dist=%.9f\\n\",\n",
    "               dot0, 1.0 - dot0);\n",
    "    }\n",
    "\n",
    "    // 3) GPU buffers\n",
    "    float *d_data = 0, *d_q = 0, *d_centroids = 0;\n",
    "    float *d_tmpCentDist = 0;\n",
    "\n",
    "    cudaMalloc(&d_data, (size_t)N * DIM * sizeof(float));\n",
    "    cudaMalloc(&d_q, DIM * sizeof(float));\n",
    "    cudaMalloc(&d_centroids, (size_t)K * DIM * sizeof(float));\n",
    "    cudaMalloc(&d_tmpCentDist, K * sizeof(float));\n",
    "\n",
    "    cudaMemcpy(d_data, h_data.data(),\n",
    "               (size_t)N * DIM * sizeof(float),\n",
    "               cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_q, qvec.data(),\n",
    "               DIM * sizeof(float),\n",
    "               cudaMemcpyHostToDevice);\n",
    "\n",
    "    // 4) initial centroids: Host random select K centers\n",
    "    {\n",
    "        std::vector<int> idx(N);\n",
    "        std::iota(idx.begin(), idx.end(), 0);\n",
    "        std::shuffle(idx.begin(), idx.end(), rng);\n",
    "        std::vector<float> h_initC((size_t)K * DIM);\n",
    "        for (int c = 0; c < K; ++c) {\n",
    "            int i = idx[c];\n",
    "            std::copy_n(&h_data[(size_t)i * DIM], DIM,\n",
    "                        &h_initC[(size_t)c * DIM]);\n",
    "        }\n",
    "        cudaMemcpy(d_centroids, h_initC.data(),\n",
    "                   (size_t)K * DIM * sizeof(float),\n",
    "                   cudaMemcpyHostToDevice);\n",
    "    }\n",
    "\n",
    "    int   *d_assign = 0;\n",
    "    float *d_sums   = 0;\n",
    "    int   *d_counts = 0;\n",
    "\n",
    "    cudaMalloc(&d_assign, N * sizeof(int));\n",
    "    cudaMalloc(&d_sums,   (size_t)K * DIM * sizeof(float));\n",
    "    cudaMalloc(&d_counts, K * sizeof(int));\n",
    "\n",
    "    // 5) GPU K-Means\n",
    "    {\n",
    "        dim3 block(BLOCK);\n",
    "        dim3 gridN((N + BLOCK - 1) / BLOCK);\n",
    "        dim3 gridK((K + BLOCK - 1) / BLOCK);\n",
    "\n",
    "        printf(\"[BUILD] GPU K-Means: iters=%d\\n\", KMEANS_ITERS);\n",
    "\n",
    "        for (int it = 0; it < KMEANS_ITERS; ++it) {\n",
    "            cudaMemset(d_sums,   0, (size_t)K * DIM * sizeof(float));\n",
    "            cudaMemset(d_counts, 0, K * sizeof(int));\n",
    "\n",
    "            assignAndAccumulateKernel<<<gridN, block>>>(\n",
    "                d_data, N, d_centroids, K,\n",
    "                d_assign, d_sums, d_counts\n",
    "            );\n",
    "            cudaDeviceSynchronize();\n",
    "\n",
    "            updateCentroidsKernel<<<gridK, block>>>(\n",
    "                d_centroids, d_sums, d_counts, K\n",
    "            );\n",
    "            cudaDeviceSynchronize();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // 6) build inverted index on host\n",
    "    std::vector<int> h_assign(N);\n",
    "    cudaMemcpy(h_assign.data(), d_assign,\n",
    "               N * sizeof(int),\n",
    "               cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // IVF FOR \n",
    "    std::vector<std::vector<int>> lists;\n",
    "    buildInvertedLists(h_assign, N, K, lists);\n",
    "\n",
    "    int nonEmpty = 0;\n",
    "    for (int c = 0; c < K; ++c)\n",
    "        if (!lists[c].empty()) nonEmpty++;\n",
    "    printf(\"[BUILD] Non-empty clusters: %d / %d\\n\", nonEmpty, K);\n",
    "\n",
    "    // 7) flatten lists -> CSR, copy to device\n",
    "    std::vector<int> h_listOffsets;\n",
    "    std::vector<int> h_listIds;\n",
    "    buildCSRFromLists(lists, K, N, h_listOffsets, h_listIds);\n",
    "\n",
    "    int *d_listOffsets = 0;\n",
    "    int *d_listIds     = 0;\n",
    "    cudaMalloc(&d_listOffsets, (K + 1) * sizeof(int));\n",
    "    cudaMalloc(&d_listIds,     h_listIds.size() * sizeof(int));\n",
    "\n",
    "    cudaMemcpy(d_listOffsets, h_listOffsets.data(),\n",
    "               (K + 1) * sizeof(int),\n",
    "               cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_listIds, h_listIds.data(),\n",
    "               h_listIds.size() * sizeof(int),\n",
    "               cudaMemcpyHostToDevice);\n",
    "\n",
    "    // 8) Search Stage 1: q vs centroids -> Thrust sort for NPROBE\n",
    "    {\n",
    "        dim3 block(BLOCK);\n",
    "        dim3 grid((K + BLOCK - 1) / BLOCK);\n",
    "        cosineDistKernel<<<grid, block>>>(d_centroids, d_q, K, d_tmpCentDist);\n",
    "        cudaDeviceSynchronize();\n",
    "    }\n",
    "\n",
    "    thrust::device_ptr<float> dist_ptr(d_tmpCentDist);\n",
    "    thrust::device_vector<int> d_centIds(K);\n",
    "    thrust::sequence(d_centIds.begin(), d_centIds.end()); // 0..K-1\n",
    "\n",
    "    thrust::sort_by_key(dist_ptr, dist_ptr + K, d_centIds.begin());\n",
    "\n",
    "    // 9) GPU  collect the NPROBE numbers of cluster to do candiating\n",
    "    int *d_outIdx   = 0;\n",
    "    int *d_outCount = 0;\n",
    "    cudaMalloc(&d_outIdx,   N * sizeof(int));  // 上界 N（通常远小于）\n",
    "    cudaMalloc(&d_outCount, sizeof(int));\n",
    "    cudaMemset(d_outCount,  0, sizeof(int));\n",
    "\n",
    "    {\n",
    "        gatherCandidatesKernel<<<BLOCK, threads>>>(\n",
    "            thrust::raw_pointer_cast(d_centIds.data()),\n",
    "            NPROBE,\n",
    "            d_listOffsets,\n",
    "            d_listIds,\n",
    "            d_outIdx,\n",
    "            d_outCount\n",
    "        );\n",
    "        cudaDeviceSynchronize();\n",
    "    }\n",
    "\n",
    "    int M = 0;\n",
    "    cudaMemcpy(&M, d_outCount, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "    printf(\"Candidates from chosen centers: M=%d (of N=%d)\\n\", M, N);\n",
    "\n",
    "    if (M <= 0) {\n",
    "        printf(\"No candidates, abort.\\n\");\n",
    "    } else {\n",
    "        // 10) Stage 2: candidate Top-K on GPU via CUB\n",
    "\n",
    "        float *d_selDist   = 0;   // distance between candidates\n",
    "        float *d_keys_out  = 0;   // distance after sorting\n",
    "        int   *d_vals_out  = 0;   // candidates id after sorting\n",
    "        void  *d_temp_storage = 0;\n",
    "        size_t temp_bytes = 0;\n",
    "        \n",
    "        // 1) 为距离分配空间\n",
    "        cudaMalloc(&d_selDist, M * sizeof(float));\n",
    "        \n",
    "        // 2) 计算 query vs 每个候选向量的距离\n",
    "        {\n",
    "            dim3 block(BLOCK);\n",
    "            dim3 grid((M + BLOCK - 1) / BLOCK);\n",
    "            // 注意这里直接用 d_outIdx 作为候选 id 列表\n",
    "            cosineDistIndexKernel<<<grid, block>>>(\n",
    "                d_data, d_q, d_outIdx, M, d_selDist\n",
    "            );\n",
    "            cudaDeviceSynchronize();\n",
    "        }\n",
    "        \n",
    "        // 3)CUB malloc space\n",
    "        cudaMalloc(&d_keys_out, M * sizeof(float));\n",
    "        cudaMalloc(&d_vals_out, M * sizeof(int));\n",
    "        \n",
    "        // 4) first time using SortPairs  to access size of buffer ares needed\n",
    "        cub::DeviceRadixSort::SortPairs(\n",
    "            d_temp_storage, temp_bytes,\n",
    "            d_selDist, d_keys_out,   // keys: distance\n",
    "            d_outIdx,  d_vals_out,   // values: gathered id（\n",
    "            M\n",
    "        );\n",
    "        cudaMalloc(&d_temp_storage, temp_bytes);\n",
    "        \n",
    "        // 5) really sort from nearest to further\n",
    "        cub::DeviceRadixSort::SortPairs(\n",
    "            d_temp_storage, temp_bytes,\n",
    "            d_selDist, d_keys_out,\n",
    "            d_outIdx,  d_vals_out,\n",
    "            M\n",
    "        );\n",
    "        cudaDeviceSynchronize();\n",
    "        \n",
    "        // 6) extract top to CPU，做 TopK & 打印\n",
    "        int take = std::min(M, TOPK * 4);\n",
    "        std::vector<float> h_keys(take);\n",
    "        std::vector<int>   h_ids(take);\n",
    "        \n",
    "        cudaMemcpy(h_keys.data(), d_keys_out,\n",
    "                   take * sizeof(float),\n",
    "                   cudaMemcpyDeviceToHost);\n",
    "        cudaMemcpy(h_ids.data(), d_vals_out,\n",
    "                   take * sizeof(int),\n",
    "                   cudaMemcpyDeviceToHost);\n",
    "        \n",
    "        std::vector<Pair> uniq;\n",
    "        uniq.reserve(TOPK);\n",
    "        std::unordered_set<int> seen;\n",
    "        \n",
    "        for (int i = 0; i < take; ++i) {\n",
    "            int id = h_ids[i];\n",
    "            float dist = h_keys[i];\n",
    "            if (id < 0 || !std::isfinite(dist)) continue;\n",
    "            if (seen.insert(id).second) {\n",
    "                uniq.push_back(Pair{dist, id});\n",
    "                if ((int)uniq.size() == TOPK) break;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        printf(\"Top-%d among %d candidates (CUB SortPairs):\\n\",\n",
    "               (int)uniq.size(), M);\n",
    "        for (int i = 0; i < (int)uniq.size(); ++i) {\n",
    "            printf(\"%2d) id=%d  dist=%.6f  sim=%.6f\\n\",\n",
    "                   i+1, uniq[i].id, uniq[i].key, 1.f - uniq[i].key);\n",
    "        }\n",
    "\n",
    "        if (!uniq.empty()) {\n",
    "            int bestId = uniq[0].id;\n",
    "            std::vector<float> qhost(qvec.begin(), qvec.end());\n",
    "            std::vector<float> dv(DIM);\n",
    "            for (int i = 0; i < DIM; ++i)\n",
    "                dv[i] = h_data[(size_t)bestId * DIM + i];\n",
    "            double dotChk = dot_host(qhost.data(), dv.data());\n",
    "            printf(\"[DEBUG] host check best id=%d  dot=%.9f  dist=%.9f\\n\",\n",
    "                   bestId, dotChk, 1.0 - dotChk);\n",
    "        }\n",
    "\n",
    "        cudaFree(d_temp_storage);\n",
    "        cudaFree(d_keys_out);\n",
    "        cudaFree(d_vals_out);\n",
    "        cudaFree(d_selDist);\n",
    "    }\n",
    "\n",
    "    // 11) free\n",
    "    cudaFree(d_outIdx);\n",
    "    cudaFree(d_outCount);\n",
    "    cudaFree(d_tmpCentDist);\n",
    "    cudaFree(d_centroids);\n",
    "    cudaFree(d_q);\n",
    "    cudaFree(d_data);\n",
    "    cudaFree(d_assign);\n",
    "    cudaFree(d_sums);\n",
    "    cudaFree(d_counts);\n",
    "    cudaFree(d_listOffsets);\n",
    "    cudaFree(d_listIds);\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b69852ec-ff21-44a3-913e-e2eb75cc13c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc -O3 -std=c++17 -arch=sm_70 kmeans_ann_cuda_search.cu -o kmeans_ann_cuda_search -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20ad9ed9-526b-47fb-807d-a0297186e981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1111200== NVPROF is profiling process 1111200, command: ./kmeans_ann_cuda_search\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: N=1048576  K=1024  nprobe=4  TOPK=5  DIM=64  KMEANS_ITERS=15 threads=1024 blocks=80\n",
      "[DEBUG #1] host dot(q, data[0])=0.927471359  dist=0.072528641\n",
      "[BUILD] GPU K-Means: iters=15\n",
      "[BUILD] Non-empty clusters: 1024 / 1024\n",
      "Candidates from chosen centers: M=4655 (of N=1048576)\n",
      "Top-5 among 4655 candidates (CUB SortPairs):\n",
      " 1) id=89698  dist=0.157913  sim=0.842087\n",
      " 2) id=913782  dist=0.158968  sim=0.841032\n",
      " 3) id=350035  dist=0.164414  sim=0.835586\n",
      " 4) id=56801  dist=0.177664  sim=0.822336\n",
      " 5) id=91744  dist=0.177767  sim=0.822233\n",
      "[DEBUG] host check best id=89698  dot=0.842086914  dist=0.157913086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1111200== Profiling application: ./kmeans_ann_cuda_search\n",
      "==1111200== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   70.57%  666.16ms        15  44.411ms  43.935ms  45.312ms  assignAndAccumulateKernel(float const *, int, float const *, int, int*, float*, int*)\n",
      "                   28.93%  273.07ms         5  54.615ms  1.0880us  269.68ms  [CUDA memcpy HtoD]\n",
      "                    0.45%  4.2173ms         4  1.0543ms  1.9520us  4.2092ms  [CUDA memcpy DtoH]\n",
      "                    0.03%  315.77us        15  21.051us  19.999us  24.672us  updateCentroidsKernel(float*, float const *, int const *, int)\n",
      "                    0.01%  115.71us         1  115.71us  115.71us  115.71us  gatherCandidatesKernel(int const *, int, int const *, int const *, int*, int*)\n",
      "                    0.00%  47.136us        31  1.5200us     672ns  2.5600us  [CUDA memset]\n",
      "                    0.00%  24.832us         1  24.832us  24.832us  24.832us  void cub::CUB_200802_SM_700::DeviceRadixSortSingleTileKernel<cub::CUB_200802_SM_700::detail::radix::policy_hub<float, int, unsigned int>::Policy1000, bool=0, float, int, unsigned int, cub::CUB_200802_SM_700::detail::identity_decomposer_t>(unsigned int const *, cub::CUB_200802_SM_700::DeviceRadixSortSingleTileKernel<cub::CUB_200802_SM_700::detail::radix::policy_hub<float, int, unsigned int>::Policy1000, bool=0, float, int, unsigned int, cub::CUB_200802_SM_700::detail::identity_decomposer_t>*, cub::CUB_200802_SM_700::detail::radix::policy_hub<float, int, unsigned int>::Policy1000 const *, cub::CUB_200802_SM_700::DeviceRadixSortSingleTileKernel<cub::CUB_200802_SM_700::detail::radix::policy_hub<float, int, unsigned int>::Policy1000, bool=0, float, int, unsigned int, cub::CUB_200802_SM_700::detail::identity_decomposer_t>**, bool=0, int, int, float)\n",
      "                    0.00%  23.552us         1  23.552us  23.552us  23.552us  void cub::CUB_200802_SM_700::DeviceRadixSortSingleTileKernel<cub::CUB_200802_SM_700::detail::radix::policy_hub<float, int, __int64>::Policy1000, bool=0, float, int, __int64, cub::CUB_200802_SM_700::detail::identity_decomposer_t>(__int64 const *, cub::CUB_200802_SM_700::DeviceRadixSortSingleTileKernel<cub::CUB_200802_SM_700::detail::radix::policy_hub<float, int, __int64>::Policy1000, bool=0, float, int, __int64, cub::CUB_200802_SM_700::detail::identity_decomposer_t>*, cub::CUB_200802_SM_700::detail::radix::policy_hub<float, int, __int64>::Policy1000 const *, cub::CUB_200802_SM_700::DeviceRadixSortSingleTileKernel<cub::CUB_200802_SM_700::detail::radix::policy_hub<float, int, __int64>::Policy1000, bool=0, float, int, __int64, cub::CUB_200802_SM_700::detail::identity_decomposer_t>**, bool=0, int, int, float)\n",
      "                    0.00%  11.584us         1  11.584us  11.584us  11.584us  cosineDistIndexKernel(float const *, float const *, int const *, int, float*)\n",
      "                    0.00%  7.4560us         1  7.4560us  7.4560us  7.4560us  cosineDistKernel(float const *, float const *, int, float*)\n",
      "                    0.00%  2.9440us         2  1.4720us  1.3440us  1.6000us  [CUDA memcpy DtoD]\n",
      "                    0.00%  1.8560us         1  1.8560us  1.8560us  1.8560us  void cub::CUB_200802_SM_700::detail::for_each::static_kernel<cub::CUB_200802_SM_700::detail::for_each::policy_hub_t::policy_350_t, unsigned long, thrust::THRUST_200802_SM_700_NS::cuda_cub::__uninitialized_fill::functor<thrust::THRUST_200802_SM_700_NS::device_ptr<int>, int>>(unsigned long, int)\n",
      "                    0.00%  1.6640us         1  1.6640us  1.6640us  1.6640us  void cub::CUB_200802_SM_700::detail::for_each::static_kernel<cub::CUB_200802_SM_700::detail::for_each::policy_hub_t::policy_350_t, long, thrust::THRUST_200802_SM_700_NS::cuda_cub::__tabulate::functor<thrust::THRUST_200802_SM_700_NS::detail::normal_iterator<thrust::THRUST_200802_SM_700_NS::device_ptr<int>>, thrust::THRUST_200802_SM_700_NS::system::detail::generic::detail::compute_sequence_value<int, void>, long>>(long, int)\n",
      "      API calls:   58.32%  1.36336s        17  80.198ms  5.7230us  1.35658s  cudaMalloc\n",
      "                   28.62%  669.03ms        34  19.677ms  14.085us  45.450ms  cudaDeviceSynchronize\n",
      "                   12.09%  282.69ms         9  31.410ms  18.705us  271.06ms  cudaMemcpy\n",
      "                    0.70%  16.318ms        37  441.02us  23.315us  8.6207ms  cudaLaunchKernel\n",
      "                    0.10%  2.3631ms        17  139.01us  3.3430us  1.0832ms  cudaFree\n",
      "                    0.10%  2.2702ms        31  73.231us  13.019us  308.96us  cudaMemset\n",
      "                    0.03%  610.56us       114  5.3550us     137ns  218.36us  cuDeviceGetAttribute\n",
      "                    0.02%  416.86us         1  416.86us  416.86us  416.86us  cudaGetDeviceProperties\n",
      "                    0.01%  250.70us         1  250.70us  250.70us  250.70us  cudaFuncGetAttributes\n",
      "                    0.01%  170.51us         2  85.257us  26.737us  143.78us  cudaMemcpyAsync\n",
      "                    0.01%  159.51us         1  159.51us  159.51us  159.51us  cuDeviceGetName\n",
      "                    0.00%  90.205us         5  18.041us  2.4290us  73.409us  cudaStreamSynchronize\n",
      "                    0.00%  25.343us         7  3.6200us     275ns  16.073us  cudaGetDevice\n",
      "                    0.00%  22.052us         1  22.052us  22.052us  22.052us  cuDeviceGetPCIBusId\n",
      "                    0.00%  18.633us         3  6.2110us     197ns  17.886us  cuDeviceGetCount\n",
      "                    0.00%  15.531us         1  15.531us  15.531us  15.531us  cuDeviceTotalMem\n",
      "                    0.00%  5.7800us        49     117ns      86ns  1.0060us  cudaGetLastError\n",
      "                    0.00%  3.6790us         2  1.8390us     217ns  3.4620us  cuDeviceGet\n",
      "                    0.00%  1.2630us         1  1.2630us  1.2630us  1.2630us  cuDeviceGetUuid\n",
      "                    0.00%     855ns         6     142ns      87ns     233ns  cudaPeekAtLastError\n",
      "                    0.00%     456ns         1     456ns     456ns     456ns  cudaGetDeviceCount\n",
      "                    0.00%     454ns         1     454ns     454ns     454ns  cuModuleGetLoadingMode\n",
      "\n",
      "==1111200== NVTX result:\n",
      "==1111200==   Thread \"<unnamed>\" (id = 2597117952)\n",
      "==1111200==     Domain \"CCCL\"\n",
      "==1111200==       Range \"cub::DeviceFor::Bulk\"\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      "          Range:  100.00%  461.25us         2  230.62us  53.633us  407.62us  cub::DeviceFor::Bulk\n",
      " GPU activities:   52.73%  1.8560us         1  1.8560us  1.8560us  1.8560us  void cub::CUB_200802_SM_700::detail::for_each::static_kernel<cub::CUB_200802_SM_700::detail::for_each::policy_hub_t::policy_350_t, unsigned long, thrust::THRUST_200802_SM_700_NS::cuda_cub::__uninitialized_fill::functor<thrust::THRUST_200802_SM_700_NS::device_ptr<int>, int>>(unsigned long, int)\n",
      "                   47.27%  1.6640us         1  1.6640us  1.6640us  1.6640us  void cub::CUB_200802_SM_700::detail::for_each::static_kernel<cub::CUB_200802_SM_700::detail::for_each::policy_hub_t::policy_350_t, long, thrust::THRUST_200802_SM_700_NS::cuda_cub::__tabulate::functor<thrust::THRUST_200802_SM_700_NS::detail::normal_iterator<thrust::THRUST_200802_SM_700_NS::device_ptr<int>>, thrust::THRUST_200802_SM_700_NS::system::detail::generic::detail::compute_sequence_value<int, void>, long>>(long, int)\n",
      "      API calls:  100.00%  138.44us         2  69.219us  43.398us  95.041us  cudaLaunchKernel\n",
      "\n",
      "==1111200==       Range \"cub::DeviceRadixSort\"\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      "          Range:  100.00%  99.345us         2  49.672us  48.947us  50.398us  cub::DeviceRadixSort\n",
      " GPU activities:   51.32%  24.832us         1  24.832us  24.832us  24.832us  void cub::CUB_200802_SM_700::DeviceRadixSortSingleTileKernel<cub::CUB_200802_SM_700::detail::radix::policy_hub<float, int, unsigned int>::Policy1000, bool=0, float, int, unsigned int, cub::CUB_200802_SM_700::detail::identity_decomposer_t>(unsigned int const *, cub::CUB_200802_SM_700::DeviceRadixSortSingleTileKernel<cub::CUB_200802_SM_700::detail::radix::policy_hub<float, int, unsigned int>::Policy1000, bool=0, float, int, unsigned int, cub::CUB_200802_SM_700::detail::identity_decomposer_t>*, cub::CUB_200802_SM_700::detail::radix::policy_hub<float, int, unsigned int>::Policy1000 const *, cub::CUB_200802_SM_700::DeviceRadixSortSingleTileKernel<cub::CUB_200802_SM_700::detail::radix::policy_hub<float, int, unsigned int>::Policy1000, bool=0, float, int, unsigned int, cub::CUB_200802_SM_700::detail::identity_decomposer_t>**, bool=0, int, int, float)\n",
      "                   48.68%  23.552us         1  23.552us  23.552us  23.552us  void cub::CUB_200802_SM_700::DeviceRadixSortSingleTileKernel<cub::CUB_200802_SM_700::detail::radix::policy_hub<float, int, __int64>::Policy1000, bool=0, float, int, __int64, cub::CUB_200802_SM_700::detail::identity_decomposer_t>(__int64 const *, cub::CUB_200802_SM_700::DeviceRadixSortSingleTileKernel<cub::CUB_200802_SM_700::detail::radix::policy_hub<float, int, __int64>::Policy1000, bool=0, float, int, __int64, cub::CUB_200802_SM_700::detail::identity_decomposer_t>*, cub::CUB_200802_SM_700::detail::radix::policy_hub<float, int, __int64>::Policy1000 const *, cub::CUB_200802_SM_700::DeviceRadixSortSingleTileKernel<cub::CUB_200802_SM_700::detail::radix::policy_hub<float, int, __int64>::Policy1000, bool=0, float, int, __int64, cub::CUB_200802_SM_700::detail::identity_decomposer_t>**, bool=0, int, int, float)\n",
      "      API calls:  100.00%  73.886us         2  36.943us  33.410us  40.476us  cudaLaunchKernel\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./kmeans_ann_cuda_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a5651b-39be-4d53-a041-1a70b0972818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

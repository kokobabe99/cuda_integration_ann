{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad82b1e1-5dab-4b93-9b31-57a667ee6568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C_ann_3.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile C_ann_3.cpp\n",
    "\n",
    "#include <cstdio>\n",
    "#include <vector>\n",
    "#include <random>\n",
    "#include <algorithm>\n",
    "#include <numeric>\n",
    "#include <cmath>\n",
    "#include <cassert>\n",
    "#include <unordered_set>\n",
    "#include <limits>\n",
    "#include <cfloat>\n",
    "#include <cstring>\n",
    "\n",
    "// ---------------- Config ----------------\n",
    "static const int DIM          = 64;\n",
    "static const float ALPHA      = 0.7f;\n",
    "static const int SEED         = 2025; \n",
    "static const int N            = 1 << 14; // demo: 1M 160m\n",
    "static const int K            = 1024;\n",
    "static const int NPROBE       = 4;       // cluster depth during search\n",
    "static const int TOPK         = 5;\n",
    "\n",
    "static const int KMEANS_ITERS = 15;      // K-Means iters\n",
    "\n",
    "using Vec = std::vector<float>;\n",
    "\n",
    "struct Pair { float key; int id; };\n",
    "\n",
    "// ---------------- Embedding basic ----------------\n",
    "\n",
    "static Vec numberBase[76]; // 1..75\n",
    "static Vec posBase[25];    // 0..24\n",
    "\n",
    "static void normInPlace(Vec &v) {\n",
    "    double s = 0;\n",
    "    for (float x : v) s += (double)x * x;\n",
    "    float n = float(std::sqrt(s) + 1e-12);\n",
    "    for (float &x : v) x /= n;\n",
    "}\n",
    "\n",
    "static Vec randUnit(std::mt19937 &rng) {\n",
    "    std::uniform_real_distribution<float> U(-1.f, 1.f);\n",
    "    Vec v(DIM);\n",
    "    for (int i = 0; i < DIM; i++) v[i] = U(rng);\n",
    "    normInPlace(v);\n",
    "    return v;\n",
    "}\n",
    "\n",
    "static void initBases() {\n",
    "    std::mt19937 rng(SEED);\n",
    "    for (int n = 1; n <= 75; n++) numberBase[n] = randUnit(rng);\n",
    "    for (int i = 0; i < 25; i++)  posBase[i]    = randUnit(rng);\n",
    "}\n",
    "\n",
    "static Vec cardToVec(const int card[25]) {\n",
    "    Vec out(DIM, 0.f);\n",
    "    for (int i = 0; i < 25; i++) {\n",
    "        int n = card[i];\n",
    "        if (n < 1 || n > 75) {\n",
    "            fprintf(stderr, \"number out of range\\n\");\n",
    "            exit(1);\n",
    "        }\n",
    "        const Vec &b = numberBase[n];\n",
    "        const Vec &p = posBase[i];\n",
    "        for (int j = 0; j < DIM; j++)\n",
    "            out[j] += b[j] + ALPHA * p[j];\n",
    "    }\n",
    "    normInPlace(out);\n",
    "    return out;\n",
    "}\n",
    "\n",
    "static void genCard(std::mt19937 &rng, int out[25]) {\n",
    "    std::vector<int> p(75);\n",
    "    std::iota(p.begin(), p.end(), 1);\n",
    "    std::shuffle(p.begin(), p.end(), rng);\n",
    "    for (int i = 0; i < 25; i++) out[i] = p[i];\n",
    "}\n",
    "\n",
    "static double dot_host(const float* a, const float* b) {\n",
    "    double s = 0;\n",
    "    for (int i = 0; i < DIM; i++) s += (double)a[i] * b[i];\n",
    "    return s;\n",
    "}\n",
    "\n",
    "// ---------------- Device: Distance Kernels ----------------\n",
    "\n",
    "void cosineDistKernel(const float* data,\n",
    "                      const float* q,\n",
    "                      int Ntot,\n",
    "                      float* out) {\n",
    "    for (int i = 0;\n",
    "         i < Ntot;\n",
    "         i++) {\n",
    "        const float* row = data + (size_t)i * DIM;\n",
    "        float dot = 0.f;\n",
    "        for (int d = 0; d < DIM; ++d) dot += row[d] * q[d];\n",
    "        out[i] = 1.f - dot;\n",
    "    }\n",
    "}\n",
    "\n",
    "void cosineDistIndexKernel(const float* data,\n",
    "                                      const float* q,\n",
    "                                      const int* idxSel,\n",
    "                                      int M,\n",
    "                                      float* distSel) {\n",
    "    for (int j = 0;\n",
    "         j < M;\n",
    "         j++) {\n",
    "        int i = idxSel[j];\n",
    "        const float* row = data + (size_t)i * DIM;\n",
    "        float dot = 0.f;\n",
    "        for (int d = 0; d < DIM; ++d) dot += row[d] * q[d];\n",
    "        distSel[j] = 1.f - dot;\n",
    "    }\n",
    "}\n",
    "\n",
    "// // data[0..Ntot-1] vs single q\n",
    "// __global__ void cosineDistKernel(const float* data,\n",
    "//                                  const float* q,\n",
    "//                                  int Ntot,\n",
    "//                                  float* out) {\n",
    "//     for (int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "//          i < Ntot;\n",
    "//          i += gridDim.x * blockDim.x) {\n",
    "//         const float* row = data + (size_t)i * DIM;\n",
    "//         float dot = 0.f;\n",
    "//         for (int d = 0; d < DIM; ++d) dot += row[d] * q[d];\n",
    "//         out[i] = 1.f - dot;\n",
    "//     }\n",
    "// }\n",
    "\n",
    "// // assign idxSel[0..M-1] vs q\n",
    "// __global__ void cosineDistIndexKernel(const float* data,\n",
    "//                                       const float* q,\n",
    "//                                       const int* idxSel,\n",
    "//                                       int M,\n",
    "//                                       float* distSel) {\n",
    "//     for (int j = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "//          j < M;\n",
    "//          j += gridDim.x * blockDim.x) {\n",
    "//         int i = idxSel[j];\n",
    "//         const float* row = data + (size_t)i * DIM;\n",
    "//         float dot = 0.f;\n",
    "//         for (int d = 0; d < DIM; ++d) dot += row[d] * q[d];\n",
    "//         distSel[j] = 1.f - dot;\n",
    "//     }\n",
    "// }\n",
    "\n",
    "// ----------------  GPU K-Means Kernels ----------------\n",
    "\n",
    "void assignAndAccumulateKernel(const float* data,\n",
    "                                          int N,\n",
    "                                          const float* centroids,\n",
    "                                          int K,\n",
    "                                          int* assign,\n",
    "                                          float* sums,\n",
    "                                          int* counts) {\n",
    "    for (int i = 0;\n",
    "         i < N;\n",
    "         i++) {\n",
    "\n",
    "        const float* xi = data + (size_t)i * DIM;\n",
    "\n",
    "        int bestC = 0;\n",
    "        float bestD = 1e30f;\n",
    "\n",
    "        for (int c = 0; c < K; ++c) {\n",
    "            const float* ctr = centroids + (size_t)c * DIM;\n",
    "            float dot = 0.f;\n",
    "            for (int d = 0; d < DIM; ++d) {\n",
    "                dot += xi[d] * ctr[d];\n",
    "            }\n",
    "            float dist = 1.f - dot;\n",
    "            if (dist < bestD) {\n",
    "                bestD = dist;\n",
    "                bestC = c;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        assign[i] = bestC;\n",
    "\n",
    "        // atomicAdd(&counts[bestC], 1);\n",
    "        counts[bestC]++;\n",
    "        size_t base = (size_t)bestC * DIM;\n",
    "        for (int d = 0; d < DIM; ++d) {\n",
    "            //atomicAdd(&sums[base + d], xi[d]);\n",
    "            sums[base + d] += xi[d];\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "void updateCentroidsKernel(float* centroids,\n",
    "                                      const float* sums,\n",
    "                                      const int* counts,\n",
    "                                      int K) {\n",
    "    for (int c = 0; c < K; c++) {\n",
    "        int cnt = counts[c];\n",
    "        float* ctr = centroids + (size_t)c * DIM;\n",
    "        const float* sumc = sums + (size_t)c * DIM;\n",
    "    \n",
    "        if (cnt > 0) {\n",
    "            double norm2 = 0.0;\n",
    "            for (int d = 0; d < DIM; ++d) {\n",
    "                float v = sumc[d] / (float)cnt;\n",
    "                ctr[d] = v;\n",
    "                norm2 += (double)v * (double)v;\n",
    "            }\n",
    "            float n = float(std::sqrt(norm2) + 1e-12);\n",
    "            for (int d = 0; d < DIM; ++d) {\n",
    "                ctr[d] /= n;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// // E-step + accumulate:\n",
    "// // every data to search nearest center -> assign[i]\n",
    "// // atomicAdd sums[c][d] and counts[c]\n",
    "// __global__ void assignAndAccumulateKernel(const float* data,\n",
    "//                                           int N,\n",
    "//                                           const float* centroids,\n",
    "//                                           int K,\n",
    "//                                           int* assign,\n",
    "//                                           float* sums,\n",
    "//                                           int* counts) {\n",
    "//     for (int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "//          i < N;\n",
    "//          i += gridDim.x * blockDim.x) {\n",
    "\n",
    "//         const float* xi = data + (size_t)i * DIM;\n",
    "\n",
    "//         int bestC = 0;\n",
    "//         float bestD = 1e30f;\n",
    "\n",
    "//         for (int c = 0; c < K; ++c) {\n",
    "//             const float* ctr = centroids + (size_t)c * DIM;\n",
    "//             float dot = 0.f;\n",
    "//             for (int d = 0; d < DIM; ++d) {\n",
    "//                 dot += xi[d] * ctr[d];\n",
    "//             }\n",
    "//             float dist = 1.f - dot;\n",
    "//             if (dist < bestD) {\n",
    "//                 bestD = dist;\n",
    "//                 bestC = c;\n",
    "//             }\n",
    "//         }\n",
    "\n",
    "//         assign[i] = bestC;\n",
    "\n",
    "//         atomicAdd(&counts[bestC], 1);\n",
    "//         size_t base = (size_t)bestC * DIM;\n",
    "//         for (int d = 0; d < DIM; ++d) {\n",
    "//             atomicAdd(&sums[base + d], xi[d]);\n",
    "//         }\n",
    "//     }\n",
    "// }\n",
    "\n",
    "// // M-step: sums/counts -> update centroid + norm\n",
    "// __global__ void updateCentroidsKernel(float* centroids,\n",
    "//                                       const float* sums,\n",
    "//                                       const int* counts,\n",
    "//                                       int K) {\n",
    "//     int c = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "//     if (c >= K) return;\n",
    "\n",
    "//     int cnt = counts[c];\n",
    "//     float* ctr = centroids + (size_t)c * DIM;\n",
    "//     const float* sumc = sums + (size_t)c * DIM;\n",
    "\n",
    "//     if (cnt > 0) {\n",
    "//         double norm2 = 0.0;\n",
    "//         for (int d = 0; d < DIM; ++d) {\n",
    "//             float v = sumc[d] / (float)cnt;\n",
    "//             ctr[d] = v;\n",
    "//             norm2 += (double)v * (double)v;\n",
    "//         }\n",
    "//         float n = float(std::sqrt(norm2) + 1e-12);\n",
    "//         for (int d = 0; d < DIM; ++d) {\n",
    "//             ctr[d] /= n;\n",
    "//         }\n",
    "//     }\n",
    "// }\n",
    "\n",
    "// ---------------- Host: Inverted Lists (vector<vector<int>>) ----------------\n",
    "\n",
    "static void buildInvertedLists(\n",
    "    const std::vector<int>& assign,\n",
    "    int N, int K,\n",
    "    std::vector<std::vector<int>>& lists\n",
    ") {\n",
    "    lists.assign(K, {});\n",
    "    for (int i = 0; i < N; ++i) {\n",
    "        int c = assign[i];\n",
    "        if (c >= 0 && c < K) {\n",
    "            lists[c].push_back(i);\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "static void buildCSRFromLists(\n",
    "    const std::vector<std::vector<int>>& lists,\n",
    "    int K, int N,\n",
    "    std::vector<int>& listOffsets,\n",
    "    std::vector<int>& listIds\n",
    ") {\n",
    "    listOffsets.assign(K + 1, 0);\n",
    "    listIds.clear();\n",
    "    listIds.reserve(N);\n",
    "\n",
    "    int offset = 0;\n",
    "    for (int c = 0; c < K; ++c) {\n",
    "        listOffsets[c] = offset;\n",
    "        const std::vector<int>& bucket = lists[c];\n",
    "        listIds.insert(listIds.end(), bucket.begin(), bucket.end());\n",
    "        offset += (int)bucket.size();\n",
    "    }\n",
    "    listOffsets[K] = offset;\n",
    "}\n",
    "\n",
    "// ---------------- Device: gatherCandidates ----------------\n",
    "\n",
    "void gatherCandidatesKernel(\n",
    "    const int* centIds,\n",
    "    int nprobe,\n",
    "    const int* listOffsets,\n",
    "    const int* listIds,\n",
    "    int* outIdx,\n",
    "    int* outCount\n",
    ") {\n",
    "\n",
    "    for (int p = 0; p < nprobe; p++) {\n",
    "        int c = centIds[p];\n",
    "        int start = listOffsets[c];\n",
    "        int end   = listOffsets[c + 1];\n",
    "        int len   = end - start;\n",
    "        if (len <= 0) return;\n",
    "    \n",
    "        // int base = atomicAdd(outCount, len);\n",
    "        int base = *outCount;\n",
    "        // 2. Perform the addition\n",
    "        *outCount += len;        \n",
    "        for (int i = 0; i < len; ++i) {\n",
    "            outIdx[base + i] = listIds[start + i];\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// // centIds:     \n",
    "// // nprobe:      nprobe to dect\n",
    "// // listOffsets: CSR offsets,\n",
    "// // listIds:     CSR ids\n",
    "// // outIdx:     \n",
    "// // outCount:    \n",
    "// __global__ void gatherCandidatesKernel(\n",
    "//     const int* centIds,\n",
    "//     int nprobe,\n",
    "//     const int* listOffsets,\n",
    "//     const int* listIds,\n",
    "//     int* outIdx,\n",
    "//     int* outCount\n",
    "// ) {\n",
    "//     int p = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "//     if (p >= nprobe) return;\n",
    "\n",
    "//     int c = centIds[p];\n",
    "//     int start = listOffsets[c];\n",
    "//     int end   = listOffsets[c + 1];\n",
    "//     int len   = end - start;\n",
    "//     if (len <= 0) return;\n",
    "\n",
    "//     int base = atomicAdd(outCount, len);\n",
    "//     for (int i = 0; i < len; ++i) {\n",
    "//         outIdx[base + i] = listIds[start + i];\n",
    "//     }\n",
    "// }\n",
    "\n",
    "// ---------------- Main ----------------\n",
    "int main() {\n",
    "    printf(\"Params: N=%d  K=%d  nprobe=%d  TOPK=%d  DIM=%d  KMEANS_ITERS=%d\\n\",\n",
    "           N, K, NPROBE, TOPK, DIM, KMEANS_ITERS);\n",
    "\n",
    "    initBases();\n",
    "    std::mt19937 rng(SEED + 7);\n",
    "\n",
    "    clock_t start, end;\n",
    "    double elapse, time_taken;\n",
    "    elapse = 0.0f;\n",
    "\n",
    "    start = clock();\n",
    "\n",
    "    // 1) building dataset\n",
    "    std::vector<int>   h_cards((size_t)N * 25);\n",
    "    std::vector<float> h_data((size_t)N * DIM);\n",
    "\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        int c[25];\n",
    "        genCard(rng, c);\n",
    "        for (int t = 0; t < 25; ++t)\n",
    "            h_cards[(size_t)i * 25 + t] = c[t];\n",
    "        Vec v = cardToVec(c);\n",
    "        for (int d = 0; d < DIM; ++d)\n",
    "            h_data[(size_t)i * DIM + d] = v[d];\n",
    "    }\n",
    "\n",
    "    // 2) build query\n",
    "    int qc[25];\n",
    "    for (int t = 0; t < 25; ++t) qc[t] = h_cards[t];\n",
    "    qc[3] = 75; qc[17] = 1; std::swap(qc[5], qc[19]);\n",
    "    Vec qvec = cardToVec(qc);\n",
    "\n",
    "    {\n",
    "        std::vector<float> qhost(qvec.begin(), qvec.end());\n",
    "        std::vector<float> d0(DIM);\n",
    "        for (int i = 0; i < DIM; i++) d0[i] = h_data[i];\n",
    "        double dot0 = dot_host(qhost.data(), d0.data());\n",
    "        printf(\"[DEBUG #1] host dot(q, data[0])=%.9f  dist=%.9f\\n\",\n",
    "               dot0, 1.0 - dot0);\n",
    "    }\n",
    "\n",
    "    // 3) GPU buffers\n",
    "    float *d_data = 0, *d_q = 0, *d_centroids = 0;\n",
    "    float *d_tmpCentDist = 0;\n",
    "\n",
    "    d_data = (float*)malloc((size_t)N * DIM * sizeof(float));\n",
    "    d_q = (float*)malloc(DIM * sizeof(float));\n",
    "    d_centroids = (float*)malloc((size_t)K * DIM * sizeof(float));\n",
    "    d_tmpCentDist = (float*)malloc(K * sizeof(float));\n",
    "\n",
    "    // cudaMalloc(&d_data, (size_t)N * DIM * sizeof(float));\n",
    "    // cudaMalloc(&d_q, DIM * sizeof(float));\n",
    "    // cudaMalloc(&d_centroids, (size_t)K * DIM * sizeof(float));\n",
    "    // cudaMalloc(&d_tmpCentDist, K * sizeof(float));\n",
    "\n",
    "    memcpy(d_data, h_data.data(),\n",
    "               (size_t)N * DIM * sizeof(float));\n",
    "    memcpy(d_q, qvec.data(),\n",
    "               DIM * sizeof(float));\n",
    "\n",
    "    // cudaMemcpy(d_data, h_data.data(),\n",
    "    //            (size_t)N * DIM * sizeof(float),\n",
    "    //            cudaMemcpyHostToDevice);\n",
    "    // cudaMemcpy(d_q, qvec.data(),\n",
    "    //            DIM * sizeof(float),\n",
    "    //            cudaMemcpyHostToDevice);\n",
    "\n",
    "    // 4) initial centroids: Host random select K centers\n",
    "    {\n",
    "        std::vector<int> idx(N);\n",
    "        std::iota(idx.begin(), idx.end(), 0);\n",
    "        std::shuffle(idx.begin(), idx.end(), rng);\n",
    "        std::vector<float> h_initC((size_t)K * DIM);\n",
    "        for (int c = 0; c < K; ++c) {\n",
    "            int i = idx[c];\n",
    "            std::copy_n(&h_data[(size_t)i * DIM], DIM,\n",
    "                        &h_initC[(size_t)c * DIM]);\n",
    "        }\n",
    "\n",
    "        memcpy(d_centroids, h_initC.data(),\n",
    "                   (size_t)K * DIM * sizeof(float));\n",
    "        // cudaMemcpy(d_centroids, h_initC.data(),\n",
    "        //            (size_t)K * DIM * sizeof(float),\n",
    "        //            cudaMemcpyHostToDevice);\n",
    "    }\n",
    "\n",
    "    int   *d_assign = 0;\n",
    "    float *d_sums   = 0;\n",
    "    int   *d_counts = 0;\n",
    "\n",
    "    d_assign = (int*)malloc(N * sizeof(int));\n",
    "    d_sums = (float*)malloc((size_t)K * DIM * sizeof(float));\n",
    "    d_counts = (int*)malloc(K * sizeof(int));\n",
    "\n",
    "    // cudaMalloc(&d_assign, N * sizeof(int));\n",
    "    // cudaMalloc(&d_sums,   (size_t)K * DIM * sizeof(float));\n",
    "    // cudaMalloc(&d_counts, K * sizeof(int));\n",
    "\n",
    "    // 5) GPU K-Means\n",
    "    {\n",
    "        printf(\"[BUILD] K-Means: iters=%d\\n\", KMEANS_ITERS);\n",
    "\n",
    "        for (int it = 0; it < KMEANS_ITERS; ++it) {\n",
    "            // cudaMemset(d_sums,   0, (size_t)K * DIM * sizeof(float));\n",
    "            // cudaMemset(d_counts, 0, K * sizeof(int));\n",
    "            memset(d_sums,   0, (size_t)K * DIM * sizeof(float));\n",
    "            memset(d_counts, 0, K * sizeof(int));\n",
    "\n",
    "            assignAndAccumulateKernel(\n",
    "                d_data, N, d_centroids, K,\n",
    "                d_assign, d_sums, d_counts\n",
    "            );\n",
    "            // cudaDeviceSynchronize();\n",
    "\n",
    "            updateCentroidsKernel(\n",
    "                d_centroids, d_sums, d_counts, K\n",
    "            );\n",
    "            // cudaDeviceSynchronize();\n",
    "        }\n",
    "\n",
    "        end = clock();\n",
    "        time_taken = ((double)(end-start))*1E3/CLOCKS_PER_SEC;\n",
    "        elapse = elapse + time_taken;\n",
    "         printf(\"K-means (in C++) average time is %f milliseconds to execute an array size %d \\n\", elapse, N);\n",
    "    }\n",
    "\n",
    "    start = clock();\n",
    "\n",
    "    // 6) build inverted index on host\n",
    "    std::vector<int> h_assign(N);\n",
    "    // cudaMemcpy(h_assign.data(), d_assign,\n",
    "    //            N * sizeof(int),\n",
    "    //            cudaMemcpyDeviceToHost);\n",
    "    memcpy(h_assign.data(), d_assign,\n",
    "               N * sizeof(int));\n",
    "\n",
    "    // IVF FOR \n",
    "    std::vector<std::vector<int>> lists;\n",
    "    buildInvertedLists(h_assign, N, K, lists);\n",
    "\n",
    "    int nonEmpty = 0;\n",
    "    for (int c = 0; c < K; ++c)\n",
    "        if (!lists[c].empty()) nonEmpty++;\n",
    "    printf(\"[BUILD] Non-empty clusters: %d / %d\\n\", nonEmpty, K);\n",
    "\n",
    "    // 7) flatten lists -> CSR, copy to device\n",
    "    std::vector<int> h_listOffsets;\n",
    "    std::vector<int> h_listIds;\n",
    "    buildCSRFromLists(lists, K, N, h_listOffsets, h_listIds);\n",
    "\n",
    "    int *d_listOffsets = 0;\n",
    "    int *d_listIds     = 0;\n",
    "\n",
    "    d_listOffsets = (int*)malloc((K + 1) * sizeof(int));\n",
    "    d_listIds = (int*)malloc(h_listIds.size() * sizeof(int));\n",
    "\n",
    "    // cudaMalloc(&d_listOffsets, (K + 1) * sizeof(int));\n",
    "    // cudaMalloc(&d_listIds,     h_listIds.size() * sizeof(int));\n",
    "\n",
    "    memcpy(d_listOffsets, h_listOffsets.data(),\n",
    "               (K + 1) * sizeof(int));\n",
    "    memcpy(d_listIds, h_listIds.data(),\n",
    "               h_listIds.size() * sizeof(int));\n",
    "\n",
    "    // cudaMemcpy(d_listOffsets, h_listOffsets.data(),\n",
    "    //            (K + 1) * sizeof(int),\n",
    "    //            cudaMemcpyHostToDevice);\n",
    "    // cudaMemcpy(d_listIds, h_listIds.data(),\n",
    "    //            h_listIds.size() * sizeof(int),\n",
    "    //            cudaMemcpyHostToDevice);\n",
    "\n",
    "    // 8) Search Stage 1: q vs centroids -> Thrust sort for NPROBE\n",
    "    {\n",
    "        // dim3 block(BLOCK);\n",
    "        // dim3 grid((K + BLOCK - 1) / BLOCK);\n",
    "        // cosineDistKernel<<<grid, block>>>(d_centroids, d_q, K, d_tmpCentDist);\n",
    "        // cudaDeviceSynchronize();\n",
    "\n",
    "        cosineDistKernel(d_centroids, d_q, K, d_tmpCentDist);\n",
    "    }\n",
    "\n",
    "    // thrust::device_ptr<float> dist_ptr(d_tmpCentDist);\n",
    "    // thrust::device_vector<int> d_centIds(K);\n",
    "    // thrust::sequence(d_centIds.begin(), d_centIds.end()); // 0..K-1\n",
    "\n",
    "    // thrust::sort_by_key(dist_ptr, dist_ptr + K, d_centIds.begin());\n",
    "\n",
    "    std::vector<int> h_centIds(K);\n",
    "    std::iota(h_centIds.begin(), h_centIds.end(), 0);\n",
    "    std::sort(h_centIds.begin(), h_centIds.end(), \n",
    "        [d_tmpCentDist](int a, int b) {\n",
    "            return d_tmpCentDist[a] < d_tmpCentDist[b];\n",
    "        }\n",
    "    );\n",
    "\n",
    "    // 9) GPU  collect the NPROBE numbers of cluster to do candiating\n",
    "    // int *d_outIdx   = 0;\n",
    "    // int *d_outCount = 0;\n",
    "    // cudaMalloc(&d_outIdx,   N * sizeof(int));  // 上界 N（通常远小于）\n",
    "    // cudaMalloc(&d_outCount, sizeof(int));\n",
    "    // cudaMemset(d_outCount,  0, sizeof(int));\n",
    "\n",
    "    int *d_outIdx = (int*)malloc(N * sizeof(int)); \n",
    "    int *d_outCount = (int*)malloc(sizeof(int));\n",
    "    *d_outCount = 0;\n",
    "\n",
    "    // {\n",
    "    //     gatherCandidatesKernel<<<BLOCK, threads>>>(\n",
    "    //         thrust::raw_pointer_cast(d_centIds.data()),\n",
    "    //         NPROBE,\n",
    "    //         d_listOffsets,\n",
    "    //         d_listIds,\n",
    "    //         d_outIdx,\n",
    "    //         d_outCount\n",
    "    //     );\n",
    "    //     cudaDeviceSynchronize();\n",
    "    // }\n",
    "\n",
    "    gatherCandidatesKernel(\n",
    "        h_centIds.data(),\n",
    "        NPROBE,\n",
    "        d_listOffsets,\n",
    "        d_listIds,\n",
    "        d_outIdx,\n",
    "        d_outCount\n",
    "    );\n",
    "\n",
    "    int M = 0;\n",
    "    // cudaMemcpy(&M, d_outCount, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "    memcpy(&M, d_outCount, sizeof(int));\n",
    "    printf(\"Candidates from chosen centers: M=%d (of N=%d)\\n\", M, N);\n",
    "\n",
    "    if (M <= 0) {\n",
    "        printf(\"No candidates, abort.\\n\");\n",
    "    } else {\n",
    "        // 10) Stage 2: candidate Top-K on GPU via CUB\n",
    "\n",
    "        float *d_selDist   = 0;   // distance between candidates\n",
    "        float *d_keys_out  = 0;   // distance after sorting\n",
    "        int   *d_vals_out  = 0;   // candidates id after sorting\n",
    "        void  *d_temp_storage = 0;\n",
    "        size_t temp_bytes = 0;\n",
    "        \n",
    "        // 1) 为距离分配空间\n",
    "        // cudaMalloc(&d_selDist, M * sizeof(float));\n",
    "        d_selDist = (float*)malloc(M * sizeof(float));\n",
    "        \n",
    "        // 2) 计算 query vs 每个候选向量的距离\n",
    "        // {\n",
    "        //     dim3 block(BLOCK);\n",
    "        //     dim3 grid((M + BLOCK - 1) / BLOCK);\n",
    "        //     // 注意这里直接用 d_outIdx 作为候选 id 列表\n",
    "        //     cosineDistIndexKernel<<<grid, block>>>(\n",
    "        //         d_data, d_q, d_outIdx, M, d_selDist\n",
    "        //     );\n",
    "        //     cudaDeviceSynchronize();\n",
    "        // }\n",
    "        cosineDistIndexKernel(\n",
    "            d_data, d_q, d_outIdx, M, d_selDist\n",
    "        );\n",
    "        \n",
    "        // 3)CUB malloc space\n",
    "        // cudaMalloc(&d_keys_out, M * sizeof(float));\n",
    "        // cudaMalloc(&d_vals_out, M * sizeof(int));\n",
    "\n",
    "        d_keys_out = (float*)malloc(M * sizeof(float));\n",
    "        d_vals_out = (int*)malloc(M * sizeof(int));\n",
    "\n",
    "        std::vector<std::pair<float, int>> pairs(M);\n",
    "        for (int i = 0; i < M; ++i) {\n",
    "            pairs[i] = {d_selDist[i], d_outIdx[i]};\n",
    "        }\n",
    "\n",
    "        std::sort(pairs.begin(), pairs.end());\n",
    "\n",
    "        for (int i = 0; i < M; ++i) {\n",
    "            d_keys_out[i] = pairs[i].first;  // The sorted distance\n",
    "            d_vals_out[i] = pairs[i].second; // The corresponding vector ID\n",
    "        }\n",
    "        \n",
    "        // // 4) first time using SortPairs  to access size of buffer ares needed\n",
    "        // cub::DeviceRadixSort::SortPairs(\n",
    "        //     d_temp_storage, temp_bytes,\n",
    "        //     d_selDist, d_keys_out,   // keys: distance\n",
    "        //     d_outIdx,  d_vals_out,   // values: gathered id（\n",
    "        //     M\n",
    "        // );\n",
    "        // cudaMalloc(&d_temp_storage, temp_bytes);\n",
    "        \n",
    "        // // 5) really sort from nearest to further\n",
    "        // cub::DeviceRadixSort::SortPairs(\n",
    "        //     d_temp_storage, temp_bytes,\n",
    "        //     d_selDist, d_keys_out,\n",
    "        //     d_outIdx,  d_vals_out,\n",
    "        //     M\n",
    "        // );\n",
    "        // cudaDeviceSynchronize();\n",
    "        \n",
    "        // 6) extract top to CPU，做 TopK & 打印\n",
    "        int take = std::min(M, TOPK * 4);\n",
    "        std::vector<float> h_keys(take);\n",
    "        std::vector<int>   h_ids(take);\n",
    "        \n",
    "        // cudaMemcpy(h_keys.data(), d_keys_out,\n",
    "        //            take * sizeof(float),\n",
    "        //            cudaMemcpyDeviceToHost);\n",
    "        // cudaMemcpy(h_ids.data(), d_vals_out,\n",
    "        //            take * sizeof(int),\n",
    "        //            cudaMemcpyDeviceToHost);\n",
    "//\n",
    "        memcpy(h_keys.data(), d_keys_out,\n",
    "                   take * sizeof(float));\n",
    "        memcpy(h_ids.data(), d_vals_out,\n",
    "                   take * sizeof(int));\n",
    "        \n",
    "        std::vector<Pair> uniq;\n",
    "        uniq.reserve(TOPK);\n",
    "        std::unordered_set<int> seen;\n",
    "        \n",
    "        for (int i = 0; i < take; ++i) {\n",
    "            int id = h_ids[i];\n",
    "            float dist = h_keys[i];\n",
    "            if (id < 0 || !std::isfinite(dist)) continue;\n",
    "            if (seen.insert(id).second) {\n",
    "                uniq.push_back(Pair{dist, id});\n",
    "                if ((int)uniq.size() == TOPK) break;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        printf(\"Top-%d among %d candidates (CUB SortPairs):\\n\",\n",
    "               (int)uniq.size(), M);\n",
    "        for (int i = 0; i < (int)uniq.size(); ++i) {\n",
    "            printf(\"%2d) id=%d  dist=%.6f  sim=%.6f\\n\",\n",
    "                   i+1, uniq[i].id, uniq[i].key, 1.f - uniq[i].key);\n",
    "        }\n",
    "\n",
    "        if (!uniq.empty()) {\n",
    "            int bestId = uniq[0].id;\n",
    "            std::vector<float> qhost(qvec.begin(), qvec.end());\n",
    "            std::vector<float> dv(DIM);\n",
    "            for (int i = 0; i < DIM; ++i)\n",
    "                dv[i] = h_data[(size_t)bestId * DIM + i];\n",
    "            double dotChk = dot_host(qhost.data(), dv.data());\n",
    "            printf(\"[DEBUG] host check best id=%d  dot=%.9f  dist=%.9f\\n\",\n",
    "                   bestId, dotChk, 1.0 - dotChk);\n",
    "        }\n",
    "\n",
    "        // cudaFree(d_temp_storage);\n",
    "        // cudaFree(d_keys_out);\n",
    "        // cudaFree(d_vals_out);\n",
    "        // cudaFree(d_selDist);\n",
    "\n",
    "        free(d_temp_storage);\n",
    "        free(d_keys_out);\n",
    "        free(d_vals_out);\n",
    "        free(d_selDist);\n",
    "    }\n",
    "\n",
    "    end = clock();\n",
    "    time_taken = ((double)(end-start))*1E3/CLOCKS_PER_SEC;\n",
    "    elapse = elapse + time_taken;\n",
    "     printf(\"Function (in C++) average time is %f milliseconds to execute an array size %d \\n\", time_taken, N);\n",
    "\n",
    "    // 11) free\n",
    "    // cudaFree(d_outIdx);\n",
    "    // cudaFree(d_outCount);\n",
    "    // cudaFree(d_tmpCentDist);\n",
    "    // cudaFree(d_centroids);\n",
    "    // cudaFree(d_q);\n",
    "    // cudaFree(d_data);\n",
    "    // cudaFree(d_assign);\n",
    "    // cudaFree(d_sums);\n",
    "    // cudaFree(d_counts);\n",
    "    // cudaFree(d_listOffsets);\n",
    "    // cudaFree(d_listIds);\n",
    "\n",
    "    free(d_outIdx);\n",
    "    free(d_outCount);\n",
    "    free(d_tmpCentDist);\n",
    "    free(d_centroids);\n",
    "    free(d_q);\n",
    "    free(d_data);\n",
    "    free(d_assign);\n",
    "    free(d_sums);\n",
    "    free(d_counts);\n",
    "    free(d_listOffsets);\n",
    "    free(d_listIds);    \n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23354457-6d74-4fcb-a030-4ab95d581082",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "g++ -std=c++11 C_ann_3.cpp -o C_ann_3 -lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf24373e-5fd8-488e-bf4c-6993538f5d22",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: N=16384  K=1024  nprobe=4  TOPK=5  DIM=64  KMEANS_ITERS=15\n",
      "[DEBUG #1] host dot(q, data[0])=0.927471359  dist=0.072528641\n",
      "[BUILD] K-Means: iters=15\n",
      "K-means (in C++) average time is 57194.134000 milliseconds to execute an array size 16384 \n",
      "[BUILD] Non-empty clusters: 1024 / 1024\n",
      "Candidates from chosen centers: M=105 (of N=16384)\n",
      "Top-5 among 105 candidates (CUB SortPairs):\n",
      " 1) id=0  dist=0.072529  sim=0.927471\n",
      " 2) id=15967  dist=0.177058  sim=0.822942\n",
      " 3) id=1427  dist=0.216366  sim=0.783634\n",
      " 4) id=3831  dist=0.226154  sim=0.773846\n",
      " 5) id=10211  dist=0.246999  sim=0.753001\n",
      "[DEBUG] host check best id=0  dot=0.927471359  dist=0.072528641\n",
      "Function (in C++) average time is 4.311000 milliseconds to execute an array size 16384 \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./C_ann_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaa9559-d3a6-49d8-8ff4-0d13d2fb40b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
